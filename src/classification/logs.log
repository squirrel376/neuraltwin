2025-08-25 18:37:59,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-25 18:37:59,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-25 18:37:59,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-25 18:37:59,822:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-25 18:38:27,088:INFO:PyCaret ClassificationExperiment
2025-08-25 18:38:27,088:INFO:Logging name: clf-default-name
2025-08-25 18:38:27,090:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-25 18:38:27,090:INFO:version 3.3.2
2025-08-25 18:38:27,091:INFO:Initializing setup()
2025-08-25 18:38:27,091:INFO:self.USI: d2d7
2025-08-25 18:38:27,091:INFO:self._variable_keys: {'html_param', 'data', 'X_train', 'idx', 'gpu_n_jobs_param', 'target_param', 'y_train', 'pipeline', 'gpu_param', 'X_test', 'n_jobs_param', 'exp_name_log', 'fold_shuffle_param', 'exp_id', 'is_multiclass', '_available_plots', 'seed', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'memory', 'USI', 'fold_generator', 'logging_param', 'y', 'X', 'y_test', 'fix_imbalance'}
2025-08-25 18:38:27,092:INFO:Checking environment
2025-08-25 18:38:27,092:INFO:python_version: 3.11.9
2025-08-25 18:38:27,093:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-25 18:38:27,093:INFO:machine: AMD64
2025-08-25 18:38:27,093:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-25 18:38:27,097:INFO:Memory: svmem(total=17024348160, available=2217205760, percent=87.0, used=14807142400, free=2217205760)
2025-08-25 18:38:27,097:INFO:Physical Core: 4
2025-08-25 18:38:27,097:INFO:Logical Core: 8
2025-08-25 18:38:27,097:INFO:Checking libraries
2025-08-25 18:38:27,097:INFO:System:
2025-08-25 18:38:27,097:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-25 18:38:27,097:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-25 18:38:27,097:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-25 18:38:27,097:INFO:PyCaret required dependencies:
2025-08-25 18:38:27,105:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-25 18:38:27,632:INFO:                 pip: Not installed
2025-08-25 18:38:27,632:INFO:          setuptools: 80.9.0
2025-08-25 18:38:27,633:INFO:             pycaret: 3.3.2
2025-08-25 18:38:27,633:INFO:             IPython: 9.4.0
2025-08-25 18:38:27,633:INFO:          ipywidgets: 8.1.7
2025-08-25 18:38:27,633:INFO:                tqdm: 4.67.1
2025-08-25 18:38:27,633:INFO:               numpy: 1.26.4
2025-08-25 18:38:27,634:INFO:              pandas: 2.1.4
2025-08-25 18:38:27,634:INFO:              jinja2: 3.1.6
2025-08-25 18:38:27,634:INFO:               scipy: 1.11.4
2025-08-25 18:38:27,634:INFO:              joblib: 1.3.2
2025-08-25 18:38:27,634:INFO:             sklearn: 1.4.2
2025-08-25 18:38:27,634:INFO:                pyod: 2.0.5
2025-08-25 18:38:27,634:INFO:            imblearn: 0.14.0
2025-08-25 18:38:27,635:INFO:   category_encoders: 2.7.0
2025-08-25 18:38:27,635:INFO:            lightgbm: 4.6.0
2025-08-25 18:38:27,635:INFO:               numba: 0.61.2
2025-08-25 18:38:27,635:INFO:            requests: 2.32.5
2025-08-25 18:38:27,635:INFO:          matplotlib: 3.7.5
2025-08-25 18:38:27,636:INFO:          scikitplot: 0.3.7
2025-08-25 18:38:27,636:INFO:         yellowbrick: 1.5
2025-08-25 18:38:27,636:INFO:              plotly: 5.24.1
2025-08-25 18:38:27,637:INFO:    plotly-resampler: Not installed
2025-08-25 18:38:27,637:INFO:             kaleido: 1.0.0
2025-08-25 18:38:27,637:INFO:           schemdraw: 0.15
2025-08-25 18:38:27,638:INFO:         statsmodels: 0.14.5
2025-08-25 18:38:27,638:INFO:              sktime: 0.26.0
2025-08-25 18:38:27,639:INFO:               tbats: 1.1.3
2025-08-25 18:38:27,639:INFO:            pmdarima: 2.0.4
2025-08-25 18:38:27,640:INFO:              psutil: 7.0.0
2025-08-25 18:38:27,640:INFO:          markupsafe: 3.0.2
2025-08-25 18:38:27,641:INFO:             pickle5: Not installed
2025-08-25 18:38:27,641:INFO:         cloudpickle: 3.1.1
2025-08-25 18:38:27,641:INFO:         deprecation: 2.1.0
2025-08-25 18:38:27,641:INFO:              xxhash: 3.5.0
2025-08-25 18:38:27,641:INFO:           wurlitzer: Not installed
2025-08-25 18:38:27,642:INFO:PyCaret optional dependencies:
2025-08-25 18:38:27,716:INFO:                shap: Not installed
2025-08-25 18:38:27,716:INFO:           interpret: Not installed
2025-08-25 18:38:27,716:INFO:                umap: Not installed
2025-08-25 18:38:27,716:INFO:     ydata_profiling: Not installed
2025-08-25 18:38:27,716:INFO:  explainerdashboard: Not installed
2025-08-25 18:38:27,716:INFO:             autoviz: Not installed
2025-08-25 18:38:27,716:INFO:           fairlearn: Not installed
2025-08-25 18:38:27,716:INFO:          deepchecks: Not installed
2025-08-25 18:38:27,716:INFO:             xgboost: Not installed
2025-08-25 18:38:27,716:INFO:            catboost: Not installed
2025-08-25 18:38:27,716:INFO:              kmodes: Not installed
2025-08-25 18:38:27,716:INFO:             mlxtend: Not installed
2025-08-25 18:38:27,716:INFO:       statsforecast: Not installed
2025-08-25 18:38:27,716:INFO:        tune_sklearn: Not installed
2025-08-25 18:38:27,716:INFO:                 ray: Not installed
2025-08-25 18:38:27,720:INFO:            hyperopt: Not installed
2025-08-25 18:38:27,720:INFO:              optuna: Not installed
2025-08-25 18:38:27,720:INFO:               skopt: Not installed
2025-08-25 18:38:27,720:INFO:              mlflow: Not installed
2025-08-25 18:38:27,720:INFO:              gradio: Not installed
2025-08-25 18:38:27,720:INFO:             fastapi: Not installed
2025-08-25 18:38:27,720:INFO:             uvicorn: Not installed
2025-08-25 18:38:27,720:INFO:              m2cgen: Not installed
2025-08-25 18:38:27,721:INFO:           evidently: Not installed
2025-08-25 18:38:27,721:INFO:               fugue: Not installed
2025-08-25 18:38:27,721:INFO:           streamlit: Not installed
2025-08-25 18:38:27,721:INFO:             prophet: Not installed
2025-08-25 18:38:27,721:INFO:None
2025-08-25 18:38:27,721:INFO:Set up data.
2025-08-25 18:38:27,731:INFO:Set up folding strategy.
2025-08-25 18:38:56,532:INFO:PyCaret ClassificationExperiment
2025-08-25 18:38:56,532:INFO:Logging name: clf-default-name
2025-08-25 18:38:56,532:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-25 18:38:56,532:INFO:version 3.3.2
2025-08-25 18:38:56,532:INFO:Initializing setup()
2025-08-25 18:38:56,532:INFO:self.USI: dd23
2025-08-25 18:38:56,532:INFO:self._variable_keys: {'html_param', 'data', 'X_train', 'idx', 'gpu_n_jobs_param', 'target_param', 'y_train', 'pipeline', 'gpu_param', 'X_test', 'n_jobs_param', 'exp_name_log', 'fold_shuffle_param', 'exp_id', 'is_multiclass', '_available_plots', 'seed', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'memory', 'USI', 'fold_generator', 'logging_param', 'y', 'X', 'y_test', 'fix_imbalance'}
2025-08-25 18:38:56,532:INFO:Checking environment
2025-08-25 18:38:56,532:INFO:python_version: 3.11.9
2025-08-25 18:38:56,533:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-25 18:38:56,533:INFO:machine: AMD64
2025-08-25 18:38:56,533:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-25 18:38:56,537:INFO:Memory: svmem(total=17024348160, available=2321158144, percent=86.4, used=14703190016, free=2321158144)
2025-08-25 18:38:56,537:INFO:Physical Core: 4
2025-08-25 18:38:56,537:INFO:Logical Core: 8
2025-08-25 18:38:56,538:INFO:Checking libraries
2025-08-25 18:38:56,538:INFO:System:
2025-08-25 18:38:56,538:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-25 18:38:56,538:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-25 18:38:56,538:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-25 18:38:56,538:INFO:PyCaret required dependencies:
2025-08-25 18:38:56,538:INFO:                 pip: Not installed
2025-08-25 18:38:56,538:INFO:          setuptools: 80.9.0
2025-08-25 18:38:56,538:INFO:             pycaret: 3.3.2
2025-08-25 18:38:56,538:INFO:             IPython: 9.4.0
2025-08-25 18:38:56,538:INFO:          ipywidgets: 8.1.7
2025-08-25 18:38:56,538:INFO:                tqdm: 4.67.1
2025-08-25 18:38:56,538:INFO:               numpy: 1.26.4
2025-08-25 18:38:56,539:INFO:              pandas: 2.1.4
2025-08-25 18:38:56,539:INFO:              jinja2: 3.1.6
2025-08-25 18:38:56,539:INFO:               scipy: 1.11.4
2025-08-25 18:38:56,539:INFO:              joblib: 1.3.2
2025-08-25 18:38:56,539:INFO:             sklearn: 1.4.2
2025-08-25 18:38:56,539:INFO:                pyod: 2.0.5
2025-08-25 18:38:56,539:INFO:            imblearn: 0.14.0
2025-08-25 18:38:56,539:INFO:   category_encoders: 2.7.0
2025-08-25 18:38:56,539:INFO:            lightgbm: 4.6.0
2025-08-25 18:38:56,539:INFO:               numba: 0.61.2
2025-08-25 18:38:56,539:INFO:            requests: 2.32.5
2025-08-25 18:38:56,539:INFO:          matplotlib: 3.7.5
2025-08-25 18:38:56,539:INFO:          scikitplot: 0.3.7
2025-08-25 18:38:56,539:INFO:         yellowbrick: 1.5
2025-08-25 18:38:56,539:INFO:              plotly: 5.24.1
2025-08-25 18:38:56,539:INFO:    plotly-resampler: Not installed
2025-08-25 18:38:56,539:INFO:             kaleido: 1.0.0
2025-08-25 18:38:56,539:INFO:           schemdraw: 0.15
2025-08-25 18:38:56,539:INFO:         statsmodels: 0.14.5
2025-08-25 18:38:56,539:INFO:              sktime: 0.26.0
2025-08-25 18:38:56,539:INFO:               tbats: 1.1.3
2025-08-25 18:38:56,539:INFO:            pmdarima: 2.0.4
2025-08-25 18:38:56,540:INFO:              psutil: 7.0.0
2025-08-25 18:38:56,540:INFO:          markupsafe: 3.0.2
2025-08-25 18:38:56,540:INFO:             pickle5: Not installed
2025-08-25 18:38:56,540:INFO:         cloudpickle: 3.1.1
2025-08-25 18:38:56,540:INFO:         deprecation: 2.1.0
2025-08-25 18:38:56,540:INFO:              xxhash: 3.5.0
2025-08-25 18:38:56,540:INFO:           wurlitzer: Not installed
2025-08-25 18:38:56,540:INFO:PyCaret optional dependencies:
2025-08-25 18:38:56,540:INFO:                shap: Not installed
2025-08-25 18:38:56,540:INFO:           interpret: Not installed
2025-08-25 18:38:56,540:INFO:                umap: Not installed
2025-08-25 18:38:56,540:INFO:     ydata_profiling: Not installed
2025-08-25 18:38:56,540:INFO:  explainerdashboard: Not installed
2025-08-25 18:38:56,540:INFO:             autoviz: Not installed
2025-08-25 18:38:56,540:INFO:           fairlearn: Not installed
2025-08-25 18:38:56,540:INFO:          deepchecks: Not installed
2025-08-25 18:38:56,540:INFO:             xgboost: Not installed
2025-08-25 18:38:56,540:INFO:            catboost: Not installed
2025-08-25 18:38:56,540:INFO:              kmodes: Not installed
2025-08-25 18:38:56,540:INFO:             mlxtend: Not installed
2025-08-25 18:38:56,540:INFO:       statsforecast: Not installed
2025-08-25 18:38:56,540:INFO:        tune_sklearn: Not installed
2025-08-25 18:38:56,540:INFO:                 ray: Not installed
2025-08-25 18:38:56,540:INFO:            hyperopt: Not installed
2025-08-25 18:38:56,541:INFO:              optuna: Not installed
2025-08-25 18:38:56,541:INFO:               skopt: Not installed
2025-08-25 18:38:56,541:INFO:              mlflow: Not installed
2025-08-25 18:38:56,541:INFO:              gradio: Not installed
2025-08-25 18:38:56,541:INFO:             fastapi: Not installed
2025-08-25 18:38:56,541:INFO:             uvicorn: Not installed
2025-08-25 18:38:56,541:INFO:              m2cgen: Not installed
2025-08-25 18:38:56,541:INFO:           evidently: Not installed
2025-08-25 18:38:56,541:INFO:               fugue: Not installed
2025-08-25 18:38:56,541:INFO:           streamlit: Not installed
2025-08-25 18:38:56,541:INFO:             prophet: Not installed
2025-08-25 18:38:56,541:INFO:None
2025-08-25 18:38:56,541:INFO:Set up data.
2025-08-25 18:38:56,542:INFO:Set up folding strategy.
2025-08-25 18:39:25,358:INFO:PyCaret ClassificationExperiment
2025-08-25 18:39:25,359:INFO:Logging name: clf-default-name
2025-08-25 18:39:25,359:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-25 18:39:25,359:INFO:version 3.3.2
2025-08-25 18:39:25,359:INFO:Initializing setup()
2025-08-25 18:39:25,359:INFO:self.USI: 749f
2025-08-25 18:39:25,359:INFO:self._variable_keys: {'html_param', 'data', 'X_train', 'idx', 'gpu_n_jobs_param', 'target_param', 'y_train', 'pipeline', 'gpu_param', 'X_test', 'n_jobs_param', 'exp_name_log', 'fold_shuffle_param', 'exp_id', 'is_multiclass', '_available_plots', 'seed', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'memory', 'USI', 'fold_generator', 'logging_param', 'y', 'X', 'y_test', 'fix_imbalance'}
2025-08-25 18:39:25,359:INFO:Checking environment
2025-08-25 18:39:25,359:INFO:python_version: 3.11.9
2025-08-25 18:39:25,359:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-25 18:39:25,359:INFO:machine: AMD64
2025-08-25 18:39:25,359:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-25 18:39:25,361:INFO:Memory: svmem(total=17024348160, available=2245017600, percent=86.8, used=14779330560, free=2245017600)
2025-08-25 18:39:25,361:INFO:Physical Core: 4
2025-08-25 18:39:25,361:INFO:Logical Core: 8
2025-08-25 18:39:25,361:INFO:Checking libraries
2025-08-25 18:39:25,361:INFO:System:
2025-08-25 18:39:25,361:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-25 18:39:25,361:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-25 18:39:25,361:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-25 18:39:25,361:INFO:PyCaret required dependencies:
2025-08-25 18:39:25,361:INFO:                 pip: Not installed
2025-08-25 18:39:25,361:INFO:          setuptools: 80.9.0
2025-08-25 18:39:25,361:INFO:             pycaret: 3.3.2
2025-08-25 18:39:25,361:INFO:             IPython: 9.4.0
2025-08-25 18:39:25,361:INFO:          ipywidgets: 8.1.7
2025-08-25 18:39:25,361:INFO:                tqdm: 4.67.1
2025-08-25 18:39:25,361:INFO:               numpy: 1.26.4
2025-08-25 18:39:25,361:INFO:              pandas: 2.1.4
2025-08-25 18:39:25,361:INFO:              jinja2: 3.1.6
2025-08-25 18:39:25,361:INFO:               scipy: 1.11.4
2025-08-25 18:39:25,361:INFO:              joblib: 1.3.2
2025-08-25 18:39:25,361:INFO:             sklearn: 1.4.2
2025-08-25 18:39:25,361:INFO:                pyod: 2.0.5
2025-08-25 18:39:25,361:INFO:            imblearn: 0.14.0
2025-08-25 18:39:25,361:INFO:   category_encoders: 2.7.0
2025-08-25 18:39:25,361:INFO:            lightgbm: 4.6.0
2025-08-25 18:39:25,361:INFO:               numba: 0.61.2
2025-08-25 18:39:25,361:INFO:            requests: 2.32.5
2025-08-25 18:39:25,364:INFO:          matplotlib: 3.7.5
2025-08-25 18:39:25,364:INFO:          scikitplot: 0.3.7
2025-08-25 18:39:25,364:INFO:         yellowbrick: 1.5
2025-08-25 18:39:25,364:INFO:              plotly: 5.24.1
2025-08-25 18:39:25,364:INFO:    plotly-resampler: Not installed
2025-08-25 18:39:25,364:INFO:             kaleido: 1.0.0
2025-08-25 18:39:25,364:INFO:           schemdraw: 0.15
2025-08-25 18:39:25,364:INFO:         statsmodels: 0.14.5
2025-08-25 18:39:25,364:INFO:              sktime: 0.26.0
2025-08-25 18:39:25,364:INFO:               tbats: 1.1.3
2025-08-25 18:39:25,364:INFO:            pmdarima: 2.0.4
2025-08-25 18:39:25,364:INFO:              psutil: 7.0.0
2025-08-25 18:39:25,364:INFO:          markupsafe: 3.0.2
2025-08-25 18:39:25,364:INFO:             pickle5: Not installed
2025-08-25 18:39:25,364:INFO:         cloudpickle: 3.1.1
2025-08-25 18:39:25,364:INFO:         deprecation: 2.1.0
2025-08-25 18:39:25,364:INFO:              xxhash: 3.5.0
2025-08-25 18:39:25,364:INFO:           wurlitzer: Not installed
2025-08-25 18:39:25,364:INFO:PyCaret optional dependencies:
2025-08-25 18:39:25,365:INFO:                shap: Not installed
2025-08-25 18:39:25,365:INFO:           interpret: Not installed
2025-08-25 18:39:25,365:INFO:                umap: Not installed
2025-08-25 18:39:25,365:INFO:     ydata_profiling: Not installed
2025-08-25 18:39:25,365:INFO:  explainerdashboard: Not installed
2025-08-25 18:39:25,365:INFO:             autoviz: Not installed
2025-08-25 18:39:25,365:INFO:           fairlearn: Not installed
2025-08-25 18:39:25,365:INFO:          deepchecks: Not installed
2025-08-25 18:39:25,365:INFO:             xgboost: Not installed
2025-08-25 18:39:25,365:INFO:            catboost: Not installed
2025-08-25 18:39:25,365:INFO:              kmodes: Not installed
2025-08-25 18:39:25,365:INFO:             mlxtend: Not installed
2025-08-25 18:39:25,365:INFO:       statsforecast: Not installed
2025-08-25 18:39:25,365:INFO:        tune_sklearn: Not installed
2025-08-25 18:39:25,365:INFO:                 ray: Not installed
2025-08-25 18:39:25,366:INFO:            hyperopt: Not installed
2025-08-25 18:39:25,366:INFO:              optuna: Not installed
2025-08-25 18:39:25,366:INFO:               skopt: Not installed
2025-08-25 18:39:25,366:INFO:              mlflow: Not installed
2025-08-25 18:39:25,366:INFO:              gradio: Not installed
2025-08-25 18:39:25,366:INFO:             fastapi: Not installed
2025-08-25 18:39:25,366:INFO:             uvicorn: Not installed
2025-08-25 18:39:25,367:INFO:              m2cgen: Not installed
2025-08-25 18:39:25,367:INFO:           evidently: Not installed
2025-08-25 18:39:25,367:INFO:               fugue: Not installed
2025-08-25 18:39:25,367:INFO:           streamlit: Not installed
2025-08-25 18:39:25,367:INFO:             prophet: Not installed
2025-08-25 18:39:25,367:INFO:None
2025-08-25 18:39:25,367:INFO:Set up data.
2025-08-25 18:39:25,368:INFO:Set up folding strategy.
2025-08-25 18:39:25,368:INFO:Set up train/test split.
2025-08-25 18:39:41,670:INFO:PyCaret ClassificationExperiment
2025-08-25 18:39:41,670:INFO:Logging name: clf-default-name
2025-08-25 18:39:41,670:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-25 18:39:41,670:INFO:version 3.3.2
2025-08-25 18:39:41,671:INFO:Initializing setup()
2025-08-25 18:39:41,671:INFO:self.USI: fa28
2025-08-25 18:39:41,671:INFO:self._variable_keys: {'html_param', 'data', 'X_train', 'idx', 'gpu_n_jobs_param', 'target_param', 'y_train', 'pipeline', 'gpu_param', 'X_test', 'n_jobs_param', 'exp_name_log', 'fold_shuffle_param', 'exp_id', 'is_multiclass', '_available_plots', 'seed', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'memory', 'USI', 'fold_generator', 'logging_param', 'y', 'X', 'y_test', 'fix_imbalance'}
2025-08-25 18:39:41,671:INFO:Checking environment
2025-08-25 18:39:41,671:INFO:python_version: 3.11.9
2025-08-25 18:39:41,671:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-25 18:39:41,671:INFO:machine: AMD64
2025-08-25 18:39:41,671:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-25 18:39:41,674:INFO:Memory: svmem(total=17024348160, available=2254721024, percent=86.8, used=14769627136, free=2254721024)
2025-08-25 18:39:41,674:INFO:Physical Core: 4
2025-08-25 18:39:41,674:INFO:Logical Core: 8
2025-08-25 18:39:41,675:INFO:Checking libraries
2025-08-25 18:39:41,675:INFO:System:
2025-08-25 18:39:41,675:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-25 18:39:41,675:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-25 18:39:41,675:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-25 18:39:41,675:INFO:PyCaret required dependencies:
2025-08-25 18:39:41,675:INFO:                 pip: Not installed
2025-08-25 18:39:41,675:INFO:          setuptools: 80.9.0
2025-08-25 18:39:41,675:INFO:             pycaret: 3.3.2
2025-08-25 18:39:41,675:INFO:             IPython: 9.4.0
2025-08-25 18:39:41,675:INFO:          ipywidgets: 8.1.7
2025-08-25 18:39:41,675:INFO:                tqdm: 4.67.1
2025-08-25 18:39:41,675:INFO:               numpy: 1.26.4
2025-08-25 18:39:41,675:INFO:              pandas: 2.1.4
2025-08-25 18:39:41,675:INFO:              jinja2: 3.1.6
2025-08-25 18:39:41,675:INFO:               scipy: 1.11.4
2025-08-25 18:39:41,675:INFO:              joblib: 1.3.2
2025-08-25 18:39:41,675:INFO:             sklearn: 1.4.2
2025-08-25 18:39:41,675:INFO:                pyod: 2.0.5
2025-08-25 18:39:41,675:INFO:            imblearn: 0.14.0
2025-08-25 18:39:41,675:INFO:   category_encoders: 2.7.0
2025-08-25 18:39:41,675:INFO:            lightgbm: 4.6.0
2025-08-25 18:39:41,675:INFO:               numba: 0.61.2
2025-08-25 18:39:41,675:INFO:            requests: 2.32.5
2025-08-25 18:39:41,675:INFO:          matplotlib: 3.7.5
2025-08-25 18:39:41,675:INFO:          scikitplot: 0.3.7
2025-08-25 18:39:41,675:INFO:         yellowbrick: 1.5
2025-08-25 18:39:41,675:INFO:              plotly: 5.24.1
2025-08-25 18:39:41,675:INFO:    plotly-resampler: Not installed
2025-08-25 18:39:41,675:INFO:             kaleido: 1.0.0
2025-08-25 18:39:41,675:INFO:           schemdraw: 0.15
2025-08-25 18:39:41,675:INFO:         statsmodels: 0.14.5
2025-08-25 18:39:41,675:INFO:              sktime: 0.26.0
2025-08-25 18:39:41,675:INFO:               tbats: 1.1.3
2025-08-25 18:39:41,675:INFO:            pmdarima: 2.0.4
2025-08-25 18:39:41,675:INFO:              psutil: 7.0.0
2025-08-25 18:39:41,675:INFO:          markupsafe: 3.0.2
2025-08-25 18:39:41,675:INFO:             pickle5: Not installed
2025-08-25 18:39:41,678:INFO:         cloudpickle: 3.1.1
2025-08-25 18:39:41,678:INFO:         deprecation: 2.1.0
2025-08-25 18:39:41,678:INFO:              xxhash: 3.5.0
2025-08-25 18:39:41,678:INFO:           wurlitzer: Not installed
2025-08-25 18:39:41,678:INFO:PyCaret optional dependencies:
2025-08-25 18:39:41,678:INFO:                shap: Not installed
2025-08-25 18:39:41,678:INFO:           interpret: Not installed
2025-08-25 18:39:41,678:INFO:                umap: Not installed
2025-08-25 18:39:41,678:INFO:     ydata_profiling: Not installed
2025-08-25 18:39:41,678:INFO:  explainerdashboard: Not installed
2025-08-25 18:39:41,678:INFO:             autoviz: Not installed
2025-08-25 18:39:41,678:INFO:           fairlearn: Not installed
2025-08-25 18:39:41,678:INFO:          deepchecks: Not installed
2025-08-25 18:39:41,678:INFO:             xgboost: Not installed
2025-08-25 18:39:41,678:INFO:            catboost: Not installed
2025-08-25 18:39:41,678:INFO:              kmodes: Not installed
2025-08-25 18:39:41,678:INFO:             mlxtend: Not installed
2025-08-25 18:39:41,678:INFO:       statsforecast: Not installed
2025-08-25 18:39:41,678:INFO:        tune_sklearn: Not installed
2025-08-25 18:39:41,678:INFO:                 ray: Not installed
2025-08-25 18:39:41,678:INFO:            hyperopt: Not installed
2025-08-25 18:39:41,678:INFO:              optuna: Not installed
2025-08-25 18:39:41,679:INFO:               skopt: Not installed
2025-08-25 18:39:41,679:INFO:              mlflow: Not installed
2025-08-25 18:39:41,679:INFO:              gradio: Not installed
2025-08-25 18:39:41,679:INFO:             fastapi: Not installed
2025-08-25 18:39:41,679:INFO:             uvicorn: Not installed
2025-08-25 18:39:41,679:INFO:              m2cgen: Not installed
2025-08-25 18:39:41,679:INFO:           evidently: Not installed
2025-08-25 18:39:41,679:INFO:               fugue: Not installed
2025-08-25 18:39:41,679:INFO:           streamlit: Not installed
2025-08-25 18:39:41,679:INFO:             prophet: Not installed
2025-08-25 18:39:41,679:INFO:None
2025-08-25 18:39:41,680:INFO:Set up data.
2025-08-25 18:39:41,684:INFO:Set up folding strategy.
2025-08-25 18:39:41,684:INFO:Set up train/test split.
2025-08-25 18:39:56,606:INFO:PyCaret ClassificationExperiment
2025-08-25 18:39:56,607:INFO:Logging name: clf-default-name
2025-08-25 18:39:56,607:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-25 18:39:56,607:INFO:version 3.3.2
2025-08-25 18:39:56,607:INFO:Initializing setup()
2025-08-25 18:39:56,607:INFO:self.USI: d11d
2025-08-25 18:39:56,607:INFO:self._variable_keys: {'html_param', 'data', 'X_train', 'idx', 'gpu_n_jobs_param', 'target_param', 'y_train', 'pipeline', 'gpu_param', 'X_test', 'n_jobs_param', 'exp_name_log', 'fold_shuffle_param', 'exp_id', 'is_multiclass', '_available_plots', 'seed', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'memory', 'USI', 'fold_generator', 'logging_param', 'y', 'X', 'y_test', 'fix_imbalance'}
2025-08-25 18:39:56,608:INFO:Checking environment
2025-08-25 18:39:56,608:INFO:python_version: 3.11.9
2025-08-25 18:39:56,608:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-25 18:39:56,608:INFO:machine: AMD64
2025-08-25 18:39:56,608:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-25 18:39:56,611:INFO:Memory: svmem(total=17024348160, available=2236153856, percent=86.9, used=14788194304, free=2236153856)
2025-08-25 18:39:56,611:INFO:Physical Core: 4
2025-08-25 18:39:56,611:INFO:Logical Core: 8
2025-08-25 18:39:56,611:INFO:Checking libraries
2025-08-25 18:39:56,614:INFO:System:
2025-08-25 18:39:56,614:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-25 18:39:56,614:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-25 18:39:56,615:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-25 18:39:56,615:INFO:PyCaret required dependencies:
2025-08-25 18:39:56,615:INFO:                 pip: Not installed
2025-08-25 18:39:56,615:INFO:          setuptools: 80.9.0
2025-08-25 18:39:56,616:INFO:             pycaret: 3.3.2
2025-08-25 18:39:56,616:INFO:             IPython: 9.4.0
2025-08-25 18:39:56,616:INFO:          ipywidgets: 8.1.7
2025-08-25 18:39:56,616:INFO:                tqdm: 4.67.1
2025-08-25 18:39:56,616:INFO:               numpy: 1.26.4
2025-08-25 18:39:56,616:INFO:              pandas: 2.1.4
2025-08-25 18:39:56,616:INFO:              jinja2: 3.1.6
2025-08-25 18:39:56,616:INFO:               scipy: 1.11.4
2025-08-25 18:39:56,617:INFO:              joblib: 1.3.2
2025-08-25 18:39:56,617:INFO:             sklearn: 1.4.2
2025-08-25 18:39:56,618:INFO:                pyod: 2.0.5
2025-08-25 18:39:56,618:INFO:            imblearn: 0.14.0
2025-08-25 18:39:56,618:INFO:   category_encoders: 2.7.0
2025-08-25 18:39:56,618:INFO:            lightgbm: 4.6.0
2025-08-25 18:39:56,618:INFO:               numba: 0.61.2
2025-08-25 18:39:56,618:INFO:            requests: 2.32.5
2025-08-25 18:39:56,618:INFO:          matplotlib: 3.7.5
2025-08-25 18:39:56,618:INFO:          scikitplot: 0.3.7
2025-08-25 18:39:56,618:INFO:         yellowbrick: 1.5
2025-08-25 18:39:56,619:INFO:              plotly: 5.24.1
2025-08-25 18:39:56,619:INFO:    plotly-resampler: Not installed
2025-08-25 18:39:56,619:INFO:             kaleido: 1.0.0
2025-08-25 18:39:56,619:INFO:           schemdraw: 0.15
2025-08-25 18:39:56,619:INFO:         statsmodels: 0.14.5
2025-08-25 18:39:56,619:INFO:              sktime: 0.26.0
2025-08-25 18:39:56,619:INFO:               tbats: 1.1.3
2025-08-25 18:39:56,619:INFO:            pmdarima: 2.0.4
2025-08-25 18:39:56,619:INFO:              psutil: 7.0.0
2025-08-25 18:39:56,619:INFO:          markupsafe: 3.0.2
2025-08-25 18:39:56,619:INFO:             pickle5: Not installed
2025-08-25 18:39:56,619:INFO:         cloudpickle: 3.1.1
2025-08-25 18:39:56,619:INFO:         deprecation: 2.1.0
2025-08-25 18:39:56,619:INFO:              xxhash: 3.5.0
2025-08-25 18:39:56,619:INFO:           wurlitzer: Not installed
2025-08-25 18:39:56,619:INFO:PyCaret optional dependencies:
2025-08-25 18:39:56,619:INFO:                shap: Not installed
2025-08-25 18:39:56,619:INFO:           interpret: Not installed
2025-08-25 18:39:56,619:INFO:                umap: Not installed
2025-08-25 18:39:56,619:INFO:     ydata_profiling: Not installed
2025-08-25 18:39:56,619:INFO:  explainerdashboard: Not installed
2025-08-25 18:39:56,622:INFO:             autoviz: Not installed
2025-08-25 18:39:56,622:INFO:           fairlearn: Not installed
2025-08-25 18:39:56,622:INFO:          deepchecks: Not installed
2025-08-25 18:39:56,622:INFO:             xgboost: Not installed
2025-08-25 18:39:56,622:INFO:            catboost: Not installed
2025-08-25 18:39:56,622:INFO:              kmodes: Not installed
2025-08-25 18:39:56,622:INFO:             mlxtend: Not installed
2025-08-25 18:39:56,622:INFO:       statsforecast: Not installed
2025-08-25 18:39:56,623:INFO:        tune_sklearn: Not installed
2025-08-25 18:39:56,623:INFO:                 ray: Not installed
2025-08-25 18:39:56,623:INFO:            hyperopt: Not installed
2025-08-25 18:39:56,623:INFO:              optuna: Not installed
2025-08-25 18:39:56,623:INFO:               skopt: Not installed
2025-08-25 18:39:56,623:INFO:              mlflow: Not installed
2025-08-25 18:39:56,623:INFO:              gradio: Not installed
2025-08-25 18:39:56,623:INFO:             fastapi: Not installed
2025-08-25 18:39:56,623:INFO:             uvicorn: Not installed
2025-08-25 18:39:56,623:INFO:              m2cgen: Not installed
2025-08-25 18:39:56,623:INFO:           evidently: Not installed
2025-08-25 18:39:56,623:INFO:               fugue: Not installed
2025-08-25 18:39:56,623:INFO:           streamlit: Not installed
2025-08-25 18:39:56,623:INFO:             prophet: Not installed
2025-08-25 18:39:56,623:INFO:None
2025-08-25 18:39:56,624:INFO:Set up data.
2025-08-25 18:39:56,632:INFO:Set up folding strategy.
2025-08-25 18:39:56,632:INFO:Set up train/test split.
2025-08-27 21:20:29,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 21:20:29,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 21:20:29,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 21:20:29,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 21:20:33,626:INFO:PyCaret ClassificationExperiment
2025-08-27 21:20:33,626:INFO:Logging name: clf-default-name
2025-08-27 21:20:33,626:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 21:20:33,626:INFO:version 3.3.2
2025-08-27 21:20:33,627:INFO:Initializing setup()
2025-08-27 21:20:33,627:INFO:self.USI: b112
2025-08-27 21:20:33,627:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 21:20:33,627:INFO:Checking environment
2025-08-27 21:20:33,627:INFO:python_version: 3.11.9
2025-08-27 21:20:33,627:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 21:20:33,627:INFO:machine: AMD64
2025-08-27 21:20:33,627:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 21:20:33,631:INFO:Memory: svmem(total=17024348160, available=1321574400, percent=92.2, used=15702773760, free=1321574400)
2025-08-27 21:20:33,631:INFO:Physical Core: 4
2025-08-27 21:20:33,631:INFO:Logical Core: 8
2025-08-27 21:20:33,631:INFO:Checking libraries
2025-08-27 21:20:33,631:INFO:System:
2025-08-27 21:20:33,631:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 21:20:33,631:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 21:20:33,631:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 21:20:33,631:INFO:PyCaret required dependencies:
2025-08-27 21:20:33,640:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
2025-08-27 21:20:33,640:WARNING:  warnings.warn(
2025-08-27 21:20:33,751:INFO:                 pip: Not installed
2025-08-27 21:20:33,751:INFO:          setuptools: 80.9.0
2025-08-27 21:20:33,751:INFO:             pycaret: 3.3.2
2025-08-27 21:20:33,751:INFO:             IPython: 9.4.0
2025-08-27 21:20:33,751:INFO:          ipywidgets: 8.1.7
2025-08-27 21:20:33,752:INFO:                tqdm: 4.67.1
2025-08-27 21:20:33,752:INFO:               numpy: 1.26.4
2025-08-27 21:20:33,752:INFO:              pandas: 2.1.4
2025-08-27 21:20:33,752:INFO:              jinja2: 3.1.6
2025-08-27 21:20:33,752:INFO:               scipy: 1.11.4
2025-08-27 21:20:33,752:INFO:              joblib: 1.3.2
2025-08-27 21:20:33,752:INFO:             sklearn: 1.4.2
2025-08-27 21:20:33,752:INFO:                pyod: 2.0.5
2025-08-27 21:20:33,752:INFO:            imblearn: 0.14.0
2025-08-27 21:20:33,752:INFO:   category_encoders: 2.7.0
2025-08-27 21:20:33,752:INFO:            lightgbm: 4.6.0
2025-08-27 21:20:33,752:INFO:               numba: 0.61.2
2025-08-27 21:20:33,752:INFO:            requests: 2.32.5
2025-08-27 21:20:33,752:INFO:          matplotlib: 3.7.5
2025-08-27 21:20:33,752:INFO:          scikitplot: 0.3.7
2025-08-27 21:20:33,752:INFO:         yellowbrick: 1.5
2025-08-27 21:20:33,752:INFO:              plotly: 5.24.1
2025-08-27 21:20:33,753:INFO:    plotly-resampler: Not installed
2025-08-27 21:20:33,753:INFO:             kaleido: 1.0.0
2025-08-27 21:20:33,753:INFO:           schemdraw: 0.15
2025-08-27 21:20:33,753:INFO:         statsmodels: 0.14.5
2025-08-27 21:20:33,753:INFO:              sktime: 0.26.0
2025-08-27 21:20:33,753:INFO:               tbats: 1.1.3
2025-08-27 21:20:33,753:INFO:            pmdarima: 2.0.4
2025-08-27 21:20:33,753:INFO:              psutil: 7.0.0
2025-08-27 21:20:33,753:INFO:          markupsafe: 3.0.2
2025-08-27 21:20:33,753:INFO:             pickle5: Not installed
2025-08-27 21:20:33,753:INFO:         cloudpickle: 3.1.1
2025-08-27 21:20:33,753:INFO:         deprecation: 2.1.0
2025-08-27 21:20:33,753:INFO:              xxhash: 3.5.0
2025-08-27 21:20:33,753:INFO:           wurlitzer: Not installed
2025-08-27 21:20:33,753:INFO:PyCaret optional dependencies:
2025-08-27 21:20:33,774:INFO:                shap: Not installed
2025-08-27 21:20:33,774:INFO:           interpret: Not installed
2025-08-27 21:20:33,774:INFO:                umap: Not installed
2025-08-27 21:20:33,774:INFO:     ydata_profiling: Not installed
2025-08-27 21:20:33,774:INFO:  explainerdashboard: Not installed
2025-08-27 21:20:33,774:INFO:             autoviz: Not installed
2025-08-27 21:20:33,774:INFO:           fairlearn: Not installed
2025-08-27 21:20:33,774:INFO:          deepchecks: Not installed
2025-08-27 21:20:33,774:INFO:             xgboost: Not installed
2025-08-27 21:20:33,774:INFO:            catboost: Not installed
2025-08-27 21:20:33,774:INFO:              kmodes: Not installed
2025-08-27 21:20:33,774:INFO:             mlxtend: Not installed
2025-08-27 21:20:33,774:INFO:       statsforecast: Not installed
2025-08-27 21:20:33,774:INFO:        tune_sklearn: Not installed
2025-08-27 21:20:33,774:INFO:                 ray: Not installed
2025-08-27 21:20:33,774:INFO:            hyperopt: Not installed
2025-08-27 21:20:33,774:INFO:              optuna: Not installed
2025-08-27 21:20:33,774:INFO:               skopt: Not installed
2025-08-27 21:20:33,774:INFO:              mlflow: Not installed
2025-08-27 21:20:33,774:INFO:              gradio: Not installed
2025-08-27 21:20:33,774:INFO:             fastapi: Not installed
2025-08-27 21:20:33,774:INFO:             uvicorn: Not installed
2025-08-27 21:20:33,774:INFO:              m2cgen: Not installed
2025-08-27 21:20:33,774:INFO:           evidently: Not installed
2025-08-27 21:20:33,774:INFO:               fugue: Not installed
2025-08-27 21:20:33,774:INFO:           streamlit: Not installed
2025-08-27 21:20:33,774:INFO:             prophet: Not installed
2025-08-27 21:20:33,774:INFO:None
2025-08-27 21:20:33,774:INFO:Set up data.
2025-08-27 21:20:33,784:INFO:Set up folding strategy.
2025-08-27 21:20:33,785:INFO:Set up train/test split.
2025-08-27 21:20:33,794:INFO:Set up index.
2025-08-27 21:20:33,797:INFO:Assigning column types.
2025-08-27 21:20:33,803:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 21:20:33,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:20:33,892:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:20:34,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:20:34,110:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:20:34,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,142:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 21:20:34,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:20:34,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,324:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:20:34,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,358:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 21:20:34,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:34,640:INFO:Preparing preprocessing pipeline...
2025-08-27 21:20:34,648:INFO:Set up simple imputation.
2025-08-27 21:20:34,711:INFO:Finished creating preprocessing pipeline.
2025-08-27 21:20:34,773:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-27 21:20:34,773:INFO:Creating final display dataframe.
2025-08-27 21:20:34,944:INFO:Setup _display_container:                     Description             Value
0                    Session id                 0
1                        Target           failure
2                   Target type            Binary
3           Original data shape          (989, 6)
4        Transformed data shape          (989, 6)
5   Transformed train set shape          (692, 6)
6    Transformed test set shape          (297, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              b112
2025-08-27 21:20:35,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:35,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:35,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:35,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:20:35,326:INFO:setup() successfully completed in 1.71s...............
2025-08-27 21:28:59,617:INFO:Initializing compare_models()
2025-08-27 21:28:59,617:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-27 21:28:59,617:INFO:Checking exceptions
2025-08-27 21:28:59,632:INFO:Preparing display monitor
2025-08-27 21:28:59,723:INFO:Initializing Logistic Regression
2025-08-27 21:28:59,723:INFO:Total runtime is 6.842613220214844e-06 minutes
2025-08-27 21:28:59,738:INFO:SubProcess create_model() called ==================================
2025-08-27 21:28:59,739:INFO:Initializing create_model()
2025-08-27 21:28:59,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:28:59,739:INFO:Checking exceptions
2025-08-27 21:28:59,740:INFO:Importing libraries
2025-08-27 21:28:59,740:INFO:Copying training dataset
2025-08-27 21:28:59,751:INFO:Defining folds
2025-08-27 21:28:59,752:INFO:Declaring metric variables
2025-08-27 21:28:59,763:INFO:Importing untrained model
2025-08-27 21:28:59,770:INFO:Logistic Regression Imported successfully
2025-08-27 21:28:59,785:INFO:Starting cross validation
2025-08-27 21:28:59,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:28:59,847:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:28:59,847:WARNING:  warnings.warn(
2025-08-27 21:29:06,651:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:29:06,654:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:29:06,741:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:29:06,841:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:29:06,872:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:29:06,899:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:29:07,015:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:29:07,233:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:29:07,347:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,348:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,385:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,389:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,394:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,394:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,400:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,401:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,402:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,402:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,406:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,406:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,407:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,410:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,410:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,410:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,418:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,421:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,424:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,427:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,428:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,429:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,429:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,429:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,434:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,435:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,435:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,436:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,441:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,442:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,451:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,460:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,557:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,562:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,572:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,578:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,580:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,580:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,580:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,583:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,585:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,594:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,604:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,607:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,608:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,613:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,662:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,672:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,676:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,678:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,678:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,680:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,774:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:07,783:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,795:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,813:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:07,817:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,817:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:07,831:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:07,840:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 21:29:07,843:WARNING:1 fits failed out of a total of 10.
2025-08-27 21:29:07,843:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 21:29:07,843:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 21:29:07,843:WARNING:
2025-08-27 21:29:07,843:WARNING:Below are more details about the failures:
2025-08-27 21:29:07,844:WARNING:--------------------------------------------------------------------------------
2025-08-27 21:29:07,844:WARNING:1 fits failed with the following error:
2025-08-27 21:29:07,844:WARNING:Traceback (most recent call last):
2025-08-27 21:29:07,844:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 21:29:07,844:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 21:29:07,844:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 21:29:07,845:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 21:29:07,845:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 21:29:07,845:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 21:29:07,845:WARNING:    return self.func(*args, **kwargs)
2025-08-27 21:29:07,845:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:29:07,845:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 21:29:07,845:WARNING:    transformer.fit(*args)
2025-08-27 21:29:07,845:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 21:29:07,845:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 21:29:07,845:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:29:07,845:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py", line 1246, in fit
2025-08-27 21:29:07,845:WARNING:    raise ValueError(
2025-08-27 21:29:07,845:WARNING:ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: False
2025-08-27 21:29:07,846:WARNING:
2025-08-27 21:29:07,846:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 21:29:07,846:INFO:Calculating mean and std
2025-08-27 21:29:07,848:INFO:Creating metrics dataframe
2025-08-27 21:29:07,858:INFO:Uploading results into container
2025-08-27 21:29:07,859:INFO:Uploading model into container now
2025-08-27 21:29:07,861:INFO:_master_model_container: 1
2025-08-27 21:29:07,861:INFO:_display_container: 2
2025-08-27 21:29:07,863:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 21:29:07,863:INFO:create_model() successfully completed......................................
2025-08-27 21:29:07,966:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:07,966:INFO:Creating metrics dataframe
2025-08-27 21:29:07,976:INFO:Initializing K Neighbors Classifier
2025-08-27 21:29:07,976:INFO:Total runtime is 0.13755658864974973 minutes
2025-08-27 21:29:07,982:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:07,983:INFO:Initializing create_model()
2025-08-27 21:29:07,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:07,983:INFO:Checking exceptions
2025-08-27 21:29:07,983:INFO:Importing libraries
2025-08-27 21:29:07,983:INFO:Copying training dataset
2025-08-27 21:29:07,991:INFO:Defining folds
2025-08-27 21:29:07,991:INFO:Declaring metric variables
2025-08-27 21:29:08,000:INFO:Importing untrained model
2025-08-27 21:29:08,007:INFO:K Neighbors Classifier Imported successfully
2025-08-27 21:29:08,022:INFO:Starting cross validation
2025-08-27 21:29:08,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:08,032:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:08,032:WARNING:  warnings.warn(
2025-08-27 21:29:08,239:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,239:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,240:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,242:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,245:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,246:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,246:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,256:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,258:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,258:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,259:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,259:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,261:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,261:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,262:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,262:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,263:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:29:08,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,264:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,264:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,264:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,264:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,264:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,264:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,269:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,269:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,269:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,272:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,272:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,276:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,276:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,278:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,278:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,280:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,283:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,283:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,291:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,297:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,299:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,299:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,304:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,343:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,347:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,347:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,352:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,352:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,360:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,360:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,361:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,364:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,364:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,364:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,365:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,372:INFO:Calculating mean and std
2025-08-27 21:29:08,374:INFO:Creating metrics dataframe
2025-08-27 21:29:08,379:INFO:Uploading results into container
2025-08-27 21:29:08,379:INFO:Uploading model into container now
2025-08-27 21:29:08,380:INFO:_master_model_container: 2
2025-08-27 21:29:08,380:INFO:_display_container: 2
2025-08-27 21:29:08,380:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 21:29:08,381:INFO:create_model() successfully completed......................................
2025-08-27 21:29:08,460:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:08,461:INFO:Creating metrics dataframe
2025-08-27 21:29:08,471:INFO:Initializing Naive Bayes
2025-08-27 21:29:08,471:INFO:Total runtime is 0.1458065907160441 minutes
2025-08-27 21:29:08,476:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:08,477:INFO:Initializing create_model()
2025-08-27 21:29:08,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:08,477:INFO:Checking exceptions
2025-08-27 21:29:08,477:INFO:Importing libraries
2025-08-27 21:29:08,477:INFO:Copying training dataset
2025-08-27 21:29:08,484:INFO:Defining folds
2025-08-27 21:29:08,484:INFO:Declaring metric variables
2025-08-27 21:29:08,493:INFO:Importing untrained model
2025-08-27 21:29:08,500:INFO:Naive Bayes Imported successfully
2025-08-27 21:29:08,514:INFO:Starting cross validation
2025-08-27 21:29:08,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:08,522:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:08,522:WARNING:  warnings.warn(
2025-08-27 21:29:08,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:29:08,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,586:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,587:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,591:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,591:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,594:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,594:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,594:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,594:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,594:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,599:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,600:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,600:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,600:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,605:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,606:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,606:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,608:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,608:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,608:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,608:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,608:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,608:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,608:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,614:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,615:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,615:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,617:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,618:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,623:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,625:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,630:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,631:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,639:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,640:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,640:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,644:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,645:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,645:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,645:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,645:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,645:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,645:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,650:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,650:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,651:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,651:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,657:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,657:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,665:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,672:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,676:INFO:Calculating mean and std
2025-08-27 21:29:08,678:INFO:Creating metrics dataframe
2025-08-27 21:29:08,682:INFO:Uploading results into container
2025-08-27 21:29:08,682:INFO:Uploading model into container now
2025-08-27 21:29:08,683:INFO:_master_model_container: 3
2025-08-27 21:29:08,683:INFO:_display_container: 2
2025-08-27 21:29:08,683:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 21:29:08,684:INFO:create_model() successfully completed......................................
2025-08-27 21:29:08,760:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:08,760:INFO:Creating metrics dataframe
2025-08-27 21:29:08,781:INFO:Initializing Decision Tree Classifier
2025-08-27 21:29:08,782:INFO:Total runtime is 0.15098905165990192 minutes
2025-08-27 21:29:08,787:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:08,788:INFO:Initializing create_model()
2025-08-27 21:29:08,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:08,788:INFO:Checking exceptions
2025-08-27 21:29:08,788:INFO:Importing libraries
2025-08-27 21:29:08,788:INFO:Copying training dataset
2025-08-27 21:29:08,795:INFO:Defining folds
2025-08-27 21:29:08,795:INFO:Declaring metric variables
2025-08-27 21:29:08,802:INFO:Importing untrained model
2025-08-27 21:29:08,810:INFO:Decision Tree Classifier Imported successfully
2025-08-27 21:29:08,821:INFO:Starting cross validation
2025-08-27 21:29:08,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:08,829:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:08,829:WARNING:  warnings.warn(
2025-08-27 21:29:08,878:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:29:08,878:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,878:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,878:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,885:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,888:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,891:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,891:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,891:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually 2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,906:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,906:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,918:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,927:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,928:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:08,929:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,929:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,929:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,929:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,929:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,929:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:08,929:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,937:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,937:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:08,938:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,940:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:08,948:INFO:Calculating mean and std
2025-08-27 21:29:08,950:INFO:Creating metrics dataframe
2025-08-27 21:29:08,953:INFO:Uploading results into container
2025-08-27 21:29:08,955:INFO:Uploading model into container now
2025-08-27 21:29:08,955:INFO:_master_model_container: 4
2025-08-27 21:29:08,955:INFO:_display_container: 2
2025-08-27 21:29:08,956:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=0, splitter='best')
2025-08-27 21:29:08,956:INFO:create_model() successfully completed......................................
2025-08-27 21:29:09,046:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:09,046:INFO:Creating metrics dataframe
2025-08-27 21:29:09,059:INFO:Initializing SVM - Linear Kernel
2025-08-27 21:29:09,059:INFO:Total runtime is 0.15559705893198647 minutes
2025-08-27 21:29:09,065:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:09,066:INFO:Initializing create_model()
2025-08-27 21:29:09,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:09,066:INFO:Checking exceptions
2025-08-27 21:29:09,067:INFO:Importing libraries
2025-08-27 21:29:09,067:INFO:Copying training dataset
2025-08-27 21:29:09,075:INFO:Defining folds
2025-08-27 21:29:09,075:INFO:Declaring metric variables
2025-08-27 21:29:09,084:INFO:Importing untrained model
2025-08-27 21:29:09,095:INFO:SVM - Linear Kernel Imported successfully
2025-08-27 21:29:09,110:INFO:Starting cross validation
2025-08-27 21:29:09,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:09,118:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:09,118:WARNING:  warnings.warn(
2025-08-27 21:29:09,171:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,171:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,171:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,171:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,171:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,177:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,177:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,177:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,177:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,177:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,192:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,192:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,193:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,194:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,200:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,203:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,206:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,209:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,209:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,216:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,219:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,219:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,223:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,223:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,227:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,227:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,230:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,231:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,231:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,232:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,234:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,243:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 21:29:09,243:WARNING:1 fits failed out of a total of 10.
2025-08-27 21:29:09,243:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 21:29:09,243:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 21:29:09,243:WARNING:
2025-08-27 21:29:09,243:WARNING:Below are more details about the failures:
2025-08-27 21:29:09,243:WARNING:--------------------------------------------------------------------------------
2025-08-27 21:29:09,243:WARNING:1 fits failed with the following error:
2025-08-27 21:29:09,243:WARNING:Traceback (most recent call last):
2025-08-27 21:29:09,243:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 21:29:09,244:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 21:29:09,244:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 21:29:09,244:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 21:29:09,244:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 21:29:09,244:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 21:29:09,244:WARNING:    return self.func(*args, **kwargs)
2025-08-27 21:29:09,244:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:29:09,244:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 21:29:09,245:WARNING:    transformer.fit(*args)
2025-08-27 21:29:09,245:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 21:29:09,245:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 21:29:09,245:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:29:09,245:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 917, in fit
2025-08-27 21:29:09,245:WARNING:    return self._fit(
2025-08-27 21:29:09,245:WARNING:           ^^^^^^^^^^
2025-08-27 21:29:09,245:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 704, in _fit
2025-08-27 21:29:09,245:WARNING:    self._partial_fit(
2025-08-27 21:29:09,245:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 658, in _partial_fit
2025-08-27 21:29:09,245:WARNING:    raise ValueError(
2025-08-27 21:29:09,245:WARNING:ValueError: The number of classes has to be greater than one; got 1 class
2025-08-27 21:29:09,245:WARNING:
2025-08-27 21:29:09,245:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 21:29:09,245:INFO:Calculating mean and std
2025-08-27 21:29:09,247:INFO:Creating metrics dataframe
2025-08-27 21:29:09,248:INFO:Uploading results into container
2025-08-27 21:29:09,250:INFO:Uploading model into container now
2025-08-27 21:29:09,250:INFO:_master_model_container: 5
2025-08-27 21:29:09,250:INFO:_display_container: 2
2025-08-27 21:29:09,251:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=0, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-27 21:29:09,251:INFO:create_model() successfully completed......................................
2025-08-27 21:29:09,332:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:09,333:INFO:Creating metrics dataframe
2025-08-27 21:29:09,348:INFO:Initializing Ridge Classifier
2025-08-27 21:29:09,349:INFO:Total runtime is 0.16043090820312497 minutes
2025-08-27 21:29:09,355:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:09,355:INFO:Initializing create_model()
2025-08-27 21:29:09,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:09,355:INFO:Checking exceptions
2025-08-27 21:29:09,356:INFO:Importing libraries
2025-08-27 21:29:09,356:INFO:Copying training dataset
2025-08-27 21:29:09,363:INFO:Defining folds
2025-08-27 21:29:09,363:INFO:Declaring metric variables
2025-08-27 21:29:09,371:INFO:Importing untrained model
2025-08-27 21:29:09,379:INFO:Ridge Classifier Imported successfully
2025-08-27 21:29:09,395:INFO:Starting cross validation
2025-08-27 21:29:09,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:09,401:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:09,401:WARNING:  warnings.warn(
2025-08-27 21:29:09,462:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,464:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,466:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,473:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,474:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,474:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,474:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,474:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,487:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,487:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,489:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,496:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,496:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,496:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,496:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,500:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,500:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,508:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,515:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:09,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,522:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,523:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,526:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,528:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,529:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:09,529:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,529:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,531:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,531:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:09,531:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,533:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:09,542:INFO:Calculating mean and std
2025-08-27 21:29:09,543:INFO:Creating metrics dataframe
2025-08-27 21:29:09,546:INFO:Uploading results into container
2025-08-27 21:29:09,546:INFO:Uploading model into container now
2025-08-27 21:29:09,547:INFO:_master_model_container: 6
2025-08-27 21:29:09,547:INFO:_display_container: 2
2025-08-27 21:29:09,548:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=0, solver='auto',
                tol=0.0001)
2025-08-27 21:29:09,548:INFO:create_model() successfully completed......................................
2025-08-27 21:29:09,628:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:09,628:INFO:Creating metrics dataframe
2025-08-27 21:29:09,642:INFO:Initializing Random Forest Classifier
2025-08-27 21:29:09,642:INFO:Total runtime is 0.16531431674957273 minutes
2025-08-27 21:29:09,649:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:09,649:INFO:Initializing create_model()
2025-08-27 21:29:09,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:09,650:INFO:Checking exceptions
2025-08-27 21:29:09,650:INFO:Importing libraries
2025-08-27 21:29:09,650:INFO:Copying training dataset
2025-08-27 21:29:09,683:INFO:Defining folds
2025-08-27 21:29:09,684:INFO:Declaring metric variables
2025-08-27 21:29:09,697:INFO:Importing untrained model
2025-08-27 21:29:09,708:INFO:Random Forest Classifier Imported successfully
2025-08-27 21:29:09,722:INFO:Starting cross validation
2025-08-27 21:29:09,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:09,730:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:09,730:WARNING:  warnings.warn(
2025-08-27 21:29:10,121:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,124:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,127:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:29:10,128:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,131:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,133:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,133:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,135:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,138:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,139:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,139:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,141:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,145:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,145:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,145:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,146:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,155:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,156:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,156:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,158:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,160:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,162:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,162:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,162:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,167:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,167:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,167:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,169:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,169:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,169:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,233:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,237:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,242:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,247:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,250:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,251:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,254:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,441:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,448:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,451:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,451:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,456:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,459:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,461:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,461:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,472:INFO:Calculating mean and std
2025-08-27 21:29:10,474:INFO:Creating metrics dataframe
2025-08-27 21:29:10,477:INFO:Uploading results into container
2025-08-27 21:29:10,477:INFO:Uploading model into container now
2025-08-27 21:29:10,479:INFO:_master_model_container: 7
2025-08-27 21:29:10,479:INFO:_display_container: 2
2025-08-27 21:29:10,480:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=0, verbose=0,
                       warm_start=False)
2025-08-27 21:29:10,480:INFO:create_model() successfully completed......................................
2025-08-27 21:29:10,564:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:10,564:INFO:Creating metrics dataframe
2025-08-27 21:29:10,575:INFO:Initializing Quadratic Discriminant Analysis
2025-08-27 21:29:10,576:INFO:Total runtime is 0.18089204629262284 minutes
2025-08-27 21:29:10,580:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:10,581:INFO:Initializing create_model()
2025-08-27 21:29:10,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:10,581:INFO:Checking exceptions
2025-08-27 21:29:10,581:INFO:Importing libraries
2025-08-27 21:29:10,582:INFO:Copying training dataset
2025-08-27 21:29:10,587:INFO:Defining folds
2025-08-27 21:29:10,587:INFO:Declaring metric variables
2025-08-27 21:29:10,594:INFO:Importing untrained model
2025-08-27 21:29:10,600:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 21:29:10,612:INFO:Starting cross validation
2025-08-27 21:29:10,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:10,617:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:10,617:WARNING:  warnings.warn(
2025-08-27 21:29:10,688:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-08-27 21:29:10,692:WARNING:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class True, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-08-27 21:29:10,692:INFO:Initializing create_model()
2025-08-27 21:29:10,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:10,693:INFO:Checking exceptions
2025-08-27 21:29:10,693:INFO:Importing libraries
2025-08-27 21:29:10,693:INFO:Copying training dataset
2025-08-27 21:29:10,699:INFO:Defining folds
2025-08-27 21:29:10,699:INFO:Declaring metric variables
2025-08-27 21:29:10,705:INFO:Importing untrained model
2025-08-27 21:29:10,712:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 21:29:10,721:INFO:Starting cross validation
2025-08-27 21:29:10,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:10,730:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:10,730:WARNING:  warnings.warn(
2025-08-27 21:29:10,793:ERROR:create_model() for qda raised an exception or returned all 0.0:
2025-08-27 21:29:10,796:ERROR:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class True, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class True, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-08-27 21:29:10,796:INFO:Initializing Ada Boost Classifier
2025-08-27 21:29:10,796:INFO:Total runtime is 0.18455394903818761 minutes
2025-08-27 21:29:10,800:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:10,801:INFO:Initializing create_model()
2025-08-27 21:29:10,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:10,801:INFO:Checking exceptions
2025-08-27 21:29:10,801:INFO:Importing libraries
2025-08-27 21:29:10,801:INFO:Copying training dataset
2025-08-27 21:29:10,808:INFO:Defining folds
2025-08-27 21:29:10,808:INFO:Declaring metric variables
2025-08-27 21:29:10,814:INFO:Importing untrained model
2025-08-27 21:29:10,821:INFO:Ada Boost Classifier Imported successfully
2025-08-27 21:29:10,830:INFO:Starting cross validation
2025-08-27 21:29:10,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:10,835:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:10,835:WARNING:  warnings.warn(
2025-08-27 21:29:10,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:29:10,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:29:10,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:29:10,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:29:10,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:29:10,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,906:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,907:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,912:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,912:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,912:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,912:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,912:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,912:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,923:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,923:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,924:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,924:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,925:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,925:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,927:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,927:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,930:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,930:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,934:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,936:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:29:10,938:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:29:10,949:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,949:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:10,949:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,949:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,957:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:10,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:10,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:10,969:INFO:Calculating mean and std
2025-08-27 21:29:10,971:INFO:Creating metrics dataframe
2025-08-27 21:29:10,977:INFO:Uploading results into container
2025-08-27 21:29:10,977:INFO:Uploading model into container now
2025-08-27 21:29:10,978:INFO:_master_model_container: 8
2025-08-27 21:29:10,978:INFO:_display_container: 2
2025-08-27 21:29:10,978:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=0)
2025-08-27 21:29:10,978:INFO:create_model() successfully completed......................................
2025-08-27 21:29:11,063:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:11,063:INFO:Creating metrics dataframe
2025-08-27 21:29:11,082:INFO:Initializing Gradient Boosting Classifier
2025-08-27 21:29:11,082:INFO:Total runtime is 0.18931718269983921 minutes
2025-08-27 21:29:11,086:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:11,087:INFO:Initializing create_model()
2025-08-27 21:29:11,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:11,087:INFO:Checking exceptions
2025-08-27 21:29:11,087:INFO:Importing libraries
2025-08-27 21:29:11,087:INFO:Copying training dataset
2025-08-27 21:29:11,095:INFO:Defining folds
2025-08-27 21:29:11,095:INFO:Declaring metric variables
2025-08-27 21:29:11,103:INFO:Importing untrained model
2025-08-27 21:29:11,110:INFO:Gradient Boosting Classifier Imported successfully
2025-08-27 21:29:11,120:INFO:Starting cross validation
2025-08-27 21:29:11,121:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:11,126:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:11,126:WARNING:  warnings.warn(
2025-08-27 21:29:11,335:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,335:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,340:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,341:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,341:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,344:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,344:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,346:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,349:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,349:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,349:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,349:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,349:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,353:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,354:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,354:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,357:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,357:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,357:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,357:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,357:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,357:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,362:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,363:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,387:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,390:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,391:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,393:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,396:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,397:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,397:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,399:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,399:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,399:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,399:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,399:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,399:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,407:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,407:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,407:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,409:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,414:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,414:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,414:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,414:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,492:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,496:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,500:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,500:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,500:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,500:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,510:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 21:29:11,510:WARNING:1 fits failed out of a total of 10.
2025-08-27 21:29:11,510:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 21:29:11,510:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 21:29:11,510:WARNING:
2025-08-27 21:29:11,510:WARNING:Below are more details about the failures:
2025-08-27 21:29:11,510:WARNING:--------------------------------------------------------------------------------
2025-08-27 21:29:11,510:WARNING:1 fits failed with the following error:
2025-08-27 21:29:11,510:WARNING:Traceback (most recent call last):
2025-08-27 21:29:11,510:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 21:29:11,510:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 21:29:11,510:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 21:29:11,510:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 21:29:11,510:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 21:29:11,510:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 21:29:11,510:WARNING:    return self.func(*args, **kwargs)
2025-08-27 21:29:11,510:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:29:11,510:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 21:29:11,510:WARNING:    transformer.fit(*args)
2025-08-27 21:29:11,510:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 21:29:11,510:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 21:29:11,512:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:29:11,512:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_gb.py", line 665, in fit
2025-08-27 21:29:11,512:WARNING:    y = self._encode_y(y=y, sample_weight=None)
2025-08-27 21:29:11,512:WARNING:        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:29:11,512:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_gb.py", line 1520, in _encode_y
2025-08-27 21:29:11,512:WARNING:    raise ValueError(
2025-08-27 21:29:11,512:WARNING:ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.
2025-08-27 21:29:11,512:WARNING:
2025-08-27 21:29:11,512:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 21:29:11,513:INFO:Calculating mean and std
2025-08-27 21:29:11,515:INFO:Creating metrics dataframe
2025-08-27 21:29:11,519:INFO:Uploading results into container
2025-08-27 21:29:11,519:INFO:Uploading model into container now
2025-08-27 21:29:11,520:INFO:_master_model_container: 9
2025-08-27 21:29:11,520:INFO:_display_container: 2
2025-08-27 21:29:11,521:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=0, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-27 21:29:11,521:INFO:create_model() successfully completed......................................
2025-08-27 21:29:11,603:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:11,603:INFO:Creating metrics dataframe
2025-08-27 21:29:11,622:INFO:Initializing Linear Discriminant Analysis
2025-08-27 21:29:11,622:INFO:Total runtime is 0.19831463893254592 minutes
2025-08-27 21:29:11,626:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:11,627:INFO:Initializing create_model()
2025-08-27 21:29:11,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:11,627:INFO:Checking exceptions
2025-08-27 21:29:11,628:INFO:Importing libraries
2025-08-27 21:29:11,628:INFO:Copying training dataset
2025-08-27 21:29:11,634:INFO:Defining folds
2025-08-27 21:29:11,634:INFO:Declaring metric variables
2025-08-27 21:29:11,642:INFO:Importing untrained model
2025-08-27 21:29:11,650:INFO:Linear Discriminant Analysis Imported successfully
2025-08-27 21:29:11,661:INFO:Starting cross validation
2025-08-27 21:29:11,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:11,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:11,667:WARNING:  warnings.warn(
2025-08-27 21:29:11,718:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,718:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,718:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,719:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,720:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,721:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,721:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,721:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,724:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,724:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,724:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,724:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,724:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually 2025-08-27 21:29:11,724:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

ine 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,731:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,740:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,740:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,741:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,741:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,746:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,747:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,748:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,748:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,748:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,748:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,748:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,748:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,761:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,761:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:11,761:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,765:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,766:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:11,774:INFO:Calculating mean and std
2025-08-27 21:29:11,775:INFO:Creating metrics dataframe
2025-08-27 21:29:11,779:INFO:Uploading results into container
2025-08-27 21:29:11,780:INFO:Uploading model into container now
2025-08-27 21:29:11,780:INFO:_master_model_container: 10
2025-08-27 21:29:11,780:INFO:_display_container: 2
2025-08-27 21:29:11,781:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-08-27 21:29:11,781:INFO:create_model() successfully completed......................................
2025-08-27 21:29:11,858:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:11,858:INFO:Creating metrics dataframe
2025-08-27 21:29:11,871:INFO:Initializing Extra Trees Classifier
2025-08-27 21:29:11,872:INFO:Total runtime is 0.20248167117436722 minutes
2025-08-27 21:29:11,878:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:11,878:INFO:Initializing create_model()
2025-08-27 21:29:11,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:11,878:INFO:Checking exceptions
2025-08-27 21:29:11,879:INFO:Importing libraries
2025-08-27 21:29:11,879:INFO:Copying training dataset
2025-08-27 21:29:11,885:INFO:Defining folds
2025-08-27 21:29:11,885:INFO:Declaring metric variables
2025-08-27 21:29:11,891:INFO:Importing untrained model
2025-08-27 21:29:11,898:INFO:Extra Trees Classifier Imported successfully
2025-08-27 21:29:11,911:INFO:Starting cross validation
2025-08-27 21:29:11,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:11,915:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:11,915:WARNING:  warnings.warn(
2025-08-27 21:29:12,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,218:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:29:12,228:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,230:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,233:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,237:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,238:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,238:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,240:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,242:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,243:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,250:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,251:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:12,252:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,253:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,254:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,255:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,255:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,259:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:12,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:12,266:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,266:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,267:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,272:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,275:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,276:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:12,279:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,334:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,340:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,350:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,352:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,353:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:12,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,368:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,372:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,376:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,383:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,383:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:12,385:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,523:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,523:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:12,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,526:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,528:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,528:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,532:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,532:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:12,533:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,533:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:12,533:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,533:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:12,533:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,533:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:12,542:INFO:Calculating mean and std
2025-08-27 21:29:12,544:INFO:Creating metrics dataframe
2025-08-27 21:29:12,547:INFO:Uploading results into container
2025-08-27 21:29:12,548:INFO:Uploading model into container now
2025-08-27 21:29:12,548:INFO:_master_model_container: 11
2025-08-27 21:29:12,549:INFO:_display_container: 2
2025-08-27 21:29:12,549:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=0, verbose=0,
                     warm_start=False)
2025-08-27 21:29:12,549:INFO:create_model() successfully completed......................................
2025-08-27 21:29:12,622:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:12,622:INFO:Creating metrics dataframe
2025-08-27 21:29:12,637:INFO:Initializing Light Gradient Boosting Machine
2025-08-27 21:29:12,637:INFO:Total runtime is 0.21524204413096104 minutes
2025-08-27 21:29:12,644:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:12,644:INFO:Initializing create_model()
2025-08-27 21:29:12,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:12,645:INFO:Checking exceptions
2025-08-27 21:29:12,645:INFO:Importing libraries
2025-08-27 21:29:12,645:INFO:Copying training dataset
2025-08-27 21:29:12,649:INFO:Defining folds
2025-08-27 21:29:12,652:INFO:Declaring metric variables
2025-08-27 21:29:12,658:INFO:Importing untrained model
2025-08-27 21:29:12,667:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-27 21:29:12,679:INFO:Starting cross validation
2025-08-27 21:29:12,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:12,687:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:12,687:WARNING:  warnings.warn(
2025-08-27 21:29:12,865:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,178:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,178:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,193:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,193:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,194:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,200:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,200:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,202:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,202:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,202:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,202:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,202:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,202:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,211:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,211:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,212:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,214:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,266:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,275:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,284:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,297:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,299:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,299:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,306:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,349:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,359:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,368:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,384:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,385:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,399:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,409:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,415:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,420:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,422:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,428:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,428:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,434:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,443:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,451:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,459:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,460:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,466:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,511:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,528:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,534:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,544:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,544:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,550:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,618:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:13,626:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:13,648:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,649:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:13,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:13,659:INFO:Calculating mean and std
2025-08-27 21:29:13,663:INFO:Creating metrics dataframe
2025-08-27 21:29:13,669:INFO:Uploading results into container
2025-08-27 21:29:13,670:INFO:Uploading model into container now
2025-08-27 21:29:13,671:INFO:_master_model_container: 12
2025-08-27 21:29:13,671:INFO:_display_container: 2
2025-08-27 21:29:13,671:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=0, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-27 21:29:13,671:INFO:create_model() successfully completed......................................
2025-08-27 21:29:13,804:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:13,804:INFO:Creating metrics dataframe
2025-08-27 21:29:13,844:INFO:Initializing Dummy Classifier
2025-08-27 21:29:13,845:INFO:Total runtime is 0.23537091016769404 minutes
2025-08-27 21:29:13,854:INFO:SubProcess create_model() called ==================================
2025-08-27 21:29:13,855:INFO:Initializing create_model()
2025-08-27 21:29:13,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B69F95110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:13,855:INFO:Checking exceptions
2025-08-27 21:29:13,855:INFO:Importing libraries
2025-08-27 21:29:13,855:INFO:Copying training dataset
2025-08-27 21:29:13,866:INFO:Defining folds
2025-08-27 21:29:13,866:INFO:Declaring metric variables
2025-08-27 21:29:13,877:INFO:Importing untrained model
2025-08-27 21:29:13,886:INFO:Dummy Classifier Imported successfully
2025-08-27 21:29:13,921:INFO:Starting cross validation
2025-08-27 21:29:13,922:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:29:13,928:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:29:13,928:WARNING:  warnings.warn(
2025-08-27 21:29:13,998:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:14,000:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:29:14,002:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,008:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:14,009:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:14,013:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,013:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,014:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,016:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,018:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,018:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,023:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,023:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,023:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,030:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,030:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,031:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:14,033:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:14,033:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,033:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,033:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,033:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:14,037:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,037:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,038:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,038:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,039:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,041:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,042:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,045:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,045:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,045:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,049:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,052:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,052:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,052:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,052:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,052:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,052:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,052:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,060:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,060:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,060:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,061:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,063:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,063:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:14,063:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,066:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:29:14,067:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,067:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,070:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,073:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,075:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,077:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,080:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,080:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:29:14,080:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:29:14,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,083:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:29:14,093:INFO:Calculating mean and std
2025-08-27 21:29:14,095:INFO:Creating metrics dataframe
2025-08-27 21:29:14,101:INFO:Uploading results into container
2025-08-27 21:29:14,101:INFO:Uploading model into container now
2025-08-27 21:29:14,103:INFO:_master_model_container: 13
2025-08-27 21:29:14,103:INFO:_display_container: 2
2025-08-27 21:29:14,103:INFO:DummyClassifier(constant=None, random_state=0, strategy='prior')
2025-08-27 21:29:14,104:INFO:create_model() successfully completed......................................
2025-08-27 21:29:14,206:INFO:SubProcess create_model() end ==================================
2025-08-27 21:29:14,211:INFO:Creating metrics dataframe
2025-08-27 21:29:14,283:INFO:Initializing create_model()
2025-08-27 21:29:14,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:29:14,283:INFO:Checking exceptions
2025-08-27 21:29:14,286:INFO:Importing libraries
2025-08-27 21:29:14,286:INFO:Copying training dataset
2025-08-27 21:29:14,301:INFO:Defining folds
2025-08-27 21:29:14,302:INFO:Declaring metric variables
2025-08-27 21:29:14,302:INFO:Importing untrained model
2025-08-27 21:29:14,302:INFO:Declaring custom model
2025-08-27 21:29:14,304:INFO:K Neighbors Classifier Imported successfully
2025-08-27 21:29:14,304:INFO:Cross validation set to False
2025-08-27 21:29:14,308:INFO:Fitting Model
2025-08-27 21:29:14,330:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 21:29:14,331:INFO:create_model() successfully completed......................................
2025-08-27 21:29:14,503:INFO:_master_model_container: 13
2025-08-27 21:29:14,503:INFO:_display_container: 2
2025-08-27 21:29:14,503:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 21:29:14,506:INFO:compare_models() successfully completed......................................
2025-08-27 21:30:43,761:INFO:Initializing plot_model()
2025-08-27 21:30:43,761:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B55EDE3D0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-27 21:30:43,761:INFO:Checking exceptions
2025-08-27 21:30:43,765:INFO:Preloading libraries
2025-08-27 21:30:43,768:INFO:Copying training dataset
2025-08-27 21:30:43,768:INFO:Plot type: confusion_matrix
2025-08-27 21:30:43,904:INFO:Fitting Model
2025-08-27 21:30:43,905:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
2025-08-27 21:30:43,905:WARNING:  warnings.warn(
2025-08-27 21:30:43,905:INFO:Scoring test/hold-out set
2025-08-27 21:30:44,647:INFO:Visual Rendered Successfully
2025-08-27 21:30:44,816:INFO:plot_model() successfully completed......................................
2025-08-27 21:46:34,127:INFO:PyCaret ClassificationExperiment
2025-08-27 21:46:34,127:INFO:Logging name: clf-default-name
2025-08-27 21:46:34,127:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 21:46:34,127:INFO:version 3.3.2
2025-08-27 21:46:34,127:INFO:Initializing setup()
2025-08-27 21:46:34,127:INFO:self.USI: fdf4
2025-08-27 21:46:34,127:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 21:46:34,127:INFO:Checking environment
2025-08-27 21:46:34,127:INFO:python_version: 3.11.9
2025-08-27 21:46:34,127:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 21:46:34,127:INFO:machine: AMD64
2025-08-27 21:46:34,127:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 21:46:34,130:INFO:Memory: svmem(total=17024348160, available=2897702912, percent=83.0, used=14126645248, free=2897702912)
2025-08-27 21:46:34,130:INFO:Physical Core: 4
2025-08-27 21:46:34,130:INFO:Logical Core: 8
2025-08-27 21:46:34,130:INFO:Checking libraries
2025-08-27 21:46:34,130:INFO:System:
2025-08-27 21:46:34,131:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 21:46:34,131:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 21:46:34,131:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 21:46:34,131:INFO:PyCaret required dependencies:
2025-08-27 21:46:34,131:INFO:                 pip: Not installed
2025-08-27 21:46:34,131:INFO:          setuptools: 80.9.0
2025-08-27 21:46:34,131:INFO:             pycaret: 3.3.2
2025-08-27 21:46:34,131:INFO:             IPython: 9.4.0
2025-08-27 21:46:34,131:INFO:          ipywidgets: 8.1.7
2025-08-27 21:46:34,131:INFO:                tqdm: 4.67.1
2025-08-27 21:46:34,131:INFO:               numpy: 1.26.4
2025-08-27 21:46:34,131:INFO:              pandas: 2.1.4
2025-08-27 21:46:34,132:INFO:              jinja2: 3.1.6
2025-08-27 21:46:34,132:INFO:               scipy: 1.11.4
2025-08-27 21:46:34,132:INFO:              joblib: 1.3.2
2025-08-27 21:46:34,132:INFO:             sklearn: 1.4.2
2025-08-27 21:46:34,132:INFO:                pyod: 2.0.5
2025-08-27 21:46:34,132:INFO:            imblearn: 0.14.0
2025-08-27 21:46:34,132:INFO:   category_encoders: 2.7.0
2025-08-27 21:46:34,132:INFO:            lightgbm: 4.6.0
2025-08-27 21:46:34,132:INFO:               numba: 0.61.2
2025-08-27 21:46:34,132:INFO:            requests: 2.32.5
2025-08-27 21:46:34,133:INFO:          matplotlib: 3.7.5
2025-08-27 21:46:34,133:INFO:          scikitplot: 0.3.7
2025-08-27 21:46:34,133:INFO:         yellowbrick: 1.5
2025-08-27 21:46:34,134:INFO:              plotly: 5.24.1
2025-08-27 21:46:34,134:INFO:    plotly-resampler: Not installed
2025-08-27 21:46:34,134:INFO:             kaleido: 1.0.0
2025-08-27 21:46:34,134:INFO:           schemdraw: 0.15
2025-08-27 21:46:34,134:INFO:         statsmodels: 0.14.5
2025-08-27 21:46:34,134:INFO:              sktime: 0.26.0
2025-08-27 21:46:34,134:INFO:               tbats: 1.1.3
2025-08-27 21:46:34,134:INFO:            pmdarima: 2.0.4
2025-08-27 21:46:34,134:INFO:              psutil: 7.0.0
2025-08-27 21:46:34,134:INFO:          markupsafe: 3.0.2
2025-08-27 21:46:34,134:INFO:             pickle5: Not installed
2025-08-27 21:46:34,134:INFO:         cloudpickle: 3.1.1
2025-08-27 21:46:34,135:INFO:         deprecation: 2.1.0
2025-08-27 21:46:34,135:INFO:              xxhash: 3.5.0
2025-08-27 21:46:34,135:INFO:           wurlitzer: Not installed
2025-08-27 21:46:34,135:INFO:PyCaret optional dependencies:
2025-08-27 21:46:34,135:INFO:                shap: Not installed
2025-08-27 21:46:34,135:INFO:           interpret: Not installed
2025-08-27 21:46:34,135:INFO:                umap: Not installed
2025-08-27 21:46:34,135:INFO:     ydata_profiling: Not installed
2025-08-27 21:46:34,135:INFO:  explainerdashboard: Not installed
2025-08-27 21:46:34,135:INFO:             autoviz: Not installed
2025-08-27 21:46:34,135:INFO:           fairlearn: Not installed
2025-08-27 21:46:34,135:INFO:          deepchecks: Not installed
2025-08-27 21:46:34,136:INFO:             xgboost: Not installed
2025-08-27 21:46:34,136:INFO:            catboost: Not installed
2025-08-27 21:46:34,136:INFO:              kmodes: Not installed
2025-08-27 21:46:34,136:INFO:             mlxtend: Not installed
2025-08-27 21:46:34,136:INFO:       statsforecast: Not installed
2025-08-27 21:46:34,136:INFO:        tune_sklearn: Not installed
2025-08-27 21:46:34,136:INFO:                 ray: Not installed
2025-08-27 21:46:34,136:INFO:            hyperopt: Not installed
2025-08-27 21:46:34,136:INFO:              optuna: Not installed
2025-08-27 21:46:34,136:INFO:               skopt: Not installed
2025-08-27 21:46:34,136:INFO:              mlflow: Not installed
2025-08-27 21:46:34,136:INFO:              gradio: Not installed
2025-08-27 21:46:34,136:INFO:             fastapi: Not installed
2025-08-27 21:46:34,136:INFO:             uvicorn: Not installed
2025-08-27 21:46:34,136:INFO:              m2cgen: Not installed
2025-08-27 21:46:34,136:INFO:           evidently: Not installed
2025-08-27 21:46:34,136:INFO:               fugue: Not installed
2025-08-27 21:46:34,136:INFO:           streamlit: Not installed
2025-08-27 21:46:34,137:INFO:             prophet: Not installed
2025-08-27 21:46:34,137:INFO:None
2025-08-27 21:46:34,137:INFO:Set up data.
2025-08-27 21:46:34,141:INFO:Set up folding strategy.
2025-08-27 21:46:34,141:INFO:Set up train/test split.
2025-08-27 21:46:34,141:INFO:Set up index.
2025-08-27 21:46:34,141:INFO:Assigning column types.
2025-08-27 21:46:34,150:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 21:46:34,203:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:46:34,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:46:34,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,290:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:46:34,290:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:46:34,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,327:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 21:46:34,381:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:46:34,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:46:34,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,501:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 21:46:34,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:34,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:35,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:35,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:35,037:INFO:Preparing preprocessing pipeline...
2025-08-27 21:46:35,046:INFO:Set up simple imputation.
2025-08-27 21:46:35,046:INFO:Set up imbalanced handling.
2025-08-27 21:46:45,131:INFO:PyCaret ClassificationExperiment
2025-08-27 21:46:45,131:INFO:Logging name: clf-default-name
2025-08-27 21:46:45,131:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 21:46:45,131:INFO:version 3.3.2
2025-08-27 21:46:45,131:INFO:Initializing setup()
2025-08-27 21:46:45,131:INFO:self.USI: 5615
2025-08-27 21:46:45,131:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 21:46:45,131:INFO:Checking environment
2025-08-27 21:46:45,131:INFO:python_version: 3.11.9
2025-08-27 21:46:45,131:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 21:46:45,131:INFO:machine: AMD64
2025-08-27 21:46:45,131:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 21:46:45,134:INFO:Memory: svmem(total=17024348160, available=2876649472, percent=83.1, used=14147698688, free=2876649472)
2025-08-27 21:46:45,134:INFO:Physical Core: 4
2025-08-27 21:46:45,135:INFO:Logical Core: 8
2025-08-27 21:46:45,135:INFO:Checking libraries
2025-08-27 21:46:45,135:INFO:System:
2025-08-27 21:46:45,135:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 21:46:45,135:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 21:46:45,135:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 21:46:45,135:INFO:PyCaret required dependencies:
2025-08-27 21:46:45,135:INFO:                 pip: Not installed
2025-08-27 21:46:45,135:INFO:          setuptools: 80.9.0
2025-08-27 21:46:45,135:INFO:             pycaret: 3.3.2
2025-08-27 21:46:45,135:INFO:             IPython: 9.4.0
2025-08-27 21:46:45,135:INFO:          ipywidgets: 8.1.7
2025-08-27 21:46:45,135:INFO:                tqdm: 4.67.1
2025-08-27 21:46:45,135:INFO:               numpy: 1.26.4
2025-08-27 21:46:45,136:INFO:              pandas: 2.1.4
2025-08-27 21:46:45,136:INFO:              jinja2: 3.1.6
2025-08-27 21:46:45,136:INFO:               scipy: 1.11.4
2025-08-27 21:46:45,136:INFO:              joblib: 1.3.2
2025-08-27 21:46:45,136:INFO:             sklearn: 1.4.2
2025-08-27 21:46:45,136:INFO:                pyod: 2.0.5
2025-08-27 21:46:45,136:INFO:            imblearn: 0.14.0
2025-08-27 21:46:45,136:INFO:   category_encoders: 2.7.0
2025-08-27 21:46:45,136:INFO:            lightgbm: 4.6.0
2025-08-27 21:46:45,136:INFO:               numba: 0.61.2
2025-08-27 21:46:45,136:INFO:            requests: 2.32.5
2025-08-27 21:46:45,136:INFO:          matplotlib: 3.7.5
2025-08-27 21:46:45,136:INFO:          scikitplot: 0.3.7
2025-08-27 21:46:45,136:INFO:         yellowbrick: 1.5
2025-08-27 21:46:45,136:INFO:              plotly: 5.24.1
2025-08-27 21:46:45,136:INFO:    plotly-resampler: Not installed
2025-08-27 21:46:45,136:INFO:             kaleido: 1.0.0
2025-08-27 21:46:45,136:INFO:           schemdraw: 0.15
2025-08-27 21:46:45,136:INFO:         statsmodels: 0.14.5
2025-08-27 21:46:45,136:INFO:              sktime: 0.26.0
2025-08-27 21:46:45,136:INFO:               tbats: 1.1.3
2025-08-27 21:46:45,136:INFO:            pmdarima: 2.0.4
2025-08-27 21:46:45,136:INFO:              psutil: 7.0.0
2025-08-27 21:46:45,136:INFO:          markupsafe: 3.0.2
2025-08-27 21:46:45,136:INFO:             pickle5: Not installed
2025-08-27 21:46:45,136:INFO:         cloudpickle: 3.1.1
2025-08-27 21:46:45,136:INFO:         deprecation: 2.1.0
2025-08-27 21:46:45,136:INFO:              xxhash: 3.5.0
2025-08-27 21:46:45,136:INFO:           wurlitzer: Not installed
2025-08-27 21:46:45,136:INFO:PyCaret optional dependencies:
2025-08-27 21:46:45,136:INFO:                shap: Not installed
2025-08-27 21:46:45,136:INFO:           interpret: Not installed
2025-08-27 21:46:45,136:INFO:                umap: Not installed
2025-08-27 21:46:45,136:INFO:     ydata_profiling: Not installed
2025-08-27 21:46:45,136:INFO:  explainerdashboard: Not installed
2025-08-27 21:46:45,136:INFO:             autoviz: Not installed
2025-08-27 21:46:45,136:INFO:           fairlearn: Not installed
2025-08-27 21:46:45,136:INFO:          deepchecks: Not installed
2025-08-27 21:46:45,136:INFO:             xgboost: Not installed
2025-08-27 21:46:45,136:INFO:            catboost: Not installed
2025-08-27 21:46:45,136:INFO:              kmodes: Not installed
2025-08-27 21:46:45,136:INFO:             mlxtend: Not installed
2025-08-27 21:46:45,136:INFO:       statsforecast: Not installed
2025-08-27 21:46:45,136:INFO:        tune_sklearn: Not installed
2025-08-27 21:46:45,136:INFO:                 ray: Not installed
2025-08-27 21:46:45,136:INFO:            hyperopt: Not installed
2025-08-27 21:46:45,136:INFO:              optuna: Not installed
2025-08-27 21:46:45,136:INFO:               skopt: Not installed
2025-08-27 21:46:45,136:INFO:              mlflow: Not installed
2025-08-27 21:46:45,136:INFO:              gradio: Not installed
2025-08-27 21:46:45,136:INFO:             fastapi: Not installed
2025-08-27 21:46:45,136:INFO:             uvicorn: Not installed
2025-08-27 21:46:45,136:INFO:              m2cgen: Not installed
2025-08-27 21:46:45,136:INFO:           evidently: Not installed
2025-08-27 21:46:45,136:INFO:               fugue: Not installed
2025-08-27 21:46:45,136:INFO:           streamlit: Not installed
2025-08-27 21:46:45,136:INFO:             prophet: Not installed
2025-08-27 21:46:45,136:INFO:None
2025-08-27 21:46:45,136:INFO:Set up data.
2025-08-27 21:46:45,142:INFO:Set up folding strategy.
2025-08-27 21:46:45,143:INFO:Set up train/test split.
2025-08-27 21:46:45,145:INFO:Set up index.
2025-08-27 21:46:45,145:INFO:Assigning column types.
2025-08-27 21:46:45,145:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 21:46:45,198:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:46:45,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:46:45,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:45,275:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:45,400:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:46:45,400:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:46:45,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:45,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:45,510:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 21:46:45,578:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:46:45,628:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:45,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:45,811:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:46:45,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:45,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:45,930:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 21:46:46,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:46,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:46,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:46,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:46:46,360:INFO:Preparing preprocessing pipeline...
2025-08-27 21:46:46,361:INFO:Set up simple imputation.
2025-08-27 21:46:46,361:INFO:Set up imbalanced handling.
2025-08-27 21:46:46,377:INFO:Finished creating preprocessing pipeline.
2025-08-27 21:46:46,377:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=0,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-08-27 21:46:46,377:INFO:Creating final display dataframe.
2025-08-27 21:47:02,454:INFO:PyCaret ClassificationExperiment
2025-08-27 21:47:02,454:INFO:Logging name: clf-default-name
2025-08-27 21:47:02,454:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 21:47:02,454:INFO:version 3.3.2
2025-08-27 21:47:02,454:INFO:Initializing setup()
2025-08-27 21:47:02,454:INFO:self.USI: 5ad0
2025-08-27 21:47:02,454:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 21:47:02,454:INFO:Checking environment
2025-08-27 21:47:02,454:INFO:python_version: 3.11.9
2025-08-27 21:47:02,454:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 21:47:02,454:INFO:machine: AMD64
2025-08-27 21:47:02,454:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 21:47:02,457:INFO:Memory: svmem(total=17024348160, available=2873896960, percent=83.1, used=14150451200, free=2873896960)
2025-08-27 21:47:02,458:INFO:Physical Core: 4
2025-08-27 21:47:02,458:INFO:Logical Core: 8
2025-08-27 21:47:02,458:INFO:Checking libraries
2025-08-27 21:47:02,458:INFO:System:
2025-08-27 21:47:02,458:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 21:47:02,458:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 21:47:02,458:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 21:47:02,458:INFO:PyCaret required dependencies:
2025-08-27 21:47:02,458:INFO:                 pip: Not installed
2025-08-27 21:47:02,459:INFO:          setuptools: 80.9.0
2025-08-27 21:47:02,459:INFO:             pycaret: 3.3.2
2025-08-27 21:47:02,459:INFO:             IPython: 9.4.0
2025-08-27 21:47:02,459:INFO:          ipywidgets: 8.1.7
2025-08-27 21:47:02,459:INFO:                tqdm: 4.67.1
2025-08-27 21:47:02,459:INFO:               numpy: 1.26.4
2025-08-27 21:47:02,459:INFO:              pandas: 2.1.4
2025-08-27 21:47:02,459:INFO:              jinja2: 3.1.6
2025-08-27 21:47:02,459:INFO:               scipy: 1.11.4
2025-08-27 21:47:02,459:INFO:              joblib: 1.3.2
2025-08-27 21:47:02,459:INFO:             sklearn: 1.4.2
2025-08-27 21:47:02,459:INFO:                pyod: 2.0.5
2025-08-27 21:47:02,459:INFO:            imblearn: 0.14.0
2025-08-27 21:47:02,459:INFO:   category_encoders: 2.7.0
2025-08-27 21:47:02,459:INFO:            lightgbm: 4.6.0
2025-08-27 21:47:02,459:INFO:               numba: 0.61.2
2025-08-27 21:47:02,459:INFO:            requests: 2.32.5
2025-08-27 21:47:02,459:INFO:          matplotlib: 3.7.5
2025-08-27 21:47:02,460:INFO:          scikitplot: 0.3.7
2025-08-27 21:47:02,460:INFO:         yellowbrick: 1.5
2025-08-27 21:47:02,460:INFO:              plotly: 5.24.1
2025-08-27 21:47:02,460:INFO:    plotly-resampler: Not installed
2025-08-27 21:47:02,460:INFO:             kaleido: 1.0.0
2025-08-27 21:47:02,460:INFO:           schemdraw: 0.15
2025-08-27 21:47:02,460:INFO:         statsmodels: 0.14.5
2025-08-27 21:47:02,460:INFO:              sktime: 0.26.0
2025-08-27 21:47:02,460:INFO:               tbats: 1.1.3
2025-08-27 21:47:02,460:INFO:            pmdarima: 2.0.4
2025-08-27 21:47:02,460:INFO:              psutil: 7.0.0
2025-08-27 21:47:02,460:INFO:          markupsafe: 3.0.2
2025-08-27 21:47:02,460:INFO:             pickle5: Not installed
2025-08-27 21:47:02,460:INFO:         cloudpickle: 3.1.1
2025-08-27 21:47:02,460:INFO:         deprecation: 2.1.0
2025-08-27 21:47:02,460:INFO:              xxhash: 3.5.0
2025-08-27 21:47:02,460:INFO:           wurlitzer: Not installed
2025-08-27 21:47:02,461:INFO:PyCaret optional dependencies:
2025-08-27 21:47:02,461:INFO:                shap: Not installed
2025-08-27 21:47:02,461:INFO:           interpret: Not installed
2025-08-27 21:47:02,461:INFO:                umap: Not installed
2025-08-27 21:47:02,461:INFO:     ydata_profiling: Not installed
2025-08-27 21:47:02,461:INFO:  explainerdashboard: Not installed
2025-08-27 21:47:02,461:INFO:             autoviz: Not installed
2025-08-27 21:47:02,461:INFO:           fairlearn: Not installed
2025-08-27 21:47:02,461:INFO:          deepchecks: Not installed
2025-08-27 21:47:02,461:INFO:             xgboost: Not installed
2025-08-27 21:47:02,461:INFO:            catboost: Not installed
2025-08-27 21:47:02,461:INFO:              kmodes: Not installed
2025-08-27 21:47:02,461:INFO:             mlxtend: Not installed
2025-08-27 21:47:02,461:INFO:       statsforecast: Not installed
2025-08-27 21:47:02,461:INFO:        tune_sklearn: Not installed
2025-08-27 21:47:02,461:INFO:                 ray: Not installed
2025-08-27 21:47:02,461:INFO:            hyperopt: Not installed
2025-08-27 21:47:02,462:INFO:              optuna: Not installed
2025-08-27 21:47:02,462:INFO:               skopt: Not installed
2025-08-27 21:47:02,462:INFO:              mlflow: Not installed
2025-08-27 21:47:02,462:INFO:              gradio: Not installed
2025-08-27 21:47:02,462:INFO:             fastapi: Not installed
2025-08-27 21:47:02,462:INFO:             uvicorn: Not installed
2025-08-27 21:47:02,462:INFO:              m2cgen: Not installed
2025-08-27 21:47:02,462:INFO:           evidently: Not installed
2025-08-27 21:47:02,462:INFO:               fugue: Not installed
2025-08-27 21:47:02,462:INFO:           streamlit: Not installed
2025-08-27 21:47:02,462:INFO:             prophet: Not installed
2025-08-27 21:47:02,462:INFO:None
2025-08-27 21:47:02,462:INFO:Set up data.
2025-08-27 21:47:02,466:INFO:Set up folding strategy.
2025-08-27 21:47:02,466:INFO:Set up train/test split.
2025-08-27 21:47:02,471:INFO:Set up index.
2025-08-27 21:47:02,471:INFO:Assigning column types.
2025-08-27 21:47:02,475:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 21:47:02,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:47:02,530:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:47:02,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:02,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:02,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:47:02,617:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:47:02,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:02,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:02,651:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 21:47:02,712:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:47:02,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:02,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:02,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:47:02,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:02,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:02,880:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 21:47:03,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:03,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:03,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:03,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:03,466:INFO:Preparing preprocessing pipeline...
2025-08-27 21:47:03,469:INFO:Set up simple imputation.
2025-08-27 21:47:03,469:INFO:Set up imbalanced handling.
2025-08-27 21:47:03,517:INFO:Finished creating preprocessing pipeline.
2025-08-27 21:47:03,527:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=0,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-08-27 21:47:03,527:INFO:Creating final display dataframe.
2025-08-27 21:47:11,904:INFO:PyCaret ClassificationExperiment
2025-08-27 21:47:11,905:INFO:Logging name: clf-default-name
2025-08-27 21:47:11,905:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 21:47:11,906:INFO:version 3.3.2
2025-08-27 21:47:11,906:INFO:Initializing setup()
2025-08-27 21:47:11,906:INFO:self.USI: 898a
2025-08-27 21:47:11,906:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 21:47:11,906:INFO:Checking environment
2025-08-27 21:47:11,906:INFO:python_version: 3.11.9
2025-08-27 21:47:11,906:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 21:47:11,906:INFO:machine: AMD64
2025-08-27 21:47:11,907:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 21:47:11,911:INFO:Memory: svmem(total=17024348160, available=2864898048, percent=83.2, used=14159450112, free=2864898048)
2025-08-27 21:47:11,911:INFO:Physical Core: 4
2025-08-27 21:47:11,911:INFO:Logical Core: 8
2025-08-27 21:47:11,912:INFO:Checking libraries
2025-08-27 21:47:11,912:INFO:System:
2025-08-27 21:47:11,912:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 21:47:11,912:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 21:47:11,912:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 21:47:11,912:INFO:PyCaret required dependencies:
2025-08-27 21:47:11,912:INFO:                 pip: Not installed
2025-08-27 21:47:11,912:INFO:          setuptools: 80.9.0
2025-08-27 21:47:11,913:INFO:             pycaret: 3.3.2
2025-08-27 21:47:11,913:INFO:             IPython: 9.4.0
2025-08-27 21:47:11,913:INFO:          ipywidgets: 8.1.7
2025-08-27 21:47:11,913:INFO:                tqdm: 4.67.1
2025-08-27 21:47:11,913:INFO:               numpy: 1.26.4
2025-08-27 21:47:11,913:INFO:              pandas: 2.1.4
2025-08-27 21:47:11,914:INFO:              jinja2: 3.1.6
2025-08-27 21:47:11,914:INFO:               scipy: 1.11.4
2025-08-27 21:47:11,914:INFO:              joblib: 1.3.2
2025-08-27 21:47:11,914:INFO:             sklearn: 1.4.2
2025-08-27 21:47:11,914:INFO:                pyod: 2.0.5
2025-08-27 21:47:11,914:INFO:            imblearn: 0.14.0
2025-08-27 21:47:11,914:INFO:   category_encoders: 2.7.0
2025-08-27 21:47:11,914:INFO:            lightgbm: 4.6.0
2025-08-27 21:47:11,914:INFO:               numba: 0.61.2
2025-08-27 21:47:11,914:INFO:            requests: 2.32.5
2025-08-27 21:47:11,914:INFO:          matplotlib: 3.7.5
2025-08-27 21:47:11,914:INFO:          scikitplot: 0.3.7
2025-08-27 21:47:11,914:INFO:         yellowbrick: 1.5
2025-08-27 21:47:11,914:INFO:              plotly: 5.24.1
2025-08-27 21:47:11,914:INFO:    plotly-resampler: Not installed
2025-08-27 21:47:11,914:INFO:             kaleido: 1.0.0
2025-08-27 21:47:11,914:INFO:           schemdraw: 0.15
2025-08-27 21:47:11,914:INFO:         statsmodels: 0.14.5
2025-08-27 21:47:11,914:INFO:              sktime: 0.26.0
2025-08-27 21:47:11,914:INFO:               tbats: 1.1.3
2025-08-27 21:47:11,914:INFO:            pmdarima: 2.0.4
2025-08-27 21:47:11,914:INFO:              psutil: 7.0.0
2025-08-27 21:47:11,914:INFO:          markupsafe: 3.0.2
2025-08-27 21:47:11,914:INFO:             pickle5: Not installed
2025-08-27 21:47:11,914:INFO:         cloudpickle: 3.1.1
2025-08-27 21:47:11,914:INFO:         deprecation: 2.1.0
2025-08-27 21:47:11,914:INFO:              xxhash: 3.5.0
2025-08-27 21:47:11,914:INFO:           wurlitzer: Not installed
2025-08-27 21:47:11,914:INFO:PyCaret optional dependencies:
2025-08-27 21:47:11,914:INFO:                shap: Not installed
2025-08-27 21:47:11,914:INFO:           interpret: Not installed
2025-08-27 21:47:11,914:INFO:                umap: Not installed
2025-08-27 21:47:11,914:INFO:     ydata_profiling: Not installed
2025-08-27 21:47:11,914:INFO:  explainerdashboard: Not installed
2025-08-27 21:47:11,914:INFO:             autoviz: Not installed
2025-08-27 21:47:11,914:INFO:           fairlearn: Not installed
2025-08-27 21:47:11,914:INFO:          deepchecks: Not installed
2025-08-27 21:47:11,914:INFO:             xgboost: Not installed
2025-08-27 21:47:11,914:INFO:            catboost: Not installed
2025-08-27 21:47:11,914:INFO:              kmodes: Not installed
2025-08-27 21:47:11,914:INFO:             mlxtend: Not installed
2025-08-27 21:47:11,914:INFO:       statsforecast: Not installed
2025-08-27 21:47:11,914:INFO:        tune_sklearn: Not installed
2025-08-27 21:47:11,914:INFO:                 ray: Not installed
2025-08-27 21:47:11,914:INFO:            hyperopt: Not installed
2025-08-27 21:47:11,914:INFO:              optuna: Not installed
2025-08-27 21:47:11,914:INFO:               skopt: Not installed
2025-08-27 21:47:11,914:INFO:              mlflow: Not installed
2025-08-27 21:47:11,914:INFO:              gradio: Not installed
2025-08-27 21:47:11,914:INFO:             fastapi: Not installed
2025-08-27 21:47:11,914:INFO:             uvicorn: Not installed
2025-08-27 21:47:11,914:INFO:              m2cgen: Not installed
2025-08-27 21:47:11,914:INFO:           evidently: Not installed
2025-08-27 21:47:11,914:INFO:               fugue: Not installed
2025-08-27 21:47:11,914:INFO:           streamlit: Not installed
2025-08-27 21:47:11,914:INFO:             prophet: Not installed
2025-08-27 21:47:11,914:INFO:None
2025-08-27 21:47:11,914:INFO:Set up data.
2025-08-27 21:47:11,928:INFO:Set up folding strategy.
2025-08-27 21:47:11,928:INFO:Set up train/test split.
2025-08-27 21:47:11,936:INFO:Set up index.
2025-08-27 21:47:11,936:INFO:Assigning column types.
2025-08-27 21:47:11,945:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 21:47:12,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:47:12,064:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:47:12,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,146:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:47:12,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:47:12,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,202:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 21:47:12,318:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:47:12,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:47:12,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,534:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 21:47:12,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:12,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:13,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:13,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:13,017:INFO:Preparing preprocessing pipeline...
2025-08-27 21:47:13,017:INFO:Set up simple imputation.
2025-08-27 21:47:13,034:INFO:Finished creating preprocessing pipeline.
2025-08-27 21:47:13,037:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-27 21:47:13,037:INFO:Creating final display dataframe.
2025-08-27 21:47:13,100:INFO:Setup _display_container:                     Description             Value
0                    Session id                 0
1                        Target           failure
2                   Target type            Binary
3           Original data shape          (989, 6)
4        Transformed data shape          (989, 6)
5   Transformed train set shape          (692, 6)
6    Transformed test set shape          (297, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              898a
2025-08-27 21:47:13,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:13,221:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:13,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:13,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:47:13,330:INFO:setup() successfully completed in 1.43s...............
2025-08-27 21:47:13,331:INFO:Initializing compare_models()
2025-08-27 21:47:13,331:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-27 21:47:13,331:INFO:Checking exceptions
2025-08-27 21:47:13,336:INFO:Preparing display monitor
2025-08-27 21:47:13,372:INFO:Initializing Logistic Regression
2025-08-27 21:47:13,372:INFO:Total runtime is 0.0 minutes
2025-08-27 21:47:13,378:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:13,379:INFO:Initializing create_model()
2025-08-27 21:47:13,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:13,379:INFO:Checking exceptions
2025-08-27 21:47:13,379:INFO:Importing libraries
2025-08-27 21:47:13,379:INFO:Copying training dataset
2025-08-27 21:47:13,387:INFO:Defining folds
2025-08-27 21:47:13,387:INFO:Declaring metric variables
2025-08-27 21:47:13,393:INFO:Importing untrained model
2025-08-27 21:47:13,400:INFO:Logistic Regression Imported successfully
2025-08-27 21:47:13,411:INFO:Starting cross validation
2025-08-27 21:47:13,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:13,416:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:13,416:WARNING:  warnings.warn(
2025-08-27 21:47:20,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:47:21,011:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:21,019:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,024:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,024:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,034:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:21,034:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:21,037:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:21,221:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:21,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,231:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,237:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,240:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:21,241:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:21,244:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:21,285:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:21,290:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,294:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,298:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:21,298:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:21,301:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:21,303:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:21,416:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:47:21,422:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:47:21,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:47:22,029:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:47:22,066:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:47:22,283:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:47:22,391:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:22,406:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,412:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,418:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,420:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:22,420:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:22,429:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:22,471:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 21:47:22,606:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:22,616:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,629:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,639:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,649:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:22,649:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:22,655:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:22,924:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:22,931:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,939:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,945:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:22,948:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:22,948:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:22,953:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,029:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,038:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,039:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,045:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,046:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,050:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,050:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,051:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,056:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,061:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,062:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,064:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,218:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,224:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,231:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,234:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,235:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,240:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,255:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 21:47:23,256:WARNING:1 fits failed out of a total of 10.
2025-08-27 21:47:23,256:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 21:47:23,256:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 21:47:23,256:WARNING:
2025-08-27 21:47:23,256:WARNING:Below are more details about the failures:
2025-08-27 21:47:23,256:WARNING:--------------------------------------------------------------------------------
2025-08-27 21:47:23,256:WARNING:1 fits failed with the following error:
2025-08-27 21:47:23,256:WARNING:Traceback (most recent call last):
2025-08-27 21:47:23,257:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 21:47:23,257:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 21:47:23,257:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 21:47:23,257:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 21:47:23,257:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 21:47:23,257:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 21:47:23,257:WARNING:    return self.func(*args, **kwargs)
2025-08-27 21:47:23,257:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:47:23,257:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 21:47:23,258:WARNING:    transformer.fit(*args)
2025-08-27 21:47:23,258:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 21:47:23,258:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 21:47:23,258:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:47:23,258:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py", line 1246, in fit
2025-08-27 21:47:23,258:WARNING:    raise ValueError(
2025-08-27 21:47:23,259:WARNING:ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0
2025-08-27 21:47:23,259:WARNING:
2025-08-27 21:47:23,259:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 21:47:23,260:INFO:Calculating mean and std
2025-08-27 21:47:23,263:INFO:Creating metrics dataframe
2025-08-27 21:47:23,268:INFO:Uploading results into container
2025-08-27 21:47:23,271:INFO:Uploading model into container now
2025-08-27 21:47:23,273:INFO:_master_model_container: 1
2025-08-27 21:47:23,273:INFO:_display_container: 2
2025-08-27 21:47:23,274:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 21:47:23,274:INFO:create_model() successfully completed......................................
2025-08-27 21:47:23,478:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:23,478:INFO:Creating metrics dataframe
2025-08-27 21:47:23,503:INFO:Initializing K Neighbors Classifier
2025-08-27 21:47:23,504:INFO:Total runtime is 0.16887114842732748 minutes
2025-08-27 21:47:23,509:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:23,509:INFO:Initializing create_model()
2025-08-27 21:47:23,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:23,509:INFO:Checking exceptions
2025-08-27 21:47:23,513:INFO:Importing libraries
2025-08-27 21:47:23,513:INFO:Copying training dataset
2025-08-27 21:47:23,522:INFO:Defining folds
2025-08-27 21:47:23,523:INFO:Declaring metric variables
2025-08-27 21:47:23,549:INFO:Importing untrained model
2025-08-27 21:47:23,558:INFO:K Neighbors Classifier Imported successfully
2025-08-27 21:47:23,583:INFO:Starting cross validation
2025-08-27 21:47:23,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:23,590:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:23,590:WARNING:  warnings.warn(
2025-08-27 21:47:23,785:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,786:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,791:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,792:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,792:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,796:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:47:23,796:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,796:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,796:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,796:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,796:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,796:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,801:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,803:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,803:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

7:23,804:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,807:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,807:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,808:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,810:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,810:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,810:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,811:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,814:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,815:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,815:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,817:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,817:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,817:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,818:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,818:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,820:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,821:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,821:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,826:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,827:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,827:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,827:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,827:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,836:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,836:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,842:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,843:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,845:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,845:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,846:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,846:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,846:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,849:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,915:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,918:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:23,918:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,927:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,927:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,931:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,931:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,931:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,931:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,937:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:23,938:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,940:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,941:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:23,946:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:23,952:INFO:Calculating mean and std
2025-08-27 21:47:23,956:INFO:Creating metrics dataframe
2025-08-27 21:47:23,961:INFO:Uploading results into container
2025-08-27 21:47:23,963:INFO:Uploading model into container now
2025-08-27 21:47:23,963:INFO:_master_model_container: 2
2025-08-27 21:47:23,964:INFO:_display_container: 2
2025-08-27 21:47:23,964:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 21:47:23,964:INFO:create_model() successfully completed......................................
2025-08-27 21:47:24,214:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:24,215:INFO:Creating metrics dataframe
2025-08-27 21:47:24,233:INFO:Initializing Naive Bayes
2025-08-27 21:47:24,233:INFO:Total runtime is 0.18101480801900227 minutes
2025-08-27 21:47:24,243:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:24,244:INFO:Initializing create_model()
2025-08-27 21:47:24,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:24,244:INFO:Checking exceptions
2025-08-27 21:47:24,245:INFO:Importing libraries
2025-08-27 21:47:24,245:INFO:Copying training dataset
2025-08-27 21:47:24,257:INFO:Defining folds
2025-08-27 21:47:24,258:INFO:Declaring metric variables
2025-08-27 21:47:24,267:INFO:Importing untrained model
2025-08-27 21:47:24,274:INFO:Naive Bayes Imported successfully
2025-08-27 21:47:24,294:INFO:Starting cross validation
2025-08-27 21:47:24,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:24,303:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:24,303:WARNING:  warnings.warn(
2025-08-27 21:47:24,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,368:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:47:24,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,379:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,390:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,390:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,395:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,397:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,397:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,402:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,403:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,405:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,405:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,412:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,417:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,419:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,419:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,429:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,431:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,434:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,434:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,434:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,442:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,443:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,443:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,448:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,448:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,448:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,448:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,456:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,456:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,461:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,461:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,462:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,464:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,465:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,465:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,466:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,466:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,467:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,469:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,471:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,471:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,474:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,484:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,489:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,501:INFO:Calculating mean and std
2025-08-27 21:47:24,507:INFO:Creating metrics dataframe
2025-08-27 21:47:24,513:INFO:Uploading results into container
2025-08-27 21:47:24,514:INFO:Uploading model into container now
2025-08-27 21:47:24,515:INFO:_master_model_container: 3
2025-08-27 21:47:24,515:INFO:_display_container: 2
2025-08-27 21:47:24,515:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 21:47:24,515:INFO:create_model() successfully completed......................................
2025-08-27 21:47:24,697:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:24,697:INFO:Creating metrics dataframe
2025-08-27 21:47:24,712:INFO:Initializing Decision Tree Classifier
2025-08-27 21:47:24,712:INFO:Total runtime is 0.18899981578191122 minutes
2025-08-27 21:47:24,726:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:24,726:INFO:Initializing create_model()
2025-08-27 21:47:24,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:24,730:INFO:Checking exceptions
2025-08-27 21:47:24,730:INFO:Importing libraries
2025-08-27 21:47:24,730:INFO:Copying training dataset
2025-08-27 21:47:24,743:INFO:Defining folds
2025-08-27 21:47:24,743:INFO:Declaring metric variables
2025-08-27 21:47:24,751:INFO:Importing untrained model
2025-08-27 21:47:24,764:INFO:Decision Tree Classifier Imported successfully
2025-08-27 21:47:24,797:INFO:Starting cross validation
2025-08-27 21:47:24,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:24,805:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:24,806:WARNING:  warnings.warn(
2025-08-27 21:47:24,878:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:47:24,886:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,892:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,892:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,905:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,906:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,906:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,906:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,911:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,911:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,911:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,920:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,920:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,920:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,922:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,922:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,924:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,924:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,928:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,931:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,939:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,942:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,943:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,943:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,945:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,945:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,953:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,956:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,963:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,963:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,963:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,963:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,973:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,973:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,974:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,977:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:24,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,983:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,983:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,983:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,984:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,990:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,991:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,992:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,995:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,995:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,995:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:24,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:24,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:24,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,001:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,001:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,003:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,014:INFO:Calculating mean and std
2025-08-27 21:47:25,014:INFO:Creating metrics dataframe
2025-08-27 21:47:25,024:INFO:Uploading results into container
2025-08-27 21:47:25,025:INFO:Uploading model into container now
2025-08-27 21:47:25,026:INFO:_master_model_container: 4
2025-08-27 21:47:25,026:INFO:_display_container: 2
2025-08-27 21:47:25,027:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=0, splitter='best')
2025-08-27 21:47:25,027:INFO:create_model() successfully completed......................................
2025-08-27 21:47:25,193:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:25,193:INFO:Creating metrics dataframe
2025-08-27 21:47:25,213:INFO:Initializing SVM - Linear Kernel
2025-08-27 21:47:25,213:INFO:Total runtime is 0.1973577340443929 minutes
2025-08-27 21:47:25,223:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:25,223:INFO:Initializing create_model()
2025-08-27 21:47:25,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:25,223:INFO:Checking exceptions
2025-08-27 21:47:25,223:INFO:Importing libraries
2025-08-27 21:47:25,223:INFO:Copying training dataset
2025-08-27 21:47:25,228:INFO:Defining folds
2025-08-27 21:47:25,228:INFO:Declaring metric variables
2025-08-27 21:47:25,240:INFO:Importing untrained model
2025-08-27 21:47:25,256:INFO:SVM - Linear Kernel Imported successfully
2025-08-27 21:47:25,320:INFO:Starting cross validation
2025-08-27 21:47:25,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:25,352:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:25,352:WARNING:  warnings.warn(
2025-08-27 21:47:25,429:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,431:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,431:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,438:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,438:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,442:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,445:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,447:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,449:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,449:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,449:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,449:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,451:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,451:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,453:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,454:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,454:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,455:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,461:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,461:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,461:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,466:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,466:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,466:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,466:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,467:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,471:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,473:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,479:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,479:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,482:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,485:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,485:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,496:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,503:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,507:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,514:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,520:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,522:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,523:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,535:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 21:47:25,535:WARNING:1 fits failed out of a total of 10.
2025-08-27 21:47:25,535:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 21:47:25,535:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 21:47:25,535:WARNING:
2025-08-27 21:47:25,535:WARNING:Below are more details about the failures:
2025-08-27 21:47:25,535:WARNING:--------------------------------------------------------------------------------
2025-08-27 21:47:25,535:WARNING:1 fits failed with the following error:
2025-08-27 21:47:25,535:WARNING:Traceback (most recent call last):
2025-08-27 21:47:25,535:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 21:47:25,535:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 21:47:25,536:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 21:47:25,536:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 21:47:25,536:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 21:47:25,536:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 21:47:25,536:WARNING:    return self.func(*args, **kwargs)
2025-08-27 21:47:25,536:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:47:25,536:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 21:47:25,536:WARNING:    transformer.fit(*args)
2025-08-27 21:47:25,536:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 21:47:25,536:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 21:47:25,536:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:47:25,536:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 917, in fit
2025-08-27 21:47:25,537:WARNING:    return self._fit(
2025-08-27 21:47:25,537:WARNING:           ^^^^^^^^^^
2025-08-27 21:47:25,537:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 704, in _fit
2025-08-27 21:47:25,537:WARNING:    self._partial_fit(
2025-08-27 21:47:25,537:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 658, in _partial_fit
2025-08-27 21:47:25,537:WARNING:    raise ValueError(
2025-08-27 21:47:25,537:WARNING:ValueError: The number of classes has to be greater than one; got 1 class
2025-08-27 21:47:25,537:WARNING:
2025-08-27 21:47:25,537:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 21:47:25,538:INFO:Calculating mean and std
2025-08-27 21:47:25,541:INFO:Creating metrics dataframe
2025-08-27 21:47:25,554:INFO:Uploading results into container
2025-08-27 21:47:25,557:INFO:Uploading model into container now
2025-08-27 21:47:25,559:INFO:_master_model_container: 5
2025-08-27 21:47:25,559:INFO:_display_container: 2
2025-08-27 21:47:25,561:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=0, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-27 21:47:25,561:INFO:create_model() successfully completed......................................
2025-08-27 21:47:25,741:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:25,741:INFO:Creating metrics dataframe
2025-08-27 21:47:25,766:INFO:Initializing Ridge Classifier
2025-08-27 21:47:25,766:INFO:Total runtime is 0.2065623958905538 minutes
2025-08-27 21:47:25,776:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:25,778:INFO:Initializing create_model()
2025-08-27 21:47:25,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:25,778:INFO:Checking exceptions
2025-08-27 21:47:25,778:INFO:Importing libraries
2025-08-27 21:47:25,778:INFO:Copying training dataset
2025-08-27 21:47:25,792:INFO:Defining folds
2025-08-27 21:47:25,793:INFO:Declaring metric variables
2025-08-27 21:47:25,806:INFO:Importing untrained model
2025-08-27 21:47:25,816:INFO:Ridge Classifier Imported successfully
2025-08-27 21:47:25,844:INFO:Starting cross validation
2025-08-27 21:47:25,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:25,847:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:25,847:WARNING:  warnings.warn(
2025-08-27 21:47:25,918:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,925:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,930:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,934:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,935:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,941:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,942:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,942:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,943:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,944:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,945:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,946:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,949:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,950:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,952:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,956:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,958:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,958:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,958:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,960:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,960:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,964:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,964:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,964:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,965:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,965:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,965:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,965:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,971:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,971:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,972:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,973:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,981:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,982:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,985:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,985:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:25,986:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,989:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,990:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,991:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,991:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,992:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:25,993:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:25,993:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:25,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:26,000:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:26,001:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:26,003:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:26,003:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:26,004:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:26,008:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:26,008:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:26,009:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:26,009:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:26,013:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:26,016:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:26,020:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:26,026:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:26,030:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:26,030:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:26,033:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:26,035:INFO:Calculating mean and std
2025-08-27 21:47:26,037:INFO:Creating metrics dataframe
2025-08-27 21:47:26,043:INFO:Uploading results into container
2025-08-27 21:47:26,045:INFO:Uploading model into container now
2025-08-27 21:47:26,046:INFO:_master_model_container: 6
2025-08-27 21:47:26,046:INFO:_display_container: 2
2025-08-27 21:47:26,047:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=0, solver='auto',
                tol=0.0001)
2025-08-27 21:47:26,047:INFO:create_model() successfully completed......................................
2025-08-27 21:47:26,215:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:26,215:INFO:Creating metrics dataframe
2025-08-27 21:47:26,236:INFO:Initializing Random Forest Classifier
2025-08-27 21:47:26,236:INFO:Total runtime is 0.21440298557281495 minutes
2025-08-27 21:47:26,244:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:26,245:INFO:Initializing create_model()
2025-08-27 21:47:26,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:26,245:INFO:Checking exceptions
2025-08-27 21:47:26,246:INFO:Importing libraries
2025-08-27 21:47:26,246:INFO:Copying training dataset
2025-08-27 21:47:26,253:INFO:Defining folds
2025-08-27 21:47:26,253:INFO:Declaring metric variables
2025-08-27 21:47:26,264:INFO:Importing untrained model
2025-08-27 21:47:26,274:INFO:Random Forest Classifier Imported successfully
2025-08-27 21:47:26,305:INFO:Starting cross validation
2025-08-27 21:47:26,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:26,321:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:26,321:WARNING:  warnings.warn(
2025-08-27 21:47:27,071:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:27,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,083:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,088:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,088:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,095:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,099:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,099:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,102:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,104:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,116:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:27,128:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,135:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:27,141:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,149:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,151:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,152:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,155:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,155:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,158:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,162:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,197:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:47:27,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:27,204:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,210:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,216:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:27,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,222:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,223:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,224:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,227:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,231:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,236:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,239:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,240:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,243:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,258:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:27,265:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,276:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,280:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,281:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,284:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:27,671:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,675:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:27,678:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,679:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,683:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,683:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,683:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,683:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,691:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,693:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:27,696:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,697:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:27,698:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:27,704:INFO:Calculating mean and std
2025-08-27 21:47:27,707:INFO:Creating metrics dataframe
2025-08-27 21:47:27,710:INFO:Uploading results into container
2025-08-27 21:47:27,714:INFO:Uploading model into container now
2025-08-27 21:47:27,714:INFO:_master_model_container: 7
2025-08-27 21:47:27,714:INFO:_display_container: 2
2025-08-27 21:47:27,714:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=0, verbose=0,
                       warm_start=False)
2025-08-27 21:47:27,714:INFO:create_model() successfully completed......................................
2025-08-27 21:47:27,882:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:27,883:INFO:Creating metrics dataframe
2025-08-27 21:47:27,901:INFO:Initializing Quadratic Discriminant Analysis
2025-08-27 21:47:27,904:INFO:Total runtime is 0.24220452706019086 minutes
2025-08-27 21:47:27,912:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:27,913:INFO:Initializing create_model()
2025-08-27 21:47:27,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:27,914:INFO:Checking exceptions
2025-08-27 21:47:27,914:INFO:Importing libraries
2025-08-27 21:47:27,914:INFO:Copying training dataset
2025-08-27 21:47:27,925:INFO:Defining folds
2025-08-27 21:47:27,926:INFO:Declaring metric variables
2025-08-27 21:47:27,936:INFO:Importing untrained model
2025-08-27 21:47:27,945:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 21:47:27,964:INFO:Starting cross validation
2025-08-27 21:47:27,967:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:27,972:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:27,973:WARNING:  warnings.warn(
2025-08-27 21:47:28,061:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-08-27 21:47:28,063:WARNING:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-08-27 21:47:28,064:INFO:Initializing create_model()
2025-08-27 21:47:28,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:28,064:INFO:Checking exceptions
2025-08-27 21:47:28,064:INFO:Importing libraries
2025-08-27 21:47:28,064:INFO:Copying training dataset
2025-08-27 21:47:28,076:INFO:Defining folds
2025-08-27 21:47:28,076:INFO:Declaring metric variables
2025-08-27 21:47:28,085:INFO:Importing untrained model
2025-08-27 21:47:28,094:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 21:47:28,112:INFO:Starting cross validation
2025-08-27 21:47:28,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:28,119:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:28,120:WARNING:  warnings.warn(
2025-08-27 21:47:28,199:ERROR:create_model() for qda raised an exception or returned all 0.0:
2025-08-27 21:47:28,203:ERROR:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-08-27 21:47:28,203:INFO:Initializing Ada Boost Classifier
2025-08-27 21:47:28,203:INFO:Total runtime is 0.24718292554219565 minutes
2025-08-27 21:47:28,208:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:28,209:INFO:Initializing create_model()
2025-08-27 21:47:28,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:28,209:INFO:Checking exceptions
2025-08-27 21:47:28,209:INFO:Importing libraries
2025-08-27 21:47:28,209:INFO:Copying training dataset
2025-08-27 21:47:28,217:INFO:Defining folds
2025-08-27 21:47:28,221:INFO:Declaring metric variables
2025-08-27 21:47:28,229:INFO:Importing untrained model
2025-08-27 21:47:28,237:INFO:Ada Boost Classifier Imported successfully
2025-08-27 21:47:28,259:INFO:Starting cross validation
2025-08-27 21:47:28,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:28,267:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:28,267:WARNING:  warnings.warn(
2025-08-27 21:47:28,305:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,307:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,307:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,319:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,335:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,346:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,352:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,363:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,364:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,369:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,369:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,369:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,374:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,374:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,381:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,381:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,382:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,383:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,385:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,386:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,386:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,386:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,391:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,393:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,394:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,395:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,395:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,395:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,396:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,397:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,399:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,401:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,402:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,402:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,402:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,405:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,405:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,405:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,405:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,414:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,414:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,416:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,416:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,416:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,416:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,416:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,424:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,425:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 21:47:28,426:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,431:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,432:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,432:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,432:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,439:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,442:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,442:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,447:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,447:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:28,453:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,455:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,464:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,467:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,467:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:28,467:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,469:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,469:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:28,471:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:28,478:INFO:Calculating mean and std
2025-08-27 21:47:28,480:INFO:Creating metrics dataframe
2025-08-27 21:47:28,486:INFO:Uploading results into container
2025-08-27 21:47:28,487:INFO:Uploading model into container now
2025-08-27 21:47:28,487:INFO:_master_model_container: 8
2025-08-27 21:47:28,487:INFO:_display_container: 2
2025-08-27 21:47:28,487:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=0)
2025-08-27 21:47:28,487:INFO:create_model() successfully completed......................................
2025-08-27 21:47:28,719:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:28,719:INFO:Creating metrics dataframe
2025-08-27 21:47:28,750:INFO:Initializing Gradient Boosting Classifier
2025-08-27 21:47:28,750:INFO:Total runtime is 0.25630077521006267 minutes
2025-08-27 21:47:28,779:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:28,780:INFO:Initializing create_model()
2025-08-27 21:47:28,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:28,781:INFO:Checking exceptions
2025-08-27 21:47:28,781:INFO:Importing libraries
2025-08-27 21:47:28,782:INFO:Copying training dataset
2025-08-27 21:47:28,797:INFO:Defining folds
2025-08-27 21:47:28,798:INFO:Declaring metric variables
2025-08-27 21:47:28,814:INFO:Importing untrained model
2025-08-27 21:47:28,823:INFO:Gradient Boosting Classifier Imported successfully
2025-08-27 21:47:28,844:INFO:Starting cross validation
2025-08-27 21:47:28,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:28,854:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:28,854:WARNING:  warnings.warn(
2025-08-27 21:47:29,251:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,257:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,274:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,283:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,284:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,287:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,289:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,291:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,297:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,297:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,299:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,301:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,301:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,307:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,307:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,314:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,315:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,318:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,319:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,321:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,327:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,332:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,336:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,336:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,336:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,339:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,340:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,342:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,348:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,352:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,352:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,362:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,362:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,368:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,369:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,370:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,372:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,374:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,381:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,387:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,387:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,388:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,388:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,388:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,394:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,404:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,409:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,418:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,420:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,421:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,424:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,651:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:29,654:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,669:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:29,669:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,669:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:29,674:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:29,685:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 21:47:29,686:WARNING:1 fits failed out of a total of 10.
2025-08-27 21:47:29,686:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 21:47:29,686:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 21:47:29,686:WARNING:
2025-08-27 21:47:29,686:WARNING:Below are more details about the failures:
2025-08-27 21:47:29,686:WARNING:--------------------------------------------------------------------------------
2025-08-27 21:47:29,686:WARNING:1 fits failed with the following error:
2025-08-27 21:47:29,686:WARNING:Traceback (most recent call last):
2025-08-27 21:47:29,686:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 21:47:29,686:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 21:47:29,686:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 21:47:29,686:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 21:47:29,686:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 21:47:29,687:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 21:47:29,687:WARNING:    return self.func(*args, **kwargs)
2025-08-27 21:47:29,687:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:47:29,687:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 21:47:29,687:WARNING:    transformer.fit(*args)
2025-08-27 21:47:29,687:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 21:47:29,687:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 21:47:29,687:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:47:29,688:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_gb.py", line 665, in fit
2025-08-27 21:47:29,688:WARNING:    y = self._encode_y(y=y, sample_weight=None)
2025-08-27 21:47:29,688:WARNING:        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 21:47:29,688:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_gb.py", line 1520, in _encode_y
2025-08-27 21:47:29,688:WARNING:    raise ValueError(
2025-08-27 21:47:29,688:WARNING:ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.
2025-08-27 21:47:29,688:WARNING:
2025-08-27 21:47:29,688:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 21:47:29,689:INFO:Calculating mean and std
2025-08-27 21:47:29,689:INFO:Creating metrics dataframe
2025-08-27 21:47:29,695:INFO:Uploading results into container
2025-08-27 21:47:29,699:INFO:Uploading model into container now
2025-08-27 21:47:29,700:INFO:_master_model_container: 9
2025-08-27 21:47:29,700:INFO:_display_container: 2
2025-08-27 21:47:29,702:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=0, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-27 21:47:29,702:INFO:create_model() successfully completed......................................
2025-08-27 21:47:30,053:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:30,053:INFO:Creating metrics dataframe
2025-08-27 21:47:30,078:INFO:Initializing Linear Discriminant Analysis
2025-08-27 21:47:30,078:INFO:Total runtime is 0.27844203313191734 minutes
2025-08-27 21:47:30,088:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:30,089:INFO:Initializing create_model()
2025-08-27 21:47:30,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:30,089:INFO:Checking exceptions
2025-08-27 21:47:30,089:INFO:Importing libraries
2025-08-27 21:47:30,090:INFO:Copying training dataset
2025-08-27 21:47:30,101:INFO:Defining folds
2025-08-27 21:47:30,102:INFO:Declaring metric variables
2025-08-27 21:47:30,110:INFO:Importing untrained model
2025-08-27 21:47:30,124:INFO:Linear Discriminant Analysis Imported successfully
2025-08-27 21:47:30,153:INFO:Starting cross validation
2025-08-27 21:47:30,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:30,161:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:30,161:WARNING:  warnings.warn(
2025-08-27 21:47:30,222:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,225:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,231:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,232:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,237:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,238:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,243:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,249:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,252:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,253:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,255:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,255:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,259:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,263:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,266:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,269:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,272:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,272:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,272:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,272:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,276:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,277:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,277:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,282:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,285:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,287:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,289:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,296:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,297:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,300:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,303:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,308:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,310:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,317:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,321:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,322:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,323:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,325:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

ier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,325:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,329:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,334:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,335:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,335:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,337:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,339:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,340:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,341:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,341:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,343:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,351:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,354:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,355:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:30,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,360:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,370:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,374:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:30,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,380:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:30,385:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:30,398:INFO:Calculating mean and std
2025-08-27 21:47:30,401:INFO:Creating metrics dataframe
2025-08-27 21:47:30,406:INFO:Uploading results into container
2025-08-27 21:47:30,406:INFO:Uploading model into container now
2025-08-27 21:47:30,406:INFO:_master_model_container: 10
2025-08-27 21:47:30,406:INFO:_display_container: 2
2025-08-27 21:47:30,406:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-08-27 21:47:30,406:INFO:create_model() successfully completed......................................
2025-08-27 21:47:30,611:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:30,612:INFO:Creating metrics dataframe
2025-08-27 21:47:30,637:INFO:Initializing Extra Trees Classifier
2025-08-27 21:47:30,637:INFO:Total runtime is 0.2877525130907695 minutes
2025-08-27 21:47:30,648:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:30,649:INFO:Initializing create_model()
2025-08-27 21:47:30,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:30,651:INFO:Checking exceptions
2025-08-27 21:47:30,651:INFO:Importing libraries
2025-08-27 21:47:30,651:INFO:Copying training dataset
2025-08-27 21:47:30,663:INFO:Defining folds
2025-08-27 21:47:30,665:INFO:Declaring metric variables
2025-08-27 21:47:30,674:INFO:Importing untrained model
2025-08-27 21:47:30,685:INFO:Extra Trees Classifier Imported successfully
2025-08-27 21:47:30,707:INFO:Starting cross validation
2025-08-27 21:47:30,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:30,714:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:30,714:WARNING:  warnings.warn(
2025-08-27 21:47:31,257:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,257:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,264:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,273:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,274:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,279:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,280:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,282:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,282:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,282:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,285:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,287:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,290:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,291:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,293:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,293:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,295:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,297:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,297:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,306:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,308:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,308:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,309:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,314:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,321:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,324:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,324:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,328:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:47:31,335:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,340:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,368:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,374:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,384:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,389:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,393:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,394:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,401:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,438:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,453:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,453:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,458:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,476:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,485:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,746:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,756:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:31,761:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,764:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,766:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,766:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,773:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:31,776:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,776:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:31,778:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:31,783:INFO:Calculating mean and std
2025-08-27 21:47:31,786:INFO:Creating metrics dataframe
2025-08-27 21:47:31,791:INFO:Uploading results into container
2025-08-27 21:47:31,792:INFO:Uploading model into container now
2025-08-27 21:47:31,792:INFO:_master_model_container: 11
2025-08-27 21:47:31,792:INFO:_display_container: 2
2025-08-27 21:47:31,793:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=0, verbose=0,
                     warm_start=False)
2025-08-27 21:47:31,793:INFO:create_model() successfully completed......................................
2025-08-27 21:47:31,959:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:31,959:INFO:Creating metrics dataframe
2025-08-27 21:47:32,040:INFO:Initializing Light Gradient Boosting Machine
2025-08-27 21:47:32,040:INFO:Total runtime is 0.3111420869827271 minutes
2025-08-27 21:47:32,056:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:32,057:INFO:Initializing create_model()
2025-08-27 21:47:32,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:32,057:INFO:Checking exceptions
2025-08-27 21:47:32,057:INFO:Importing libraries
2025-08-27 21:47:32,057:INFO:Copying training dataset
2025-08-27 21:47:32,088:INFO:Defining folds
2025-08-27 21:47:32,088:INFO:Declaring metric variables
2025-08-27 21:47:32,105:INFO:Importing untrained model
2025-08-27 21:47:32,123:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-27 21:47:32,175:INFO:Starting cross validation
2025-08-27 21:47:32,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:32,188:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:32,188:WARNING:  warnings.warn(
2025-08-27 21:47:32,511:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,163:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,176:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,185:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,188:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,188:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,193:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,220:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,222:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,275:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,280:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,285:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,288:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,290:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,290:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,291:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,294:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,295:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,295:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,308:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,313:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,324:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,342:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,353:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,357:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,357:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,386:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,395:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,406:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,419:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,426:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,427:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,433:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,440:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,497:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,514:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,522:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,530:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,533:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,540:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,545:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,545:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,553:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,613:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,623:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,630:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,639:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,657:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,730:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:33,739:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,744:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,756:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:33,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:33,766:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:33,773:INFO:Calculating mean and std
2025-08-27 21:47:33,775:INFO:Creating metrics dataframe
2025-08-27 21:47:33,789:INFO:Uploading results into container
2025-08-27 21:47:33,790:INFO:Uploading model into container now
2025-08-27 21:47:33,791:INFO:_master_model_container: 12
2025-08-27 21:47:33,791:INFO:_display_container: 2
2025-08-27 21:47:33,792:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=0, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-27 21:47:33,792:INFO:create_model() successfully completed......................................
2025-08-27 21:47:34,001:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:34,002:INFO:Creating metrics dataframe
2025-08-27 21:47:34,036:INFO:Initializing Dummy Classifier
2025-08-27 21:47:34,036:INFO:Total runtime is 0.34440624316533414 minutes
2025-08-27 21:47:34,044:INFO:SubProcess create_model() called ==================================
2025-08-27 21:47:34,045:INFO:Initializing create_model()
2025-08-27 21:47:34,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B68514810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:34,045:INFO:Checking exceptions
2025-08-27 21:47:34,045:INFO:Importing libraries
2025-08-27 21:47:34,045:INFO:Copying training dataset
2025-08-27 21:47:34,071:INFO:Defining folds
2025-08-27 21:47:34,071:INFO:Declaring metric variables
2025-08-27 21:47:34,076:INFO:Importing untrained model
2025-08-27 21:47:34,095:INFO:Dummy Classifier Imported successfully
2025-08-27 21:47:34,118:INFO:Starting cross validation
2025-08-27 21:47:34,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 21:47:34,126:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 21:47:34,126:WARNING:  warnings.warn(
2025-08-27 21:47:34,177:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,177:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 21:47:34,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,189:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,190:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,192:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,193:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,193:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,194:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,202:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,203:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,204:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,205:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,205:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,220:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,220:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,221:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,224:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,224:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,224:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,231:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,238:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,238:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,241:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,242:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,243:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,243:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,243:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,255:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,257:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,257:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,258:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,258:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,258:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 21:47:34,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,260:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,263:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,268:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,268:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,271:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,272:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,275:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,276:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,279:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 21:47:34,279:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,279:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,283:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,284:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 21:47:34,285:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,288:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 21:47:34,299:INFO:Calculating mean and std
2025-08-27 21:47:34,308:INFO:Creating metrics dataframe
2025-08-27 21:47:34,310:INFO:Uploading results into container
2025-08-27 21:47:34,310:INFO:Uploading model into container now
2025-08-27 21:47:34,313:INFO:_master_model_container: 13
2025-08-27 21:47:34,314:INFO:_display_container: 2
2025-08-27 21:47:34,314:INFO:DummyClassifier(constant=None, random_state=0, strategy='prior')
2025-08-27 21:47:34,314:INFO:create_model() successfully completed......................................
2025-08-27 21:47:34,510:INFO:SubProcess create_model() end ==================================
2025-08-27 21:47:34,510:INFO:Creating metrics dataframe
2025-08-27 21:47:34,564:INFO:Initializing create_model()
2025-08-27 21:47:34,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 21:47:34,565:INFO:Checking exceptions
2025-08-27 21:47:34,570:INFO:Importing libraries
2025-08-27 21:47:34,570:INFO:Copying training dataset
2025-08-27 21:47:34,579:INFO:Defining folds
2025-08-27 21:47:34,580:INFO:Declaring metric variables
2025-08-27 21:47:34,580:INFO:Importing untrained model
2025-08-27 21:47:34,580:INFO:Declaring custom model
2025-08-27 21:47:34,583:INFO:Logistic Regression Imported successfully
2025-08-27 21:47:34,587:INFO:Cross validation set to False
2025-08-27 21:47:34,587:INFO:Fitting Model
2025-08-27 21:47:34,638:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 21:47:34,638:INFO:create_model() successfully completed......................................
2025-08-27 21:47:34,896:INFO:_master_model_container: 13
2025-08-27 21:47:34,898:INFO:_display_container: 2
2025-08-27 21:47:34,898:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 21:47:34,899:INFO:compare_models() successfully completed......................................
2025-08-27 21:47:34,903:INFO:Initializing plot_model()
2025-08-27 21:47:34,903:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6E347F50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-27 21:47:34,903:INFO:Checking exceptions
2025-08-27 21:47:34,913:INFO:Preloading libraries
2025-08-27 21:47:34,913:INFO:Copying training dataset
2025-08-27 21:47:34,913:INFO:Plot type: confusion_matrix
2025-08-27 21:47:35,074:INFO:Fitting Model
2025-08-27 21:47:35,074:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
2025-08-27 21:47:35,074:WARNING:  warnings.warn(
2025-08-27 21:47:35,074:INFO:Scoring test/hold-out set
2025-08-27 21:47:35,440:INFO:Visual Rendered Successfully
2025-08-27 21:47:35,629:INFO:plot_model() successfully completed......................................
2025-08-27 21:58:37,521:INFO:PyCaret ClassificationExperiment
2025-08-27 21:58:37,521:INFO:Logging name: clf-default-name
2025-08-27 21:58:37,521:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 21:58:37,521:INFO:version 3.3.2
2025-08-27 21:58:37,521:INFO:Initializing setup()
2025-08-27 21:58:37,521:INFO:self.USI: a59b
2025-08-27 21:58:37,521:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 21:58:37,521:INFO:Checking environment
2025-08-27 21:58:37,522:INFO:python_version: 3.11.9
2025-08-27 21:58:37,522:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 21:58:37,522:INFO:machine: AMD64
2025-08-27 21:58:37,522:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 21:58:37,526:INFO:Memory: svmem(total=17024348160, available=729493504, percent=95.7, used=16294854656, free=729493504)
2025-08-27 21:58:37,527:INFO:Physical Core: 4
2025-08-27 21:58:37,527:INFO:Logical Core: 8
2025-08-27 21:58:37,527:INFO:Checking libraries
2025-08-27 21:58:37,527:INFO:System:
2025-08-27 21:58:37,527:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 21:58:37,528:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 21:58:37,528:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 21:58:37,528:INFO:PyCaret required dependencies:
2025-08-27 21:58:37,528:INFO:                 pip: Not installed
2025-08-27 21:58:37,528:INFO:          setuptools: 80.9.0
2025-08-27 21:58:37,528:INFO:             pycaret: 3.3.2
2025-08-27 21:58:37,528:INFO:             IPython: 9.4.0
2025-08-27 21:58:37,529:INFO:          ipywidgets: 8.1.7
2025-08-27 21:58:37,529:INFO:                tqdm: 4.67.1
2025-08-27 21:58:37,529:INFO:               numpy: 1.26.4
2025-08-27 21:58:37,529:INFO:              pandas: 2.1.4
2025-08-27 21:58:37,529:INFO:              jinja2: 3.1.6
2025-08-27 21:58:37,529:INFO:               scipy: 1.11.4
2025-08-27 21:58:37,529:INFO:              joblib: 1.3.2
2025-08-27 21:58:37,529:INFO:             sklearn: 1.4.2
2025-08-27 21:58:37,529:INFO:                pyod: 2.0.5
2025-08-27 21:58:37,530:INFO:            imblearn: 0.14.0
2025-08-27 21:58:37,530:INFO:   category_encoders: 2.7.0
2025-08-27 21:58:37,530:INFO:            lightgbm: 4.6.0
2025-08-27 21:58:37,530:INFO:               numba: 0.61.2
2025-08-27 21:58:37,530:INFO:            requests: 2.32.5
2025-08-27 21:58:37,530:INFO:          matplotlib: 3.7.5
2025-08-27 21:58:37,530:INFO:          scikitplot: 0.3.7
2025-08-27 21:58:37,530:INFO:         yellowbrick: 1.5
2025-08-27 21:58:37,531:INFO:              plotly: 5.24.1
2025-08-27 21:58:37,531:INFO:    plotly-resampler: Not installed
2025-08-27 21:58:37,531:INFO:             kaleido: 1.0.0
2025-08-27 21:58:37,531:INFO:           schemdraw: 0.15
2025-08-27 21:58:37,531:INFO:         statsmodels: 0.14.5
2025-08-27 21:58:37,531:INFO:              sktime: 0.26.0
2025-08-27 21:58:37,531:INFO:               tbats: 1.1.3
2025-08-27 21:58:37,531:INFO:            pmdarima: 2.0.4
2025-08-27 21:58:37,531:INFO:              psutil: 7.0.0
2025-08-27 21:58:37,531:INFO:          markupsafe: 3.0.2
2025-08-27 21:58:37,531:INFO:             pickle5: Not installed
2025-08-27 21:58:37,531:INFO:         cloudpickle: 3.1.1
2025-08-27 21:58:37,531:INFO:         deprecation: 2.1.0
2025-08-27 21:58:37,531:INFO:              xxhash: 3.5.0
2025-08-27 21:58:37,531:INFO:           wurlitzer: Not installed
2025-08-27 21:58:37,531:INFO:PyCaret optional dependencies:
2025-08-27 21:58:37,532:INFO:                shap: Not installed
2025-08-27 21:58:37,532:INFO:           interpret: Not installed
2025-08-27 21:58:37,532:INFO:                umap: Not installed
2025-08-27 21:58:37,532:INFO:     ydata_profiling: Not installed
2025-08-27 21:58:37,532:INFO:  explainerdashboard: Not installed
2025-08-27 21:58:37,532:INFO:             autoviz: Not installed
2025-08-27 21:58:37,532:INFO:           fairlearn: Not installed
2025-08-27 21:58:37,532:INFO:          deepchecks: Not installed
2025-08-27 21:58:37,532:INFO:             xgboost: Not installed
2025-08-27 21:58:37,532:INFO:            catboost: Not installed
2025-08-27 21:58:37,532:INFO:              kmodes: Not installed
2025-08-27 21:58:37,532:INFO:             mlxtend: Not installed
2025-08-27 21:58:37,533:INFO:       statsforecast: Not installed
2025-08-27 21:58:37,533:INFO:        tune_sklearn: Not installed
2025-08-27 21:58:37,533:INFO:                 ray: Not installed
2025-08-27 21:58:37,533:INFO:            hyperopt: Not installed
2025-08-27 21:58:37,533:INFO:              optuna: Not installed
2025-08-27 21:58:37,533:INFO:               skopt: Not installed
2025-08-27 21:58:37,533:INFO:              mlflow: Not installed
2025-08-27 21:58:37,533:INFO:              gradio: Not installed
2025-08-27 21:58:37,533:INFO:             fastapi: Not installed
2025-08-27 21:58:37,533:INFO:             uvicorn: Not installed
2025-08-27 21:58:37,533:INFO:              m2cgen: Not installed
2025-08-27 21:58:37,533:INFO:           evidently: Not installed
2025-08-27 21:58:37,533:INFO:               fugue: Not installed
2025-08-27 21:58:37,533:INFO:           streamlit: Not installed
2025-08-27 21:58:37,533:INFO:             prophet: Not installed
2025-08-27 21:58:37,533:INFO:None
2025-08-27 21:58:37,533:INFO:Set up data.
2025-08-27 21:58:37,538:INFO:Set up folding strategy.
2025-08-27 21:58:37,539:INFO:Set up train/test split.
2025-08-27 21:58:37,539:INFO:Set up index.
2025-08-27 21:58:37,544:INFO:Assigning column types.
2025-08-27 21:58:37,549:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 21:58:37,668:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:58:37,669:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:58:37,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:37,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:37,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:58:37,768:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:58:37,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:37,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:37,802:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 21:58:37,858:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:58:37,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:37,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:37,937:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:58:37,975:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:37,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:37,975:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 21:58:38,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:38,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:38,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:38,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:58:38,271:INFO:Preparing preprocessing pipeline...
2025-08-27 21:58:38,272:INFO:Set up simple imputation.
2025-08-27 21:58:38,272:INFO:Set up imbalanced handling.
2025-08-27 21:58:38,303:INFO:Finished creating preprocessing pipeline.
2025-08-27 21:58:38,304:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=0,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-08-27 21:58:38,304:INFO:Creating final display dataframe.
2025-08-27 21:59:22,717:INFO:PyCaret ClassificationExperiment
2025-08-27 21:59:22,717:INFO:Logging name: clf-default-name
2025-08-27 21:59:22,717:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 21:59:22,718:INFO:version 3.3.2
2025-08-27 21:59:22,718:INFO:Initializing setup()
2025-08-27 21:59:22,718:INFO:self.USI: 32b9
2025-08-27 21:59:22,718:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 21:59:22,718:INFO:Checking environment
2025-08-27 21:59:22,718:INFO:python_version: 3.11.9
2025-08-27 21:59:22,718:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 21:59:22,718:INFO:machine: AMD64
2025-08-27 21:59:22,718:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 21:59:22,721:INFO:Memory: svmem(total=17024348160, available=659644416, percent=96.1, used=16364703744, free=659644416)
2025-08-27 21:59:22,721:INFO:Physical Core: 4
2025-08-27 21:59:22,722:INFO:Logical Core: 8
2025-08-27 21:59:22,722:INFO:Checking libraries
2025-08-27 21:59:22,722:INFO:System:
2025-08-27 21:59:22,722:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 21:59:22,722:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 21:59:22,722:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 21:59:22,722:INFO:PyCaret required dependencies:
2025-08-27 21:59:22,722:INFO:                 pip: Not installed
2025-08-27 21:59:22,722:INFO:          setuptools: 80.9.0
2025-08-27 21:59:22,722:INFO:             pycaret: 3.3.2
2025-08-27 21:59:22,722:INFO:             IPython: 9.4.0
2025-08-27 21:59:22,722:INFO:          ipywidgets: 8.1.7
2025-08-27 21:59:22,722:INFO:                tqdm: 4.67.1
2025-08-27 21:59:22,722:INFO:               numpy: 1.26.4
2025-08-27 21:59:22,722:INFO:              pandas: 2.1.4
2025-08-27 21:59:22,722:INFO:              jinja2: 3.1.6
2025-08-27 21:59:22,722:INFO:               scipy: 1.11.4
2025-08-27 21:59:22,722:INFO:              joblib: 1.3.2
2025-08-27 21:59:22,722:INFO:             sklearn: 1.4.2
2025-08-27 21:59:22,722:INFO:                pyod: 2.0.5
2025-08-27 21:59:22,722:INFO:            imblearn: 0.14.0
2025-08-27 21:59:22,722:INFO:   category_encoders: 2.7.0
2025-08-27 21:59:22,722:INFO:            lightgbm: 4.6.0
2025-08-27 21:59:22,722:INFO:               numba: 0.61.2
2025-08-27 21:59:22,722:INFO:            requests: 2.32.5
2025-08-27 21:59:22,722:INFO:          matplotlib: 3.7.5
2025-08-27 21:59:22,722:INFO:          scikitplot: 0.3.7
2025-08-27 21:59:22,722:INFO:         yellowbrick: 1.5
2025-08-27 21:59:22,722:INFO:              plotly: 5.24.1
2025-08-27 21:59:22,722:INFO:    plotly-resampler: Not installed
2025-08-27 21:59:22,722:INFO:             kaleido: 1.0.0
2025-08-27 21:59:22,722:INFO:           schemdraw: 0.15
2025-08-27 21:59:22,722:INFO:         statsmodels: 0.14.5
2025-08-27 21:59:22,722:INFO:              sktime: 0.26.0
2025-08-27 21:59:22,722:INFO:               tbats: 1.1.3
2025-08-27 21:59:22,722:INFO:            pmdarima: 2.0.4
2025-08-27 21:59:22,722:INFO:              psutil: 7.0.0
2025-08-27 21:59:22,722:INFO:          markupsafe: 3.0.2
2025-08-27 21:59:22,722:INFO:             pickle5: Not installed
2025-08-27 21:59:22,722:INFO:         cloudpickle: 3.1.1
2025-08-27 21:59:22,722:INFO:         deprecation: 2.1.0
2025-08-27 21:59:22,722:INFO:              xxhash: 3.5.0
2025-08-27 21:59:22,722:INFO:           wurlitzer: Not installed
2025-08-27 21:59:22,722:INFO:PyCaret optional dependencies:
2025-08-27 21:59:22,722:INFO:                shap: Not installed
2025-08-27 21:59:22,722:INFO:           interpret: Not installed
2025-08-27 21:59:22,722:INFO:                umap: Not installed
2025-08-27 21:59:22,722:INFO:     ydata_profiling: Not installed
2025-08-27 21:59:22,722:INFO:  explainerdashboard: Not installed
2025-08-27 21:59:22,722:INFO:             autoviz: Not installed
2025-08-27 21:59:22,722:INFO:           fairlearn: Not installed
2025-08-27 21:59:22,722:INFO:          deepchecks: Not installed
2025-08-27 21:59:22,722:INFO:             xgboost: Not installed
2025-08-27 21:59:22,722:INFO:            catboost: Not installed
2025-08-27 21:59:22,722:INFO:              kmodes: Not installed
2025-08-27 21:59:22,722:INFO:             mlxtend: Not installed
2025-08-27 21:59:22,722:INFO:       statsforecast: Not installed
2025-08-27 21:59:22,722:INFO:        tune_sklearn: Not installed
2025-08-27 21:59:22,722:INFO:                 ray: Not installed
2025-08-27 21:59:22,722:INFO:            hyperopt: Not installed
2025-08-27 21:59:22,722:INFO:              optuna: Not installed
2025-08-27 21:59:22,722:INFO:               skopt: Not installed
2025-08-27 21:59:22,722:INFO:              mlflow: Not installed
2025-08-27 21:59:22,722:INFO:              gradio: Not installed
2025-08-27 21:59:22,722:INFO:             fastapi: Not installed
2025-08-27 21:59:22,722:INFO:             uvicorn: Not installed
2025-08-27 21:59:22,722:INFO:              m2cgen: Not installed
2025-08-27 21:59:22,722:INFO:           evidently: Not installed
2025-08-27 21:59:22,722:INFO:               fugue: Not installed
2025-08-27 21:59:22,722:INFO:           streamlit: Not installed
2025-08-27 21:59:22,722:INFO:             prophet: Not installed
2025-08-27 21:59:22,722:INFO:None
2025-08-27 21:59:22,722:INFO:Set up data.
2025-08-27 21:59:22,722:INFO:Set up folding strategy.
2025-08-27 21:59:22,722:INFO:Set up train/test split.
2025-08-27 21:59:22,734:INFO:Set up index.
2025-08-27 21:59:22,734:INFO:Assigning column types.
2025-08-27 21:59:22,734:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 21:59:22,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:59:22,787:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:59:22,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:22,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:22,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 21:59:22,997:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:59:23,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,096:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 21:59:23,167:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:59:23,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,250:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 21:59:23,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,280:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 21:59:23,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 21:59:23,574:INFO:Preparing preprocessing pipeline...
2025-08-27 21:59:23,581:INFO:Set up simple imputation.
2025-08-27 21:59:23,581:INFO:Set up imbalanced handling.
2025-08-27 21:59:23,606:INFO:Finished creating preprocessing pipeline.
2025-08-27 21:59:23,606:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=0,
                                                                              sampling_strategy='auto'))))],
         verbose=False)
2025-08-27 21:59:23,606:INFO:Creating final display dataframe.
2025-08-27 22:01:09,806:INFO:PyCaret ClassificationExperiment
2025-08-27 22:01:09,806:INFO:Logging name: clf-default-name
2025-08-27 22:01:09,806:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 22:01:09,806:INFO:version 3.3.2
2025-08-27 22:01:09,806:INFO:Initializing setup()
2025-08-27 22:01:09,806:INFO:self.USI: c865
2025-08-27 22:01:09,806:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 22:01:09,806:INFO:Checking environment
2025-08-27 22:01:09,807:INFO:python_version: 3.11.9
2025-08-27 22:01:09,807:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 22:01:09,807:INFO:machine: AMD64
2025-08-27 22:01:09,807:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 22:01:09,813:INFO:Memory: svmem(total=17024348160, available=658731008, percent=96.1, used=16365617152, free=658731008)
2025-08-27 22:01:09,813:INFO:Physical Core: 4
2025-08-27 22:01:09,814:INFO:Logical Core: 8
2025-08-27 22:01:09,814:INFO:Checking libraries
2025-08-27 22:01:09,814:INFO:System:
2025-08-27 22:01:09,814:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 22:01:09,814:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 22:01:09,814:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 22:01:09,814:INFO:PyCaret required dependencies:
2025-08-27 22:01:09,814:INFO:                 pip: Not installed
2025-08-27 22:01:09,814:INFO:          setuptools: 80.9.0
2025-08-27 22:01:09,814:INFO:             pycaret: 3.3.2
2025-08-27 22:01:09,814:INFO:             IPython: 9.4.0
2025-08-27 22:01:09,814:INFO:          ipywidgets: 8.1.7
2025-08-27 22:01:09,814:INFO:                tqdm: 4.67.1
2025-08-27 22:01:09,814:INFO:               numpy: 1.26.4
2025-08-27 22:01:09,814:INFO:              pandas: 2.1.4
2025-08-27 22:01:09,814:INFO:              jinja2: 3.1.6
2025-08-27 22:01:09,814:INFO:               scipy: 1.11.4
2025-08-27 22:01:09,815:INFO:              joblib: 1.3.2
2025-08-27 22:01:09,815:INFO:             sklearn: 1.4.2
2025-08-27 22:01:09,815:INFO:                pyod: 2.0.5
2025-08-27 22:01:09,815:INFO:            imblearn: 0.14.0
2025-08-27 22:01:09,815:INFO:   category_encoders: 2.7.0
2025-08-27 22:01:09,815:INFO:            lightgbm: 4.6.0
2025-08-27 22:01:09,815:INFO:               numba: 0.61.2
2025-08-27 22:01:09,815:INFO:            requests: 2.32.5
2025-08-27 22:01:09,815:INFO:          matplotlib: 3.7.5
2025-08-27 22:01:09,815:INFO:          scikitplot: 0.3.7
2025-08-27 22:01:09,815:INFO:         yellowbrick: 1.5
2025-08-27 22:01:09,815:INFO:              plotly: 5.24.1
2025-08-27 22:01:09,815:INFO:    plotly-resampler: Not installed
2025-08-27 22:01:09,815:INFO:             kaleido: 1.0.0
2025-08-27 22:01:09,815:INFO:           schemdraw: 0.15
2025-08-27 22:01:09,815:INFO:         statsmodels: 0.14.5
2025-08-27 22:01:09,815:INFO:              sktime: 0.26.0
2025-08-27 22:01:09,815:INFO:               tbats: 1.1.3
2025-08-27 22:01:09,815:INFO:            pmdarima: 2.0.4
2025-08-27 22:01:09,817:INFO:              psutil: 7.0.0
2025-08-27 22:01:09,817:INFO:          markupsafe: 3.0.2
2025-08-27 22:01:09,817:INFO:             pickle5: Not installed
2025-08-27 22:01:09,817:INFO:         cloudpickle: 3.1.1
2025-08-27 22:01:09,817:INFO:         deprecation: 2.1.0
2025-08-27 22:01:09,817:INFO:              xxhash: 3.5.0
2025-08-27 22:01:09,817:INFO:           wurlitzer: Not installed
2025-08-27 22:01:09,817:INFO:PyCaret optional dependencies:
2025-08-27 22:01:09,818:INFO:                shap: Not installed
2025-08-27 22:01:09,818:INFO:           interpret: Not installed
2025-08-27 22:01:09,818:INFO:                umap: Not installed
2025-08-27 22:01:09,818:INFO:     ydata_profiling: Not installed
2025-08-27 22:01:09,818:INFO:  explainerdashboard: Not installed
2025-08-27 22:01:09,819:INFO:             autoviz: Not installed
2025-08-27 22:01:09,819:INFO:           fairlearn: Not installed
2025-08-27 22:01:09,819:INFO:          deepchecks: Not installed
2025-08-27 22:01:09,819:INFO:             xgboost: Not installed
2025-08-27 22:01:09,819:INFO:            catboost: Not installed
2025-08-27 22:01:09,819:INFO:              kmodes: Not installed
2025-08-27 22:01:09,819:INFO:             mlxtend: Not installed
2025-08-27 22:01:09,819:INFO:       statsforecast: Not installed
2025-08-27 22:01:09,819:INFO:        tune_sklearn: Not installed
2025-08-27 22:01:09,819:INFO:                 ray: Not installed
2025-08-27 22:01:09,819:INFO:            hyperopt: Not installed
2025-08-27 22:01:09,820:INFO:              optuna: Not installed
2025-08-27 22:01:09,820:INFO:               skopt: Not installed
2025-08-27 22:01:09,820:INFO:              mlflow: Not installed
2025-08-27 22:01:09,820:INFO:              gradio: Not installed
2025-08-27 22:01:09,820:INFO:             fastapi: Not installed
2025-08-27 22:01:09,820:INFO:             uvicorn: Not installed
2025-08-27 22:01:09,820:INFO:              m2cgen: Not installed
2025-08-27 22:01:09,820:INFO:           evidently: Not installed
2025-08-27 22:01:09,820:INFO:               fugue: Not installed
2025-08-27 22:01:09,820:INFO:           streamlit: Not installed
2025-08-27 22:01:09,820:INFO:             prophet: Not installed
2025-08-27 22:01:09,820:INFO:None
2025-08-27 22:01:09,821:INFO:Set up data.
2025-08-27 22:01:09,825:INFO:Set up folding strategy.
2025-08-27 22:01:09,825:INFO:Set up train/test split.
2025-08-27 22:01:09,833:INFO:Set up index.
2025-08-27 22:01:09,833:INFO:Assigning column types.
2025-08-27 22:01:09,839:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 22:01:09,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 22:01:09,898:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 22:01:09,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:09,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,006:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 22:01:10,006:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 22:01:10,051:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,051:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 22:01:10,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 22:01:10,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,215:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 22:01:10,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,262:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 22:01:10,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,472:INFO:Preparing preprocessing pipeline...
2025-08-27 22:01:10,474:INFO:Set up simple imputation.
2025-08-27 22:01:10,490:INFO:Finished creating preprocessing pipeline.
2025-08-27 22:01:10,490:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-27 22:01:10,490:INFO:Creating final display dataframe.
2025-08-27 22:01:10,632:INFO:Setup _display_container:                     Description             Value
0                    Session id                 0
1                        Target           failure
2                   Target type            Binary
3           Original data shape          (989, 6)
4        Transformed data shape          (989, 6)
5   Transformed train set shape          (692, 6)
6    Transformed test set shape          (297, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c865
2025-08-27 22:01:10,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:01:10,916:INFO:setup() successfully completed in 1.11s...............
2025-08-27 22:01:10,918:INFO:Initializing compare_models()
2025-08-27 22:01:10,918:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-27 22:01:10,918:INFO:Checking exceptions
2025-08-27 22:01:10,922:INFO:Preparing display monitor
2025-08-27 22:01:10,989:INFO:Initializing Logistic Regression
2025-08-27 22:01:10,989:INFO:Total runtime is 0.0 minutes
2025-08-27 22:01:10,995:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:10,995:INFO:Initializing create_model()
2025-08-27 22:01:10,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:10,996:INFO:Checking exceptions
2025-08-27 22:01:10,996:INFO:Importing libraries
2025-08-27 22:01:10,996:INFO:Copying training dataset
2025-08-27 22:01:11,005:INFO:Defining folds
2025-08-27 22:01:11,006:INFO:Declaring metric variables
2025-08-27 22:01:11,013:INFO:Importing untrained model
2025-08-27 22:01:11,023:INFO:Logistic Regression Imported successfully
2025-08-27 22:01:11,040:INFO:Starting cross validation
2025-08-27 22:01:11,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:11,049:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:11,049:WARNING:  warnings.warn(
2025-08-27 22:01:18,852:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:01:19,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:19,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,503:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:19,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:19,510:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:19,651:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:19,661:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,676:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,693:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,701:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:19,703:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:19,706:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:19,753:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:19,759:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,764:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:19,770:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:19,771:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:19,774:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:19,975:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:01:20,219:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:01:20,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:01:20,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:01:20,323:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:01:20,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:01:20,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:20,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,485:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:20,498:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,715:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:20,723:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:20,725:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,732:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,732:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,737:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,738:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,739:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,739:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:20,744:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,766:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:20,778:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,794:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:01:20,872:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:20,875:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:20,879:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,880:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,883:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,886:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,888:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,891:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:20,892:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:20,894:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,895:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:20,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:20,899:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,112:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,116:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,119:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,121:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,124:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,131:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 22:01:21,131:WARNING:1 fits failed out of a total of 10.
2025-08-27 22:01:21,131:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 22:01:21,131:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 22:01:21,131:WARNING:
2025-08-27 22:01:21,131:WARNING:Below are more details about the failures:
2025-08-27 22:01:21,132:WARNING:--------------------------------------------------------------------------------
2025-08-27 22:01:21,132:WARNING:1 fits failed with the following error:
2025-08-27 22:01:21,132:WARNING:Traceback (most recent call last):
2025-08-27 22:01:21,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 22:01:21,132:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 22:01:21,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 22:01:21,132:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 22:01:21,133:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 22:01:21,133:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 22:01:21,133:WARNING:    return self.func(*args, **kwargs)
2025-08-27 22:01:21,133:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:01:21,133:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 22:01:21,133:WARNING:    transformer.fit(*args)
2025-08-27 22:01:21,133:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 22:01:21,133:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 22:01:21,134:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:01:21,134:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py", line 1246, in fit
2025-08-27 22:01:21,134:WARNING:    raise ValueError(
2025-08-27 22:01:21,134:WARNING:ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0
2025-08-27 22:01:21,134:WARNING:
2025-08-27 22:01:21,134:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 22:01:21,135:INFO:Calculating mean and std
2025-08-27 22:01:21,137:INFO:Creating metrics dataframe
2025-08-27 22:01:21,141:INFO:Uploading results into container
2025-08-27 22:01:21,142:INFO:Uploading model into container now
2025-08-27 22:01:21,143:INFO:_master_model_container: 1
2025-08-27 22:01:21,143:INFO:_display_container: 2
2025-08-27 22:01:21,144:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 22:01:21,144:INFO:create_model() successfully completed......................................
2025-08-27 22:01:21,298:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:21,298:INFO:Creating metrics dataframe
2025-08-27 22:01:21,305:INFO:Initializing K Neighbors Classifier
2025-08-27 22:01:21,305:INFO:Total runtime is 0.17194053332010906 minutes
2025-08-27 22:01:21,310:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:21,310:INFO:Initializing create_model()
2025-08-27 22:01:21,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:21,311:INFO:Checking exceptions
2025-08-27 22:01:21,311:INFO:Importing libraries
2025-08-27 22:01:21,311:INFO:Copying training dataset
2025-08-27 22:01:21,316:INFO:Defining folds
2025-08-27 22:01:21,317:INFO:Declaring metric variables
2025-08-27 22:01:21,322:INFO:Importing untrained model
2025-08-27 22:01:21,327:INFO:K Neighbors Classifier Imported successfully
2025-08-27 22:01:21,339:INFO:Starting cross validation
2025-08-27 22:01:21,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:21,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:21,345:WARNING:  warnings.warn(
2025-08-27 22:01:21,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:01:21,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,473:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,474:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,477:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,477:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,487:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,489:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,496:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,498:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,503:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,503:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,504:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,504:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,504:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,504:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,504:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,510:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,510:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,510:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,514:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,536:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,536:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,541:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,541:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,545:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,547:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,550:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,553:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,553:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,553:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,556:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,556:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

e 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,560:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,572:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,574:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,578:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,578:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,583:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,584:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,585:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,586:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,586:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,588:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,588:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,588:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,589:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,595:INFO:Calculating mean and std
2025-08-27 22:01:21,597:INFO:Creating metrics dataframe
2025-08-27 22:01:21,600:INFO:Uploading results into container
2025-08-27 22:01:21,601:INFO:Uploading model into container now
2025-08-27 22:01:21,602:INFO:_master_model_container: 2
2025-08-27 22:01:21,602:INFO:_display_container: 2
2025-08-27 22:01:21,602:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 22:01:21,603:INFO:create_model() successfully completed......................................
2025-08-27 22:01:21,739:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:21,739:INFO:Creating metrics dataframe
2025-08-27 22:01:21,757:INFO:Initializing Naive Bayes
2025-08-27 22:01:21,757:INFO:Total runtime is 0.17947490612665812 minutes
2025-08-27 22:01:21,767:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:21,767:INFO:Initializing create_model()
2025-08-27 22:01:21,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:21,768:INFO:Checking exceptions
2025-08-27 22:01:21,768:INFO:Importing libraries
2025-08-27 22:01:21,768:INFO:Copying training dataset
2025-08-27 22:01:21,778:INFO:Defining folds
2025-08-27 22:01:21,779:INFO:Declaring metric variables
2025-08-27 22:01:21,788:INFO:Importing untrained model
2025-08-27 22:01:21,795:INFO:Naive Bayes Imported successfully
2025-08-27 22:01:21,805:INFO:Starting cross validation
2025-08-27 22:01:21,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:21,813:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:21,814:WARNING:  warnings.warn(
2025-08-27 22:01:21,857:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:01:21,857:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,858:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,858:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,858:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,858:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,874:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,888:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,889:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,889:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,890:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,893:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,893:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,893:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,896:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,903:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,903:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,905:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:21,905:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,905:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,908:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,909:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,909:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,913:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,916:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,916:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,916:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,916:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,917:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:21,918:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,918:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,919:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,919:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:21,922:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:21,930:INFO:Calculating mean and std
2025-08-27 22:01:21,932:INFO:Creating metrics dataframe
2025-08-27 22:01:21,935:INFO:Uploading results into container
2025-08-27 22:01:21,936:INFO:Uploading model into container now
2025-08-27 22:01:21,937:INFO:_master_model_container: 3
2025-08-27 22:01:21,937:INFO:_display_container: 2
2025-08-27 22:01:21,937:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 22:01:21,938:INFO:create_model() successfully completed......................................
2025-08-27 22:01:22,055:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:22,056:INFO:Creating metrics dataframe
2025-08-27 22:01:22,069:INFO:Initializing Decision Tree Classifier
2025-08-27 22:01:22,069:INFO:Total runtime is 0.1846596598625183 minutes
2025-08-27 22:01:22,073:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:22,074:INFO:Initializing create_model()
2025-08-27 22:01:22,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:22,075:INFO:Checking exceptions
2025-08-27 22:01:22,075:INFO:Importing libraries
2025-08-27 22:01:22,075:INFO:Copying training dataset
2025-08-27 22:01:22,082:INFO:Defining folds
2025-08-27 22:01:22,082:INFO:Declaring metric variables
2025-08-27 22:01:22,088:INFO:Importing untrained model
2025-08-27 22:01:22,093:INFO:Decision Tree Classifier Imported successfully
2025-08-27 22:01:22,105:INFO:Starting cross validation
2025-08-27 22:01:22,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:22,109:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:22,109:WARNING:  warnings.warn(
2025-08-27 22:01:22,149:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,157:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(resu2025-08-27 22:01:22,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,183:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,183:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,183:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,185:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,186:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,186:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,188:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,189:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,191:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,191:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,193:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,200:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,202:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,203:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,204:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,205:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,206:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,208:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,211:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,211:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,211:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,214:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,215:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,228:INFO:Calculating mean and std
2025-08-27 22:01:22,230:INFO:Creating metrics dataframe
2025-08-27 22:01:22,235:INFO:Uploading results into container
2025-08-27 22:01:22,236:INFO:Uploading model into container now
2025-08-27 22:01:22,236:INFO:_master_model_container: 4
2025-08-27 22:01:22,237:INFO:_display_container: 2
2025-08-27 22:01:22,237:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=0, splitter='best')
2025-08-27 22:01:22,237:INFO:create_model() successfully completed......................................
2025-08-27 22:01:22,371:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:22,371:INFO:Creating metrics dataframe
2025-08-27 22:01:22,383:INFO:Initializing SVM - Linear Kernel
2025-08-27 22:01:22,384:INFO:Total runtime is 0.18991448879241943 minutes
2025-08-27 22:01:22,388:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:22,389:INFO:Initializing create_model()
2025-08-27 22:01:22,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:22,389:INFO:Checking exceptions
2025-08-27 22:01:22,389:INFO:Importing libraries
2025-08-27 22:01:22,389:INFO:Copying training dataset
2025-08-27 22:01:22,396:INFO:Defining folds
2025-08-27 22:01:22,396:INFO:Declaring metric variables
2025-08-27 22:01:22,404:INFO:Importing untrained model
2025-08-27 22:01:22,410:INFO:SVM - Linear Kernel Imported successfully
2025-08-27 22:01:22,421:INFO:Starting cross validation
2025-08-27 22:01:22,422:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:22,425:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:22,425:WARNING:  warnings.warn(
2025-08-27 22:01:22,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,488:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,495:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,500:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,507:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,507:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,510:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,511:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,511:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,514:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,514:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,514:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,515:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,516:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,520:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,523:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,529:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,529:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,530:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,532:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 22:01:22,532:WARNING:1 fits failed out of a total of 10.
2025-08-27 22:01:22,532:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 22:01:22,532:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 22:01:22,532:WARNING:
2025-08-27 22:01:22,532:WARNING:Below are more details about the failures:
2025-08-27 22:01:22,532:WARNING:--------------------------------------------------------------------------------
2025-08-27 22:01:22,532:WARNING:1 fits failed with the following error:
2025-08-27 22:01:22,532:WARNING:Traceback (most recent call last):
2025-08-27 22:01:22,532:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 22:01:22,532:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 22:01:22,533:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 22:01:22,533:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 22:01:22,533:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 22:01:22,533:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 22:01:22,533:WARNING:    return self.func(*args, **kwargs)
2025-08-27 22:01:22,533:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:01:22,533:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 22:01:22,533:WARNING:    transformer.fit(*args)
2025-08-27 22:01:22,533:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 22:01:22,533:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 22:01:22,533:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:01:22,533:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 917, in fit
2025-08-27 22:01:22,533:WARNING:    return self._fit(
2025-08-27 22:01:22,533:WARNING:           ^^^^^^^^^^
2025-08-27 22:01:22,533:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 704, in _fit
2025-08-27 22:01:22,533:WARNING:    self._partial_fit(
2025-08-27 22:01:22,533:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 658, in _partial_fit
2025-08-27 22:01:22,533:WARNING:    raise ValueError(
2025-08-27 22:01:22,533:WARNING:ValueError: The number of classes has to be greater than one; got 1 class
2025-08-27 22:01:22,533:WARNING:
2025-08-27 22:01:22,533:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 22:01:22,534:INFO:Calculating mean and std
2025-08-27 22:01:22,535:INFO:Creating metrics dataframe
2025-08-27 22:01:22,537:INFO:Uploading results into container
2025-08-27 22:01:22,537:INFO:Uploading model into container now
2025-08-27 22:01:22,537:INFO:_master_model_container: 5
2025-08-27 22:01:22,538:INFO:_display_container: 2
2025-08-27 22:01:22,538:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=0, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-27 22:01:22,539:INFO:create_model() successfully completed......................................
2025-08-27 22:01:22,641:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:22,641:INFO:Creating metrics dataframe
2025-08-27 22:01:22,651:INFO:Initializing Ridge Classifier
2025-08-27 22:01:22,653:INFO:Total runtime is 0.19437505801518756 minutes
2025-08-27 22:01:22,656:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:22,656:INFO:Initializing create_model()
2025-08-27 22:01:22,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:22,657:INFO:Checking exceptions
2025-08-27 22:01:22,657:INFO:Importing libraries
2025-08-27 22:01:22,657:INFO:Copying training dataset
2025-08-27 22:01:22,665:INFO:Defining folds
2025-08-27 22:01:22,665:INFO:Declaring metric variables
2025-08-27 22:01:22,674:INFO:Importing untrained model
2025-08-27 22:01:22,684:INFO:Ridge Classifier Imported successfully
2025-08-27 22:01:22,697:INFO:Starting cross validation
2025-08-27 22:01:22,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:22,704:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:22,704:WARNING:  warnings.warn(
2025-08-27 22:01:22,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,768:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,768:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,768:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,768:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,768:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,768:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,776:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,776:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,787:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,787:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,787:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,787:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,787:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,792:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,792:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,795:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,787:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,795:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,795:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,801:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,801:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,802:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,805:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,807:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,808:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,809:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,810:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,811:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,811:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,813:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,813:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,815:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,816:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,817:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,817:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,820:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,820:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,821:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:22,824:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,825:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,827:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,828:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,829:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,829:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,829:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:22,831:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,831:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:22,831:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,833:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:22,844:INFO:Calculating mean and std
2025-08-27 22:01:22,845:INFO:Creating metrics dataframe
2025-08-27 22:01:22,848:INFO:Uploading results into container
2025-08-27 22:01:22,849:INFO:Uploading model into container now
2025-08-27 22:01:22,850:INFO:_master_model_container: 6
2025-08-27 22:01:22,850:INFO:_display_container: 2
2025-08-27 22:01:22,850:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=0, solver='auto',
                tol=0.0001)
2025-08-27 22:01:22,850:INFO:create_model() successfully completed......................................
2025-08-27 22:01:22,964:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:22,964:INFO:Creating metrics dataframe
2025-08-27 22:01:22,986:INFO:Initializing Random Forest Classifier
2025-08-27 22:01:22,986:INFO:Total runtime is 0.1999505003293355 minutes
2025-08-27 22:01:22,991:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:22,992:INFO:Initializing create_model()
2025-08-27 22:01:22,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:22,992:INFO:Checking exceptions
2025-08-27 22:01:22,992:INFO:Importing libraries
2025-08-27 22:01:22,992:INFO:Copying training dataset
2025-08-27 22:01:23,002:INFO:Defining folds
2025-08-27 22:01:23,002:INFO:Declaring metric variables
2025-08-27 22:01:23,009:INFO:Importing untrained model
2025-08-27 22:01:23,016:INFO:Random Forest Classifier Imported successfully
2025-08-27 22:01:23,031:INFO:Starting cross validation
2025-08-27 22:01:23,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:23,039:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:23,039:WARNING:  warnings.warn(
2025-08-27 22:01:23,573:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:01:23,573:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:23,577:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:23,578:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,584:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,586:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,588:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,590:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,591:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:23,591:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,592:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,593:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,594:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:23,597:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,598:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:23,602:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,612:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,624:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:23,630:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,636:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,638:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:23,649:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,652:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,665:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,672:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,672:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:23,680:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,719:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:23,726:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,734:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,740:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,742:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:23,747:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,783:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:23,789:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,795:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,806:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,807:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:23,815:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,834:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:23,839:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,849:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,856:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:23,860:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:23,862:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:23,866:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,078:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,087:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,090:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,093:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,094:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,094:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,097:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,099:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,108:INFO:Calculating mean and std
2025-08-27 22:01:24,109:INFO:Creating metrics dataframe
2025-08-27 22:01:24,112:INFO:Uploading results into container
2025-08-27 22:01:24,112:INFO:Uploading model into container now
2025-08-27 22:01:24,113:INFO:_master_model_container: 7
2025-08-27 22:01:24,113:INFO:_display_container: 2
2025-08-27 22:01:24,114:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=0, verbose=0,
                       warm_start=False)
2025-08-27 22:01:24,115:INFO:create_model() successfully completed......................................
2025-08-27 22:01:24,222:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:24,222:INFO:Creating metrics dataframe
2025-08-27 22:01:24,234:INFO:Initializing Quadratic Discriminant Analysis
2025-08-27 22:01:24,234:INFO:Total runtime is 0.22074975570042926 minutes
2025-08-27 22:01:24,239:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:24,239:INFO:Initializing create_model()
2025-08-27 22:01:24,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:24,240:INFO:Checking exceptions
2025-08-27 22:01:24,240:INFO:Importing libraries
2025-08-27 22:01:24,240:INFO:Copying training dataset
2025-08-27 22:01:24,246:INFO:Defining folds
2025-08-27 22:01:24,246:INFO:Declaring metric variables
2025-08-27 22:01:24,252:INFO:Importing untrained model
2025-08-27 22:01:24,257:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 22:01:24,269:INFO:Starting cross validation
2025-08-27 22:01:24,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:24,274:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:24,275:WARNING:  warnings.warn(
2025-08-27 22:01:24,365:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-08-27 22:01:24,367:WARNING:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1.0, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-08-27 22:01:24,367:INFO:Initializing create_model()
2025-08-27 22:01:24,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:24,368:INFO:Checking exceptions
2025-08-27 22:01:24,368:INFO:Importing libraries
2025-08-27 22:01:24,368:INFO:Copying training dataset
2025-08-27 22:01:24,374:INFO:Defining folds
2025-08-27 22:01:24,374:INFO:Declaring metric variables
2025-08-27 22:01:24,381:INFO:Importing untrained model
2025-08-27 22:01:24,389:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 22:01:24,400:INFO:Starting cross validation
2025-08-27 22:01:24,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:24,408:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:24,408:WARNING:  warnings.warn(
2025-08-27 22:01:24,472:ERROR:create_model() for qda raised an exception or returned all 0.0:
2025-08-27 22:01:24,473:ERROR:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1.0, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1.0, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-08-27 22:01:24,473:INFO:Initializing Ada Boost Classifier
2025-08-27 22:01:24,473:INFO:Total runtime is 0.22473996082941688 minutes
2025-08-27 22:01:24,479:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:24,479:INFO:Initializing create_model()
2025-08-27 22:01:24,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:24,480:INFO:Checking exceptions
2025-08-27 22:01:24,480:INFO:Importing libraries
2025-08-27 22:01:24,480:INFO:Copying training dataset
2025-08-27 22:01:24,486:INFO:Defining folds
2025-08-27 22:01:24,486:INFO:Declaring metric variables
2025-08-27 22:01:24,491:INFO:Importing untrained model
2025-08-27 22:01:24,497:INFO:Ada Boost Classifier Imported successfully
2025-08-27 22:01:24,506:INFO:Starting cross validation
2025-08-27 22:01:24,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:24,511:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:24,512:WARNING:  warnings.warn(
2025-08-27 22:01:24,539:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,539:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,547:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,547:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,554:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,554:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,554:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,554:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,567:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,567:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,571:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,571:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,571:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,571:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,575:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,575:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,575:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,575:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,575:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,592:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,592:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,593:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,593:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,593:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,594:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,595:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,595:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,595:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,595:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,597:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,598:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,599:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,600:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,601:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,602:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:01:24,602:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,604:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,612:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:24,613:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,616:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,617:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,617:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,617:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,617:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:24,617:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,617:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,622:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,622:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:24,622:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,624:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:24,634:INFO:Calculating mean and std
2025-08-27 22:01:24,635:INFO:Creating metrics dataframe
2025-08-27 22:01:24,639:INFO:Uploading results into container
2025-08-27 22:01:24,640:INFO:Uploading model into container now
2025-08-27 22:01:24,641:INFO:_master_model_container: 8
2025-08-27 22:01:24,641:INFO:_display_container: 2
2025-08-27 22:01:24,641:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=0)
2025-08-27 22:01:24,641:INFO:create_model() successfully completed......................................
2025-08-27 22:01:24,759:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:24,760:INFO:Creating metrics dataframe
2025-08-27 22:01:24,775:INFO:Initializing Gradient Boosting Classifier
2025-08-27 22:01:24,775:INFO:Total runtime is 0.22977135181427 minutes
2025-08-27 22:01:24,782:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:24,783:INFO:Initializing create_model()
2025-08-27 22:01:24,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:24,783:INFO:Checking exceptions
2025-08-27 22:01:24,783:INFO:Importing libraries
2025-08-27 22:01:24,783:INFO:Copying training dataset
2025-08-27 22:01:24,790:INFO:Defining folds
2025-08-27 22:01:24,790:INFO:Declaring metric variables
2025-08-27 22:01:24,796:INFO:Importing untrained model
2025-08-27 22:01:24,801:INFO:Gradient Boosting Classifier Imported successfully
2025-08-27 22:01:24,813:INFO:Starting cross validation
2025-08-27 22:01:24,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:24,817:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:24,817:WARNING:  warnings.warn(
2025-08-27 22:01:25,032:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,034:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,037:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,037:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,040:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,040:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,040:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,047:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,047:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,047:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,051:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,051:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,051:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,051:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,051:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,051:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,051:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,056:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,056:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,057:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,057:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,061:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,063:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,068:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,068:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,068:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,070:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,071:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,072:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,077:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,077:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,080:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,080:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,083:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,083:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,214:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,226:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 22:01:25,226:WARNING:1 fits failed out of a total of 10.
2025-08-27 22:01:25,226:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 22:01:25,226:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 22:01:25,226:WARNING:
2025-08-27 22:01:25,226:WARNING:Below are more details about the failures:
2025-08-27 22:01:25,226:WARNING:--------------------------------------------------------------------------------
2025-08-27 22:01:25,226:WARNING:1 fits failed with the following error:
2025-08-27 22:01:25,226:WARNING:Traceback (most recent call last):
2025-08-27 22:01:25,226:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 22:01:25,226:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 22:01:25,226:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 22:01:25,226:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 22:01:25,226:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 22:01:25,227:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 22:01:25,227:WARNING:    return self.func(*args, **kwargs)
2025-08-27 22:01:25,227:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:01:25,227:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 22:01:25,227:WARNING:    transformer.fit(*args)
2025-08-27 22:01:25,227:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 22:01:25,227:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 22:01:25,227:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:01:25,227:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_gb.py", line 665, in fit
2025-08-27 22:01:25,227:WARNING:    y = self._encode_y(y=y, sample_weight=None)
2025-08-27 22:01:25,227:WARNING:        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:01:25,227:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_gb.py", line 1520, in _encode_y
2025-08-27 22:01:25,227:WARNING:    raise ValueError(
2025-08-27 22:01:25,227:WARNING:ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.
2025-08-27 22:01:25,227:WARNING:
2025-08-27 22:01:25,227:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 22:01:25,227:INFO:Calculating mean and std
2025-08-27 22:01:25,229:INFO:Creating metrics dataframe
2025-08-27 22:01:25,232:INFO:Uploading results into container
2025-08-27 22:01:25,234:INFO:Uploading model into container now
2025-08-27 22:01:25,234:INFO:_master_model_container: 9
2025-08-27 22:01:25,235:INFO:_display_container: 2
2025-08-27 22:01:25,235:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=0, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-27 22:01:25,236:INFO:create_model() successfully completed......................................
2025-08-27 22:01:25,340:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:25,340:INFO:Creating metrics dataframe
2025-08-27 22:01:25,357:INFO:Initializing Linear Discriminant Analysis
2025-08-27 22:01:25,357:INFO:Total runtime is 0.2394707679748535 minutes
2025-08-27 22:01:25,363:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:25,364:INFO:Initializing create_model()
2025-08-27 22:01:25,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:25,364:INFO:Checking exceptions
2025-08-27 22:01:25,364:INFO:Importing libraries
2025-08-27 22:01:25,365:INFO:Copying training dataset
2025-08-27 22:01:25,371:INFO:Defining folds
2025-08-27 22:01:25,371:INFO:Declaring metric variables
2025-08-27 22:01:25,377:INFO:Importing untrained model
2025-08-27 22:01:25,383:INFO:Linear Discriminant Analysis Imported successfully
2025-08-27 22:01:25,398:INFO:Starting cross validation
2025-08-27 22:01:25,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:25,402:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:25,402:WARNING:  warnings.warn(
2025-08-27 22:01:25,457:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,457:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,459:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,459:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,460:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,460:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,461:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,470:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

ier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,485:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,488:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,504:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,505:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:25,505:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,505:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,505:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,513:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,516:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:25,516:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,516:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:25,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,520:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:25,523:INFO:Calculating mean and std
2025-08-27 22:01:25,524:INFO:Creating metrics dataframe
2025-08-27 22:01:25,527:INFO:Uploading results into container
2025-08-27 22:01:25,528:INFO:Uploading model into container now
2025-08-27 22:01:25,528:INFO:_master_model_container: 10
2025-08-27 22:01:25,530:INFO:_display_container: 2
2025-08-27 22:01:25,531:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-08-27 22:01:25,531:INFO:create_model() successfully completed......................................
2025-08-27 22:01:25,657:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:25,658:INFO:Creating metrics dataframe
2025-08-27 22:01:25,672:INFO:Initializing Extra Trees Classifier
2025-08-27 22:01:25,672:INFO:Total runtime is 0.2447236696879069 minutes
2025-08-27 22:01:25,677:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:25,678:INFO:Initializing create_model()
2025-08-27 22:01:25,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:25,678:INFO:Checking exceptions
2025-08-27 22:01:25,678:INFO:Importing libraries
2025-08-27 22:01:25,678:INFO:Copying training dataset
2025-08-27 22:01:25,686:INFO:Defining folds
2025-08-27 22:01:25,687:INFO:Declaring metric variables
2025-08-27 22:01:25,691:INFO:Importing untrained model
2025-08-27 22:01:25,700:INFO:Extra Trees Classifier Imported successfully
2025-08-27 22:01:25,714:INFO:Starting cross validation
2025-08-27 22:01:25,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:25,721:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:25,721:WARNING:  warnings.warn(
2025-08-27 22:01:26,079:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,081:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,090:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,091:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,093:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,095:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,099:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,099:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,100:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,100:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:01:26,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,103:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,108:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,113:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,120:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,120:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,123:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,124:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,125:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,128:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,128:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,132:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,133:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,155:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,160:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,166:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,168:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,171:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,172:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,175:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,180:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,182:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,183:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,185:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,242:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,245:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,249:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,253:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,254:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,255:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,257:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,368:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,370:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,374:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,376:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,376:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,382:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,385:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,387:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,387:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,388:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,397:INFO:Calculating mean and std
2025-08-27 22:01:26,399:INFO:Creating metrics dataframe
2025-08-27 22:01:26,401:INFO:Uploading results into container
2025-08-27 22:01:26,403:INFO:Uploading model into container now
2025-08-27 22:01:26,403:INFO:_master_model_container: 11
2025-08-27 22:01:26,404:INFO:_display_container: 2
2025-08-27 22:01:26,404:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=0, verbose=0,
                     warm_start=False)
2025-08-27 22:01:26,405:INFO:create_model() successfully completed......................................
2025-08-27 22:01:26,527:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:26,527:INFO:Creating metrics dataframe
2025-08-27 22:01:26,552:INFO:Initializing Light Gradient Boosting Machine
2025-08-27 22:01:26,553:INFO:Total runtime is 0.25940236647923787 minutes
2025-08-27 22:01:26,560:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:26,560:INFO:Initializing create_model()
2025-08-27 22:01:26,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:26,561:INFO:Checking exceptions
2025-08-27 22:01:26,561:INFO:Importing libraries
2025-08-27 22:01:26,562:INFO:Copying training dataset
2025-08-27 22:01:26,574:INFO:Defining folds
2025-08-27 22:01:26,574:INFO:Declaring metric variables
2025-08-27 22:01:26,581:INFO:Importing untrained model
2025-08-27 22:01:26,592:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-27 22:01:26,622:INFO:Starting cross validation
2025-08-27 22:01:26,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:26,631:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:26,631:WARNING:  warnings.warn(
2025-08-27 22:01:26,761:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,955:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,958:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,958:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,960:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:26,961:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,962:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,966:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,967:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,969:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,969:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,970:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,973:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,973:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,976:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,977:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,981:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:26,984:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:26,984:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:26,987:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,006:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,012:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,017:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,023:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,026:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,026:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,029:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,054:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,059:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,070:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,073:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,074:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,077:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,121:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,126:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,131:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,136:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,139:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,140:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,145:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,150:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,156:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,160:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,163:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,164:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,167:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,181:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,189:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,194:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,200:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,200:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,200:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,208:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,216:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,216:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,227:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,227:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,227:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,227:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,237:INFO:Calculating mean and std
2025-08-27 22:01:27,237:INFO:Creating metrics dataframe
2025-08-27 22:01:27,237:INFO:Uploading results into container
2025-08-27 22:01:27,237:INFO:Uploading model into container now
2025-08-27 22:01:27,245:INFO:_master_model_container: 12
2025-08-27 22:01:27,245:INFO:_display_container: 2
2025-08-27 22:01:27,246:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=0, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-27 22:01:27,246:INFO:create_model() successfully completed......................................
2025-08-27 22:01:27,370:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:27,370:INFO:Creating metrics dataframe
2025-08-27 22:01:27,391:INFO:Initializing Dummy Classifier
2025-08-27 22:01:27,391:INFO:Total runtime is 0.2733594616254171 minutes
2025-08-27 22:01:27,395:INFO:SubProcess create_model() called ==================================
2025-08-27 22:01:27,395:INFO:Initializing create_model()
2025-08-27 22:01:27,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B6CD77FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:27,395:INFO:Checking exceptions
2025-08-27 22:01:27,396:INFO:Importing libraries
2025-08-27 22:01:27,396:INFO:Copying training dataset
2025-08-27 22:01:27,402:INFO:Defining folds
2025-08-27 22:01:27,403:INFO:Declaring metric variables
2025-08-27 22:01:27,409:INFO:Importing untrained model
2025-08-27 22:01:27,416:INFO:Dummy Classifier Imported successfully
2025-08-27 22:01:27,426:INFO:Starting cross validation
2025-08-27 22:01:27,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:01:27,432:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:01:27,432:WARNING:  warnings.warn(
2025-08-27 22:01:27,460:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:01:27,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,468:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,475:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,483:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,493:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,498:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,504:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,505:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,506:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:01:27,511:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,511:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,515:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,515:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,519:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:01:27,520:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,520:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:01:27,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:01:27,524:INFO:Calculating mean and std
2025-08-27 22:01:27,525:INFO:Creating metrics dataframe
2025-08-27 22:01:27,528:INFO:Uploading results into container
2025-08-27 22:01:27,528:INFO:Uploading model into container now
2025-08-27 22:01:27,528:INFO:_master_model_container: 13
2025-08-27 22:01:27,529:INFO:_display_container: 2
2025-08-27 22:01:27,529:INFO:DummyClassifier(constant=None, random_state=0, strategy='prior')
2025-08-27 22:01:27,529:INFO:create_model() successfully completed......................................
2025-08-27 22:01:27,649:INFO:SubProcess create_model() end ==================================
2025-08-27 22:01:27,649:INFO:Creating metrics dataframe
2025-08-27 22:01:27,688:INFO:Initializing create_model()
2025-08-27 22:01:27,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:01:27,688:INFO:Checking exceptions
2025-08-27 22:01:27,690:INFO:Importing libraries
2025-08-27 22:01:27,690:INFO:Copying training dataset
2025-08-27 22:01:27,696:INFO:Defining folds
2025-08-27 22:01:27,696:INFO:Declaring metric variables
2025-08-27 22:01:27,697:INFO:Importing untrained model
2025-08-27 22:01:27,697:INFO:Declaring custom model
2025-08-27 22:01:27,697:INFO:Logistic Regression Imported successfully
2025-08-27 22:01:27,697:INFO:Cross validation set to False
2025-08-27 22:01:27,697:INFO:Fitting Model
2025-08-27 22:01:27,723:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 22:01:27,723:INFO:create_model() successfully completed......................................
2025-08-27 22:01:27,870:INFO:_master_model_container: 13
2025-08-27 22:01:27,870:INFO:_display_container: 2
2025-08-27 22:01:27,872:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 22:01:27,873:INFO:compare_models() successfully completed......................................
2025-08-27 22:01:27,874:INFO:Initializing plot_model()
2025-08-27 22:01:27,874:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6DC5AD10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-27 22:01:27,874:INFO:Checking exceptions
2025-08-27 22:01:27,878:INFO:Preloading libraries
2025-08-27 22:01:27,879:INFO:Copying training dataset
2025-08-27 22:01:27,879:INFO:Plot type: confusion_matrix
2025-08-27 22:01:27,990:INFO:Fitting Model
2025-08-27 22:01:27,990:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
2025-08-27 22:01:27,990:WARNING:  warnings.warn(
2025-08-27 22:01:27,990:INFO:Scoring test/hold-out set
2025-08-27 22:01:28,172:INFO:Visual Rendered Successfully
2025-08-27 22:01:28,305:INFO:plot_model() successfully completed......................................
2025-08-27 22:47:21,851:INFO:PyCaret ClassificationExperiment
2025-08-27 22:47:21,851:INFO:Logging name: clf-default-name
2025-08-27 22:47:21,851:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 22:47:21,851:INFO:version 3.3.2
2025-08-27 22:47:21,851:INFO:Initializing setup()
2025-08-27 22:47:21,851:INFO:self.USI: 9317
2025-08-27 22:47:21,851:INFO:self._variable_keys: {'_available_plots', 'USI', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'fold_generator', 'fold_groups_param', 'idx', 'html_param', 'n_jobs_param', 'gpu_param', 'X_test', 'y', 'data', 'X', '_ml_usecase', 'target_param', 'is_multiclass', 'y_test', 'exp_id', 'pipeline', 'fold_shuffle_param', 'y_train', 'memory', 'fix_imbalance', 'X_train', 'exp_name_log', 'logging_param'}
2025-08-27 22:47:21,851:INFO:Checking environment
2025-08-27 22:47:21,851:INFO:python_version: 3.11.9
2025-08-27 22:47:21,851:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 22:47:21,851:INFO:machine: AMD64
2025-08-27 22:47:21,851:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 22:47:21,851:INFO:Memory: svmem(total=17024348160, available=3809513472, percent=77.6, used=13214834688, free=3809513472)
2025-08-27 22:47:21,863:INFO:Physical Core: 4
2025-08-27 22:47:21,863:INFO:Logical Core: 8
2025-08-27 22:47:21,863:INFO:Checking libraries
2025-08-27 22:47:21,863:INFO:System:
2025-08-27 22:47:21,863:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 22:47:21,863:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 22:47:21,863:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 22:47:21,863:INFO:PyCaret required dependencies:
2025-08-27 22:47:21,863:INFO:                 pip: Not installed
2025-08-27 22:47:21,863:INFO:          setuptools: 80.9.0
2025-08-27 22:47:21,863:INFO:             pycaret: 3.3.2
2025-08-27 22:47:21,863:INFO:             IPython: 9.4.0
2025-08-27 22:47:21,863:INFO:          ipywidgets: 8.1.7
2025-08-27 22:47:21,863:INFO:                tqdm: 4.67.1
2025-08-27 22:47:21,863:INFO:               numpy: 1.26.4
2025-08-27 22:47:21,863:INFO:              pandas: 2.1.4
2025-08-27 22:47:21,863:INFO:              jinja2: 3.1.6
2025-08-27 22:47:21,863:INFO:               scipy: 1.11.4
2025-08-27 22:47:21,863:INFO:              joblib: 1.3.2
2025-08-27 22:47:21,863:INFO:             sklearn: 1.4.2
2025-08-27 22:47:21,863:INFO:                pyod: 2.0.5
2025-08-27 22:47:21,863:INFO:            imblearn: 0.14.0
2025-08-27 22:47:21,863:INFO:   category_encoders: 2.7.0
2025-08-27 22:47:21,863:INFO:            lightgbm: 4.6.0
2025-08-27 22:47:21,863:INFO:               numba: 0.61.2
2025-08-27 22:47:21,863:INFO:            requests: 2.32.5
2025-08-27 22:47:21,863:INFO:          matplotlib: 3.7.5
2025-08-27 22:47:21,863:INFO:          scikitplot: 0.3.7
2025-08-27 22:47:21,863:INFO:         yellowbrick: 1.5
2025-08-27 22:47:21,863:INFO:              plotly: 5.24.1
2025-08-27 22:47:21,868:INFO:    plotly-resampler: Not installed
2025-08-27 22:47:21,868:INFO:             kaleido: 1.0.0
2025-08-27 22:47:21,868:INFO:           schemdraw: 0.15
2025-08-27 22:47:21,868:INFO:         statsmodels: 0.14.5
2025-08-27 22:47:21,868:INFO:              sktime: 0.26.0
2025-08-27 22:47:21,868:INFO:               tbats: 1.1.3
2025-08-27 22:47:21,868:INFO:            pmdarima: 2.0.4
2025-08-27 22:47:21,868:INFO:              psutil: 7.0.0
2025-08-27 22:47:21,868:INFO:          markupsafe: 3.0.2
2025-08-27 22:47:21,868:INFO:             pickle5: Not installed
2025-08-27 22:47:21,868:INFO:         cloudpickle: 3.1.1
2025-08-27 22:47:21,868:INFO:         deprecation: 2.1.0
2025-08-27 22:47:21,868:INFO:              xxhash: 3.5.0
2025-08-27 22:47:21,868:INFO:           wurlitzer: Not installed
2025-08-27 22:47:21,868:INFO:PyCaret optional dependencies:
2025-08-27 22:47:21,868:INFO:                shap: Not installed
2025-08-27 22:47:21,868:INFO:           interpret: Not installed
2025-08-27 22:47:21,868:INFO:                umap: Not installed
2025-08-27 22:47:21,868:INFO:     ydata_profiling: Not installed
2025-08-27 22:47:21,868:INFO:  explainerdashboard: Not installed
2025-08-27 22:47:21,868:INFO:             autoviz: Not installed
2025-08-27 22:47:21,868:INFO:           fairlearn: Not installed
2025-08-27 22:47:21,868:INFO:          deepchecks: Not installed
2025-08-27 22:47:21,868:INFO:             xgboost: Not installed
2025-08-27 22:47:21,868:INFO:            catboost: Not installed
2025-08-27 22:47:21,868:INFO:              kmodes: Not installed
2025-08-27 22:47:21,868:INFO:             mlxtend: Not installed
2025-08-27 22:47:21,868:INFO:       statsforecast: Not installed
2025-08-27 22:47:21,868:INFO:        tune_sklearn: Not installed
2025-08-27 22:47:21,868:INFO:                 ray: Not installed
2025-08-27 22:47:21,868:INFO:            hyperopt: Not installed
2025-08-27 22:47:21,868:INFO:              optuna: Not installed
2025-08-27 22:47:21,868:INFO:               skopt: Not installed
2025-08-27 22:47:21,868:INFO:              mlflow: Not installed
2025-08-27 22:47:21,868:INFO:              gradio: Not installed
2025-08-27 22:47:21,868:INFO:             fastapi: Not installed
2025-08-27 22:47:21,868:INFO:             uvicorn: Not installed
2025-08-27 22:47:21,868:INFO:              m2cgen: Not installed
2025-08-27 22:47:21,868:INFO:           evidently: Not installed
2025-08-27 22:47:21,868:INFO:               fugue: Not installed
2025-08-27 22:47:21,868:INFO:           streamlit: Not installed
2025-08-27 22:47:21,868:INFO:             prophet: Not installed
2025-08-27 22:47:21,868:INFO:None
2025-08-27 22:47:21,868:INFO:Set up data.
2025-08-27 22:47:21,880:INFO:Set up folding strategy.
2025-08-27 22:47:21,880:INFO:Set up train/test split.
2025-08-27 22:47:21,881:INFO:Set up index.
2025-08-27 22:47:21,881:INFO:Assigning column types.
2025-08-27 22:47:21,881:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 22:47:21,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 22:47:21,963:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 22:47:21,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:21,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 22:47:22,064:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 22:47:22,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,114:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 22:47:22,181:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 22:47:22,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,294:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 22:47:22,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,331:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 22:47:22,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,548:INFO:Preparing preprocessing pipeline...
2025-08-27 22:47:22,548:INFO:Set up simple imputation.
2025-08-27 22:47:22,581:INFO:Finished creating preprocessing pipeline.
2025-08-27 22:47:22,581:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-27 22:47:22,581:INFO:Creating final display dataframe.
2025-08-27 22:47:22,669:INFO:Setup _display_container:                     Description             Value
0                    Session id               224
1                        Target           failure
2                   Target type            Binary
3           Original data shape          (989, 6)
4        Transformed data shape          (989, 6)
5   Transformed train set shape          (692, 6)
6    Transformed test set shape          (297, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9317
2025-08-27 22:47:22,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 22:47:22,898:INFO:setup() successfully completed in 1.05s...............
2025-08-27 22:47:22,914:INFO:Initializing compare_models()
2025-08-27 22:47:22,914:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-27 22:47:22,914:INFO:Checking exceptions
2025-08-27 22:47:22,918:INFO:Preparing display monitor
2025-08-27 22:47:22,962:INFO:Initializing Logistic Regression
2025-08-27 22:47:22,962:INFO:Total runtime is 0.0 minutes
2025-08-27 22:47:22,969:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:22,969:INFO:Initializing create_model()
2025-08-27 22:47:22,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:22,969:INFO:Checking exceptions
2025-08-27 22:47:22,969:INFO:Importing libraries
2025-08-27 22:47:22,969:INFO:Copying training dataset
2025-08-27 22:47:22,977:INFO:Defining folds
2025-08-27 22:47:22,977:INFO:Declaring metric variables
2025-08-27 22:47:22,986:INFO:Importing untrained model
2025-08-27 22:47:23,031:INFO:Logistic Regression Imported successfully
2025-08-27 22:47:23,056:INFO:Starting cross validation
2025-08-27 22:47:23,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:23,067:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:23,067:WARNING:  warnings.warn(
2025-08-27 22:47:30,141:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:47:30,141:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:47:30,191:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:47:30,191:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:47:30,208:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:47:30,234:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:47:30,265:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:47:30,405:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 22:47:30,560:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,570:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,570:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,570:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,581:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:30,592:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,592:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:30,592:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,592:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,602:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,602:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,602:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,620:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,620:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,620:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,630:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,630:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,630:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:30,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:30,642:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,666:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,706:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,716:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,726:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,726:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,726:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,726:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,726:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:30,736:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,736:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,746:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,747:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,747:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,747:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,747:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,747:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:30,757:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,757:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,757:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,757:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,757:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:30,767:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,808:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:30,808:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,818:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,818:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:30,818:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,818:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:30,818:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:30,828:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 22:47:30,828:WARNING:1 fits failed out of a total of 10.
2025-08-27 22:47:30,828:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 22:47:30,828:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 22:47:30,828:WARNING:
2025-08-27 22:47:30,828:WARNING:Below are more details about the failures:
2025-08-27 22:47:30,828:WARNING:--------------------------------------------------------------------------------
2025-08-27 22:47:30,828:WARNING:1 fits failed with the following error:
2025-08-27 22:47:30,828:WARNING:Traceback (most recent call last):
2025-08-27 22:47:30,828:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 22:47:30,828:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 22:47:30,828:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 22:47:30,828:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 22:47:30,828:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 22:47:30,828:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 22:47:30,828:WARNING:    return self.func(*args, **kwargs)
2025-08-27 22:47:30,828:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:47:30,828:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 22:47:30,828:WARNING:    transformer.fit(*args)
2025-08-27 22:47:30,828:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 22:47:30,828:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 22:47:30,828:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:47:30,828:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py", line 1246, in fit
2025-08-27 22:47:30,828:WARNING:    raise ValueError(
2025-08-27 22:47:30,828:WARNING:ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0
2025-08-27 22:47:30,828:WARNING:
2025-08-27 22:47:30,828:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 22:47:30,828:INFO:Calculating mean and std
2025-08-27 22:47:30,828:INFO:Creating metrics dataframe
2025-08-27 22:47:30,828:INFO:Uploading results into container
2025-08-27 22:47:30,828:INFO:Uploading model into container now
2025-08-27 22:47:30,828:INFO:_master_model_container: 1
2025-08-27 22:47:30,828:INFO:_display_container: 2
2025-08-27 22:47:30,828:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=224, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 22:47:30,828:INFO:create_model() successfully completed......................................
2025-08-27 22:47:31,007:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:31,007:INFO:Creating metrics dataframe
2025-08-27 22:47:31,025:INFO:Initializing K Neighbors Classifier
2025-08-27 22:47:31,025:INFO:Total runtime is 0.13439318736394246 minutes
2025-08-27 22:47:31,027:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:31,027:INFO:Initializing create_model()
2025-08-27 22:47:31,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:31,027:INFO:Checking exceptions
2025-08-27 22:47:31,027:INFO:Importing libraries
2025-08-27 22:47:31,027:INFO:Copying training dataset
2025-08-27 22:47:31,027:INFO:Defining folds
2025-08-27 22:47:31,027:INFO:Declaring metric variables
2025-08-27 22:47:31,043:INFO:Importing untrained model
2025-08-27 22:47:31,043:INFO:K Neighbors Classifier Imported successfully
2025-08-27 22:47:31,065:INFO:Starting cross validation
2025-08-27 22:47:31,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:31,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:31,065:WARNING:  warnings.warn(
2025-08-27 22:47:31,180:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,180:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:47:31,180:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,180:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,180:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,186:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,186:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,187:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,196:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,196:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,196:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,196:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

e 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,199:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,207:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,266:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,266:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,275:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,275:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,277:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,277:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,277:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,280:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,281:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,281:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,281:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,291:INFO:Calculating mean and std
2025-08-27 22:47:31,291:INFO:Creating metrics dataframe
2025-08-27 22:47:31,291:INFO:Uploading results into container
2025-08-27 22:47:31,291:INFO:Uploading model into container now
2025-08-27 22:47:31,291:INFO:_master_model_container: 2
2025-08-27 22:47:31,291:INFO:_display_container: 2
2025-08-27 22:47:31,291:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 22:47:31,291:INFO:create_model() successfully completed......................................
2025-08-27 22:47:31,394:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:31,394:INFO:Creating metrics dataframe
2025-08-27 22:47:31,398:INFO:Initializing Naive Bayes
2025-08-27 22:47:31,398:INFO:Total runtime is 0.1406038959821065 minutes
2025-08-27 22:47:31,409:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:31,409:INFO:Initializing create_model()
2025-08-27 22:47:31,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:31,409:INFO:Checking exceptions
2025-08-27 22:47:31,409:INFO:Importing libraries
2025-08-27 22:47:31,409:INFO:Copying training dataset
2025-08-27 22:47:31,409:INFO:Defining folds
2025-08-27 22:47:31,409:INFO:Declaring metric variables
2025-08-27 22:47:31,409:INFO:Importing untrained model
2025-08-27 22:47:31,424:INFO:Naive Bayes Imported successfully
2025-08-27 22:47:31,429:INFO:Starting cross validation
2025-08-27 22:47:31,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:31,443:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:31,443:WARNING:  warnings.warn(
2025-08-27 22:47:31,476:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:47:31,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,490:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,499:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,507:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,507:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,508:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,509:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,525:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,531:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,531:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,531:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,542:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,552:INFO:Calculating mean and std
2025-08-27 22:47:31,552:INFO:Creating metrics dataframe
2025-08-27 22:47:31,552:INFO:Uploading results into container
2025-08-27 22:47:31,552:INFO:Uploading model into container now
2025-08-27 22:47:31,552:INFO:_master_model_container: 3
2025-08-27 22:47:31,552:INFO:_display_container: 2
2025-08-27 22:47:31,552:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 22:47:31,552:INFO:create_model() successfully completed......................................
2025-08-27 22:47:31,641:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:31,641:INFO:Creating metrics dataframe
2025-08-27 22:47:31,658:INFO:Initializing Decision Tree Classifier
2025-08-27 22:47:31,658:INFO:Total runtime is 0.14493627150853475 minutes
2025-08-27 22:47:31,668:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:31,668:INFO:Initializing create_model()
2025-08-27 22:47:31,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:31,668:INFO:Checking exceptions
2025-08-27 22:47:31,668:INFO:Importing libraries
2025-08-27 22:47:31,668:INFO:Copying training dataset
2025-08-27 22:47:31,676:INFO:Defining folds
2025-08-27 22:47:31,676:INFO:Declaring metric variables
2025-08-27 22:47:31,676:INFO:Importing untrained model
2025-08-27 22:47:31,676:INFO:Decision Tree Classifier Imported successfully
2025-08-27 22:47:31,699:INFO:Starting cross validation
2025-08-27 22:47:31,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:31,699:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:31,699:WARNING:  warnings.warn(
2025-08-27 22:47:31,742:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:47:31,742:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,750:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,758:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,768:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,769:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,774:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,775:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,775:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,775:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,775:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,779:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,789:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,791:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,791:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:31,808:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:31,810:INFO:Calculating mean and std
2025-08-27 22:47:31,810:INFO:Creating metrics dataframe
2025-08-27 22:47:31,810:INFO:Uploading results into container
2025-08-27 22:47:31,810:INFO:Uploading model into container now
2025-08-27 22:47:31,810:INFO:_master_model_container: 4
2025-08-27 22:47:31,810:INFO:_display_container: 2
2025-08-27 22:47:31,810:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=224, splitter='best')
2025-08-27 22:47:31,810:INFO:create_model() successfully completed......................................
2025-08-27 22:47:31,908:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:31,908:INFO:Creating metrics dataframe
2025-08-27 22:47:31,916:INFO:Initializing SVM - Linear Kernel
2025-08-27 22:47:31,916:INFO:Total runtime is 0.14924147526423137 minutes
2025-08-27 22:47:31,930:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:31,931:INFO:Initializing create_model()
2025-08-27 22:47:31,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:31,931:INFO:Checking exceptions
2025-08-27 22:47:31,931:INFO:Importing libraries
2025-08-27 22:47:31,931:INFO:Copying training dataset
2025-08-27 22:47:31,934:INFO:Defining folds
2025-08-27 22:47:31,934:INFO:Declaring metric variables
2025-08-27 22:47:31,941:INFO:Importing untrained model
2025-08-27 22:47:31,944:INFO:SVM - Linear Kernel Imported successfully
2025-08-27 22:47:31,944:INFO:Starting cross validation
2025-08-27 22:47:31,958:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:31,963:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:31,963:WARNING:  warnings.warn(
2025-08-27 22:47:32,024:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,031:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,039:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,041:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,046:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,046:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,046:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,046:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,046:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,074:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,074:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,074:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,074:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,089:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,090:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,090:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,101:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,108:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,108:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,108:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

capitalize()} is", len(result))

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,111:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,121:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,121:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,132:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 22:47:32,132:WARNING:1 fits failed out of a total of 10.
2025-08-27 22:47:32,132:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 22:47:32,132:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 22:47:32,132:WARNING:
2025-08-27 22:47:32,132:WARNING:Below are more details about the failures:
2025-08-27 22:47:32,132:WARNING:--------------------------------------------------------------------------------
2025-08-27 22:47:32,132:WARNING:1 fits failed with the following error:
2025-08-27 22:47:32,132:WARNING:Traceback (most recent call last):
2025-08-27 22:47:32,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 22:47:32,132:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 22:47:32,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 22:47:32,132:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 22:47:32,132:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 22:47:32,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 22:47:32,132:WARNING:    return self.func(*args, **kwargs)
2025-08-27 22:47:32,132:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:47:32,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 22:47:32,132:WARNING:    transformer.fit(*args)
2025-08-27 22:47:32,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 22:47:32,132:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 22:47:32,132:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:47:32,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 917, in fit
2025-08-27 22:47:32,132:WARNING:    return self._fit(
2025-08-27 22:47:32,132:WARNING:           ^^^^^^^^^^
2025-08-27 22:47:32,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 704, in _fit
2025-08-27 22:47:32,132:WARNING:    self._partial_fit(
2025-08-27 22:47:32,132:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 658, in _partial_fit
2025-08-27 22:47:32,132:WARNING:    raise ValueError(
2025-08-27 22:47:32,132:WARNING:ValueError: The number of classes has to be greater than one; got 1 class
2025-08-27 22:47:32,132:WARNING:
2025-08-27 22:47:32,132:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 22:47:32,132:INFO:Calculating mean and std
2025-08-27 22:47:32,132:INFO:Creating metrics dataframe
2025-08-27 22:47:32,136:INFO:Uploading results into container
2025-08-27 22:47:32,136:INFO:Uploading model into container now
2025-08-27 22:47:32,136:INFO:_master_model_container: 5
2025-08-27 22:47:32,136:INFO:_display_container: 2
2025-08-27 22:47:32,140:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=224, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-27 22:47:32,140:INFO:create_model() successfully completed......................................
2025-08-27 22:47:32,241:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:32,241:INFO:Creating metrics dataframe
2025-08-27 22:47:32,247:INFO:Initializing Ridge Classifier
2025-08-27 22:47:32,247:INFO:Total runtime is 0.1547545075416565 minutes
2025-08-27 22:47:32,247:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:32,258:INFO:Initializing create_model()
2025-08-27 22:47:32,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:32,258:INFO:Checking exceptions
2025-08-27 22:47:32,258:INFO:Importing libraries
2025-08-27 22:47:32,258:INFO:Copying training dataset
2025-08-27 22:47:32,258:INFO:Defining folds
2025-08-27 22:47:32,258:INFO:Declaring metric variables
2025-08-27 22:47:32,270:INFO:Importing untrained model
2025-08-27 22:47:32,275:INFO:Ridge Classifier Imported successfully
2025-08-27 22:47:32,291:INFO:Starting cross validation
2025-08-27 22:47:32,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:32,298:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:32,298:WARNING:  warnings.warn(
2025-08-27 22:47:32,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,345:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,358:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

capitalize()} is", len(result))

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,366:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,374:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,374:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,376:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,376:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,378:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,388:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,388:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,388:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,391:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,392:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,408:INFO:Calculating mean and std
2025-08-27 22:47:32,409:INFO:Creating metrics dataframe
2025-08-27 22:47:32,412:INFO:Uploading results into container
2025-08-27 22:47:32,414:INFO:Uploading model into container now
2025-08-27 22:47:32,414:INFO:_master_model_container: 6
2025-08-27 22:47:32,414:INFO:_display_container: 2
2025-08-27 22:47:32,414:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=224, solver='auto',
                tol=0.0001)
2025-08-27 22:47:32,414:INFO:create_model() successfully completed......................................
2025-08-27 22:47:32,509:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:32,509:INFO:Creating metrics dataframe
2025-08-27 22:47:32,509:INFO:Initializing Random Forest Classifier
2025-08-27 22:47:32,509:INFO:Total runtime is 0.15911842584609986 minutes
2025-08-27 22:47:32,525:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:32,525:INFO:Initializing create_model()
2025-08-27 22:47:32,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:32,525:INFO:Checking exceptions
2025-08-27 22:47:32,525:INFO:Importing libraries
2025-08-27 22:47:32,525:INFO:Copying training dataset
2025-08-27 22:47:32,525:INFO:Defining folds
2025-08-27 22:47:32,525:INFO:Declaring metric variables
2025-08-27 22:47:32,525:INFO:Importing untrained model
2025-08-27 22:47:32,542:INFO:Random Forest Classifier Imported successfully
2025-08-27 22:47:32,542:INFO:Starting cross validation
2025-08-27 22:47:32,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:32,558:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:32,558:WARNING:  warnings.warn(
2025-08-27 22:47:32,930:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:47:32,935:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,936:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,936:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,936:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,942:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,942:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,943:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,943:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,947:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,947:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,947:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,952:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,955:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,957:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,957:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,957:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,959:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,965:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:32,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,968:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:32,978:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,000:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,000:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,000:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,009:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,009:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,009:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,009:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,205:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,209:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,224:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,234:INFO:Calculating mean and std
2025-08-27 22:47:33,234:INFO:Creating metrics dataframe
2025-08-27 22:47:33,234:INFO:Uploading results into container
2025-08-27 22:47:33,234:INFO:Uploading model into container now
2025-08-27 22:47:33,234:INFO:_master_model_container: 7
2025-08-27 22:47:33,234:INFO:_display_container: 2
2025-08-27 22:47:33,234:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=224, verbose=0,
                       warm_start=False)
2025-08-27 22:47:33,234:INFO:create_model() successfully completed......................................
2025-08-27 22:47:33,329:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:33,329:INFO:Creating metrics dataframe
2025-08-27 22:47:33,343:INFO:Initializing Quadratic Discriminant Analysis
2025-08-27 22:47:33,343:INFO:Total runtime is 0.17302532196044923 minutes
2025-08-27 22:47:33,351:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:33,351:INFO:Initializing create_model()
2025-08-27 22:47:33,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:33,351:INFO:Checking exceptions
2025-08-27 22:47:33,351:INFO:Importing libraries
2025-08-27 22:47:33,351:INFO:Copying training dataset
2025-08-27 22:47:33,360:INFO:Defining folds
2025-08-27 22:47:33,361:INFO:Declaring metric variables
2025-08-27 22:47:33,362:INFO:Importing untrained model
2025-08-27 22:47:33,362:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 22:47:33,382:INFO:Starting cross validation
2025-08-27 22:47:33,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:33,384:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:33,384:WARNING:  warnings.warn(
2025-08-27 22:47:33,456:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-08-27 22:47:33,456:WARNING:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1.0, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-08-27 22:47:33,456:INFO:Initializing create_model()
2025-08-27 22:47:33,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:33,456:INFO:Checking exceptions
2025-08-27 22:47:33,456:INFO:Importing libraries
2025-08-27 22:47:33,456:INFO:Copying training dataset
2025-08-27 22:47:33,460:INFO:Defining folds
2025-08-27 22:47:33,460:INFO:Declaring metric variables
2025-08-27 22:47:33,460:INFO:Importing untrained model
2025-08-27 22:47:33,460:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 22:47:33,478:INFO:Starting cross validation
2025-08-27 22:47:33,478:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:33,478:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:33,478:WARNING:  warnings.warn(
2025-08-27 22:47:33,546:ERROR:create_model() for qda raised an exception or returned all 0.0:
2025-08-27 22:47:33,546:ERROR:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1.0, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 450, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 536, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
9 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 1.0, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py", line 905, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2025-08-27 22:47:33,546:INFO:Initializing Ada Boost Classifier
2025-08-27 22:47:33,546:INFO:Total runtime is 0.17640031178792318 minutes
2025-08-27 22:47:33,546:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:33,546:INFO:Initializing create_model()
2025-08-27 22:47:33,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:33,546:INFO:Checking exceptions
2025-08-27 22:47:33,546:INFO:Importing libraries
2025-08-27 22:47:33,546:INFO:Copying training dataset
2025-08-27 22:47:33,546:INFO:Defining folds
2025-08-27 22:47:33,546:INFO:Declaring metric variables
2025-08-27 22:47:33,560:INFO:Importing untrained model
2025-08-27 22:47:33,560:INFO:Ada Boost Classifier Imported successfully
2025-08-27 22:47:33,576:INFO:Starting cross validation
2025-08-27 22:47:33,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:33,579:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:33,579:WARNING:  warnings.warn(
2025-08-27 22:47:33,604:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,604:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,610:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,610:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,610:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,618:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,618:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,618:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,618:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,630:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,630:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,634:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,641:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,641:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,641:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,641:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,641:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,643:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,646:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,656:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,663:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 22:47:33,667:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,677:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:33,687:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:33,697:INFO:Calculating mean and std
2025-08-27 22:47:33,697:INFO:Creating metrics dataframe
2025-08-27 22:47:33,697:INFO:Uploading results into container
2025-08-27 22:47:33,697:INFO:Uploading model into container now
2025-08-27 22:47:33,697:INFO:_master_model_container: 8
2025-08-27 22:47:33,697:INFO:_display_container: 2
2025-08-27 22:47:33,697:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=224)
2025-08-27 22:47:33,697:INFO:create_model() successfully completed......................................
2025-08-27 22:47:33,795:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:33,795:INFO:Creating metrics dataframe
2025-08-27 22:47:33,814:INFO:Initializing Gradient Boosting Classifier
2025-08-27 22:47:33,814:INFO:Total runtime is 0.18087249199549357 minutes
2025-08-27 22:47:33,814:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:33,814:INFO:Initializing create_model()
2025-08-27 22:47:33,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:33,814:INFO:Checking exceptions
2025-08-27 22:47:33,814:INFO:Importing libraries
2025-08-27 22:47:33,814:INFO:Copying training dataset
2025-08-27 22:47:33,827:INFO:Defining folds
2025-08-27 22:47:33,827:INFO:Declaring metric variables
2025-08-27 22:47:33,828:INFO:Importing untrained model
2025-08-27 22:47:33,828:INFO:Gradient Boosting Classifier Imported successfully
2025-08-27 22:47:33,849:INFO:Starting cross validation
2025-08-27 22:47:33,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:33,849:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:33,849:WARNING:  warnings.warn(
2025-08-27 22:47:34,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,075:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,075:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,075:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,077:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,077:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,078:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,078:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,078:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,082:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,086:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,208:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,208:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,208:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,208:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,218:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,218:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,218:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,228:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
2025-08-27 22:47:34,228:WARNING:1 fits failed out of a total of 10.
2025-08-27 22:47:34,228:WARNING:The score on these train-test partitions for these parameters will be set to 0.0.
2025-08-27 22:47:34,228:WARNING:If these failures are not expected, you can try to debug them by setting error_score='raise'.
2025-08-27 22:47:34,228:WARNING:
2025-08-27 22:47:34,228:WARNING:Below are more details about the failures:
2025-08-27 22:47:34,228:WARNING:--------------------------------------------------------------------------------
2025-08-27 22:47:34,228:WARNING:1 fits failed with the following error:
2025-08-27 22:47:34,228:WARNING:Traceback (most recent call last):
2025-08-27 22:47:34,228:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
2025-08-27 22:47:34,228:WARNING:    estimator.fit(X_train, y_train, **fit_params)
2025-08-27 22:47:34,228:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
2025-08-27 22:47:34,228:WARNING:    fitted_estimator = self._memory_fit(
2025-08-27 22:47:34,228:WARNING:                       ^^^^^^^^^^^^^^^^^
2025-08-27 22:47:34,228:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\memory.py", line 353, in __call__
2025-08-27 22:47:34,228:WARNING:    return self.func(*args, **kwargs)
2025-08-27 22:47:34,228:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:47:34,228:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
2025-08-27 22:47:34,228:WARNING:    transformer.fit(*args)
2025-08-27 22:47:34,228:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py", line 1474, in wrapper
2025-08-27 22:47:34,228:WARNING:    return fit_method(estimator, *args, **kwargs)
2025-08-27 22:47:34,228:WARNING:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:47:34,228:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_gb.py", line 665, in fit
2025-08-27 22:47:34,228:WARNING:    y = self._encode_y(y=y, sample_weight=None)
2025-08-27 22:47:34,228:WARNING:        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-08-27 22:47:34,228:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_gb.py", line 1520, in _encode_y
2025-08-27 22:47:34,228:WARNING:    raise ValueError(
2025-08-27 22:47:34,228:WARNING:ValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.
2025-08-27 22:47:34,228:WARNING:
2025-08-27 22:47:34,228:WARNING:  warnings.warn(some_fits_failed_message, FitFailedWarning)
2025-08-27 22:47:34,228:INFO:Calculating mean and std
2025-08-27 22:47:34,228:INFO:Creating metrics dataframe
2025-08-27 22:47:34,228:INFO:Uploading results into container
2025-08-27 22:47:34,228:INFO:Uploading model into container now
2025-08-27 22:47:34,228:INFO:_master_model_container: 9
2025-08-27 22:47:34,228:INFO:_display_container: 2
2025-08-27 22:47:34,228:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=224, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-27 22:47:34,228:INFO:create_model() successfully completed......................................
2025-08-27 22:47:34,330:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:34,330:INFO:Creating metrics dataframe
2025-08-27 22:47:34,345:INFO:Initializing Linear Discriminant Analysis
2025-08-27 22:47:34,345:INFO:Total runtime is 0.18972837130228679 minutes
2025-08-27 22:47:34,347:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:34,347:INFO:Initializing create_model()
2025-08-27 22:47:34,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:34,347:INFO:Checking exceptions
2025-08-27 22:47:34,347:INFO:Importing libraries
2025-08-27 22:47:34,347:INFO:Copying training dataset
2025-08-27 22:47:34,347:INFO:Defining folds
2025-08-27 22:47:34,347:INFO:Declaring metric variables
2025-08-27 22:47:34,347:INFO:Importing untrained model
2025-08-27 22:47:34,363:INFO:Linear Discriminant Analysis Imported successfully
2025-08-27 22:47:34,377:INFO:Starting cross validation
2025-08-27 22:47:34,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:34,383:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:34,383:WARNING:  warnings.warn(
2025-08-27 22:47:34,425:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,433:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,460:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,481:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,491:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,494:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

ier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,502:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,512:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:34,517:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,527:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:34,537:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:34,547:INFO:Calculating mean and std
2025-08-27 22:47:34,547:INFO:Creating metrics dataframe
2025-08-27 22:47:34,547:INFO:Uploading results into container
2025-08-27 22:47:34,547:INFO:Uploading model into container now
2025-08-27 22:47:34,547:INFO:_master_model_container: 10
2025-08-27 22:47:34,547:INFO:_display_container: 2
2025-08-27 22:47:34,547:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-08-27 22:47:34,547:INFO:create_model() successfully completed......................................
2025-08-27 22:47:34,647:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:34,647:INFO:Creating metrics dataframe
2025-08-27 22:47:34,662:INFO:Initializing Extra Trees Classifier
2025-08-27 22:47:34,662:INFO:Total runtime is 0.19501396417617797 minutes
2025-08-27 22:47:34,668:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:34,668:INFO:Initializing create_model()
2025-08-27 22:47:34,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:34,668:INFO:Checking exceptions
2025-08-27 22:47:34,668:INFO:Importing libraries
2025-08-27 22:47:34,668:INFO:Copying training dataset
2025-08-27 22:47:34,668:INFO:Defining folds
2025-08-27 22:47:34,668:INFO:Declaring metric variables
2025-08-27 22:47:34,679:INFO:Importing untrained model
2025-08-27 22:47:34,679:INFO:Extra Trees Classifier Imported successfully
2025-08-27 22:47:34,694:INFO:Starting cross validation
2025-08-27 22:47:34,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:34,699:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:34,699:WARNING:  warnings.warn(
2025-08-27 22:47:35,002:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:47:35,012:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,012:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,012:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,017:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,019:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,019:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,022:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,028:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,028:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,028:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,028:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,028:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,032:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,032:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,032:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,032:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,032:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,035:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,035:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,035:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,035:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,035:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,035:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,035:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,042:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,044:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,044:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,046:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,050:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,138:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,138:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,148:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,256:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,256:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,261:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,261:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,265:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,265:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,270:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,280:INFO:Calculating mean and std
2025-08-27 22:47:35,280:INFO:Creating metrics dataframe
2025-08-27 22:47:35,280:INFO:Uploading results into container
2025-08-27 22:47:35,280:INFO:Uploading model into container now
2025-08-27 22:47:35,280:INFO:_master_model_container: 11
2025-08-27 22:47:35,280:INFO:_display_container: 2
2025-08-27 22:47:35,280:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=224, verbose=0,
                     warm_start=False)
2025-08-27 22:47:35,280:INFO:create_model() successfully completed......................................
2025-08-27 22:47:35,380:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:35,380:INFO:Creating metrics dataframe
2025-08-27 22:47:35,397:INFO:Initializing Light Gradient Boosting Machine
2025-08-27 22:47:35,397:INFO:Total runtime is 0.20725000301996865 minutes
2025-08-27 22:47:35,397:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:35,397:INFO:Initializing create_model()
2025-08-27 22:47:35,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:35,397:INFO:Checking exceptions
2025-08-27 22:47:35,397:INFO:Importing libraries
2025-08-27 22:47:35,397:INFO:Copying training dataset
2025-08-27 22:47:35,397:INFO:Defining folds
2025-08-27 22:47:35,397:INFO:Declaring metric variables
2025-08-27 22:47:35,414:INFO:Importing untrained model
2025-08-27 22:47:35,414:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-27 22:47:35,432:INFO:Starting cross validation
2025-08-27 22:47:35,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:35,435:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:35,435:WARNING:  warnings.warn(
2025-08-27 22:47:35,519:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,652:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,662:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,662:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,672:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,672:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,672:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,672:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,682:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,682:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,692:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,697:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,697:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,700:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,702:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,702:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,702:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,702:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,702:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,702:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,713:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,713:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,713:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,713:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,713:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,713:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,713:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,713:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,723:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,733:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,733:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,733:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,743:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,753:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,753:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,753:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,753:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,773:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,773:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,784:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,784:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,784:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,784:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,784:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,784:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,784:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,795:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,800:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,804:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,845:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:35,845:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,855:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,855:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:35,855:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,855:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:35,865:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:35,875:INFO:Calculating mean and std
2025-08-27 22:47:35,875:INFO:Creating metrics dataframe
2025-08-27 22:47:35,880:INFO:Uploading results into container
2025-08-27 22:47:35,880:INFO:Uploading model into container now
2025-08-27 22:47:35,883:INFO:_master_model_container: 12
2025-08-27 22:47:35,883:INFO:_display_container: 2
2025-08-27 22:47:35,885:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=224, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-27 22:47:35,885:INFO:create_model() successfully completed......................................
2025-08-27 22:47:36,008:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:36,008:INFO:Creating metrics dataframe
2025-08-27 22:47:36,015:INFO:Initializing Dummy Classifier
2025-08-27 22:47:36,015:INFO:Total runtime is 0.21756353775660195 minutes
2025-08-27 22:47:36,015:INFO:SubProcess create_model() called ==================================
2025-08-27 22:47:36,015:INFO:Initializing create_model()
2025-08-27 22:47:36,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017B653B9090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:36,015:INFO:Checking exceptions
2025-08-27 22:47:36,015:INFO:Importing libraries
2025-08-27 22:47:36,015:INFO:Copying training dataset
2025-08-27 22:47:36,031:INFO:Defining folds
2025-08-27 22:47:36,031:INFO:Declaring metric variables
2025-08-27 22:47:36,031:INFO:Importing untrained model
2025-08-27 22:47:36,040:INFO:Dummy Classifier Imported successfully
2025-08-27 22:47:36,054:INFO:Starting cross validation
2025-08-27 22:47:36,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 22:47:36,054:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.
2025-08-27 22:47:36,054:WARNING:  warnings.warn(
2025-08-27 22:47:36,090:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
             ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
                ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 213, in _get_response_values
    y_pred = _process_predict_proba(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_response.py", line 50, in _process_predict_proba
    raise ValueError(
ValueError: Got predict_proba of shape (70, 1), but need classifier with two classes.

  warnings.warn(

2025-08-27 22:47:36,090:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,090:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,090:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,098:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,106:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,122:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,129:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,129:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,133:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 640, in roc_auc_score
    return _average_binary_score(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 382, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(

2025-08-27 22:47:36,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:708: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,143:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.
  warnings.warn(

2025-08-27 22:47:36,154:INFO:Calculating mean and std
2025-08-27 22:47:36,154:INFO:Creating metrics dataframe
2025-08-27 22:47:36,154:INFO:Uploading results into container
2025-08-27 22:47:36,154:INFO:Uploading model into container now
2025-08-27 22:47:36,154:INFO:_master_model_container: 13
2025-08-27 22:47:36,154:INFO:_display_container: 2
2025-08-27 22:47:36,154:INFO:DummyClassifier(constant=None, random_state=224, strategy='prior')
2025-08-27 22:47:36,154:INFO:create_model() successfully completed......................................
2025-08-27 22:47:36,250:INFO:SubProcess create_model() end ==================================
2025-08-27 22:47:36,250:INFO:Creating metrics dataframe
2025-08-27 22:47:36,281:INFO:Initializing create_model()
2025-08-27 22:47:36,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=224, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 22:47:36,281:INFO:Checking exceptions
2025-08-27 22:47:36,281:INFO:Importing libraries
2025-08-27 22:47:36,281:INFO:Copying training dataset
2025-08-27 22:47:36,281:INFO:Defining folds
2025-08-27 22:47:36,281:INFO:Declaring metric variables
2025-08-27 22:47:36,281:INFO:Importing untrained model
2025-08-27 22:47:36,281:INFO:Declaring custom model
2025-08-27 22:47:36,281:INFO:Logistic Regression Imported successfully
2025-08-27 22:47:36,281:INFO:Cross validation set to False
2025-08-27 22:47:36,281:INFO:Fitting Model
2025-08-27 22:47:36,313:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=224, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 22:47:36,313:INFO:create_model() successfully completed......................................
2025-08-27 22:47:36,451:INFO:_master_model_container: 13
2025-08-27 22:47:36,451:INFO:_display_container: 2
2025-08-27 22:47:36,451:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=224, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 22:47:36,451:INFO:compare_models() successfully completed......................................
2025-08-27 22:47:36,451:INFO:Initializing plot_model()
2025-08-27 22:47:36,451:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017B6D668950>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=224, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-27 22:47:36,451:INFO:Checking exceptions
2025-08-27 22:47:36,466:INFO:Preloading libraries
2025-08-27 22:47:36,466:INFO:Copying training dataset
2025-08-27 22:47:36,466:INFO:Plot type: confusion_matrix
2025-08-27 22:47:36,537:INFO:Fitting Model
2025-08-27 22:47:36,537:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
2025-08-27 22:47:36,537:WARNING:  warnings.warn(
2025-08-27 22:47:36,537:INFO:Scoring test/hold-out set
2025-08-27 22:47:36,648:INFO:Visual Rendered Successfully
2025-08-27 22:47:36,746:INFO:plot_model() successfully completed......................................
2025-08-27 23:08:00,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 23:08:00,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 23:08:00,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 23:08:00,911:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 23:08:06,432:INFO:PyCaret ClassificationExperiment
2025-08-27 23:08:06,432:INFO:Logging name: clf-default-name
2025-08-27 23:08:06,433:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 23:08:06,433:INFO:version 3.3.2
2025-08-27 23:08:06,433:INFO:Initializing setup()
2025-08-27 23:08:06,433:INFO:self.USI: e339
2025-08-27 23:08:06,433:INFO:self._variable_keys: {'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'gpu_param', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'memory', 'fold_generator', 'html_param', 'y_train', 'USI', 'data', 'X_test', 'fold_groups_param', 'logging_param', 'X', '_ml_usecase', 'X_train', 'exp_id', 'pipeline', 'seed', '_available_plots', 'fix_imbalance', 'target_param', 'n_jobs_param', 'idx'}
2025-08-27 23:08:06,433:INFO:Checking environment
2025-08-27 23:08:06,433:INFO:python_version: 3.11.9
2025-08-27 23:08:06,433:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 23:08:06,433:INFO:machine: AMD64
2025-08-27 23:08:06,433:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 23:08:06,434:INFO:Memory: svmem(total=17024348160, available=3106463744, percent=81.8, used=13917884416, free=3106463744)
2025-08-27 23:08:06,434:INFO:Physical Core: 4
2025-08-27 23:08:06,434:INFO:Logical Core: 8
2025-08-27 23:08:06,434:INFO:Checking libraries
2025-08-27 23:08:06,434:INFO:System:
2025-08-27 23:08:06,434:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 23:08:06,434:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 23:08:06,434:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 23:08:06,434:INFO:PyCaret required dependencies:
2025-08-27 23:08:06,459:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:06,617:INFO:                 pip: Not installed
2025-08-27 23:08:06,617:INFO:          setuptools: 80.9.0
2025-08-27 23:08:06,617:INFO:             pycaret: 3.3.2
2025-08-27 23:08:06,617:INFO:             IPython: 9.4.0
2025-08-27 23:08:06,617:INFO:          ipywidgets: 8.1.7
2025-08-27 23:08:06,617:INFO:                tqdm: 4.67.1
2025-08-27 23:08:06,617:INFO:               numpy: 1.26.4
2025-08-27 23:08:06,617:INFO:              pandas: 2.1.4
2025-08-27 23:08:06,617:INFO:              jinja2: 3.1.6
2025-08-27 23:08:06,617:INFO:               scipy: 1.11.4
2025-08-27 23:08:06,617:INFO:              joblib: 1.3.2
2025-08-27 23:08:06,617:INFO:             sklearn: 1.4.2
2025-08-27 23:08:06,617:INFO:                pyod: 2.0.5
2025-08-27 23:08:06,617:INFO:            imblearn: 0.14.0
2025-08-27 23:08:06,617:INFO:   category_encoders: 2.7.0
2025-08-27 23:08:06,617:INFO:            lightgbm: 4.6.0
2025-08-27 23:08:06,617:INFO:               numba: 0.61.2
2025-08-27 23:08:06,617:INFO:            requests: 2.32.5
2025-08-27 23:08:06,617:INFO:          matplotlib: 3.7.5
2025-08-27 23:08:06,617:INFO:          scikitplot: 0.3.7
2025-08-27 23:08:06,617:INFO:         yellowbrick: 1.5
2025-08-27 23:08:06,617:INFO:              plotly: 5.24.1
2025-08-27 23:08:06,617:INFO:    plotly-resampler: Not installed
2025-08-27 23:08:06,617:INFO:             kaleido: 1.0.0
2025-08-27 23:08:06,617:INFO:           schemdraw: 0.15
2025-08-27 23:08:06,617:INFO:         statsmodels: 0.14.5
2025-08-27 23:08:06,617:INFO:              sktime: 0.26.0
2025-08-27 23:08:06,617:INFO:               tbats: 1.1.3
2025-08-27 23:08:06,617:INFO:            pmdarima: 2.0.4
2025-08-27 23:08:06,617:INFO:              psutil: 7.0.0
2025-08-27 23:08:06,617:INFO:          markupsafe: 3.0.2
2025-08-27 23:08:06,617:INFO:             pickle5: Not installed
2025-08-27 23:08:06,617:INFO:         cloudpickle: 3.1.1
2025-08-27 23:08:06,617:INFO:         deprecation: 2.1.0
2025-08-27 23:08:06,617:INFO:              xxhash: 3.5.0
2025-08-27 23:08:06,617:INFO:           wurlitzer: Not installed
2025-08-27 23:08:06,617:INFO:PyCaret optional dependencies:
2025-08-27 23:08:06,704:INFO:                shap: Not installed
2025-08-27 23:08:06,704:INFO:           interpret: Not installed
2025-08-27 23:08:06,704:INFO:                umap: Not installed
2025-08-27 23:08:06,704:INFO:     ydata_profiling: Not installed
2025-08-27 23:08:06,704:INFO:  explainerdashboard: Not installed
2025-08-27 23:08:06,704:INFO:             autoviz: Not installed
2025-08-27 23:08:06,704:INFO:           fairlearn: Not installed
2025-08-27 23:08:06,704:INFO:          deepchecks: Not installed
2025-08-27 23:08:06,704:INFO:             xgboost: Not installed
2025-08-27 23:08:06,704:INFO:            catboost: Not installed
2025-08-27 23:08:06,704:INFO:              kmodes: Not installed
2025-08-27 23:08:06,704:INFO:             mlxtend: Not installed
2025-08-27 23:08:06,704:INFO:       statsforecast: Not installed
2025-08-27 23:08:06,704:INFO:        tune_sklearn: Not installed
2025-08-27 23:08:06,704:INFO:                 ray: Not installed
2025-08-27 23:08:06,704:INFO:            hyperopt: Not installed
2025-08-27 23:08:06,704:INFO:              optuna: Not installed
2025-08-27 23:08:06,704:INFO:               skopt: Not installed
2025-08-27 23:08:06,704:INFO:              mlflow: Not installed
2025-08-27 23:08:06,704:INFO:              gradio: Not installed
2025-08-27 23:08:06,704:INFO:             fastapi: Not installed
2025-08-27 23:08:06,704:INFO:             uvicorn: Not installed
2025-08-27 23:08:06,704:INFO:              m2cgen: Not installed
2025-08-27 23:08:06,704:INFO:           evidently: Not installed
2025-08-27 23:08:06,710:INFO:               fugue: Not installed
2025-08-27 23:08:06,710:INFO:           streamlit: Not installed
2025-08-27 23:08:06,711:INFO:             prophet: Not installed
2025-08-27 23:08:06,711:INFO:None
2025-08-27 23:08:06,711:INFO:Set up data.
2025-08-27 23:08:06,780:INFO:Set up folding strategy.
2025-08-27 23:08:06,780:INFO:Set up train/test split.
2025-08-27 23:08:06,874:INFO:Set up index.
2025-08-27 23:08:06,888:INFO:Assigning column types.
2025-08-27 23:08:06,998:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 23:08:07,101:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 23:08:07,113:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:08:07,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,262:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 23:08:07,264:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:08:07,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,344:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 23:08:07,435:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:08:07,530:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,704:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:08:07,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,745:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 23:08:07,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:07,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:08,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:08,019:INFO:Preparing preprocessing pipeline...
2025-08-27 23:08:08,020:INFO:Set up date feature engineering.
2025-08-27 23:08:08,020:INFO:Set up simple imputation.
2025-08-27 23:08:08,362:INFO:Finished creating preprocessing pipeline.
2025-08-27 23:08:08,371:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['timestamp'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    t...SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-27 23:08:08,371:INFO:Creating final display dataframe.
2025-08-27 23:08:09,177:INFO:Setup _display_container:                     Description             Value
0                    Session id              8837
1                        Target           failure
2                   Target type            Binary
3           Original data shape       (116060, 7)
4        Transformed data shape       (116060, 9)
5   Transformed train set shape        (81242, 9)
6    Transformed test set shape        (34818, 9)
7              Numeric features                 5
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator   StratifiedKFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  clf-default-name
19                          USI              e339
2025-08-27 23:08:09,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:09,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:09,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:09,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:08:09,744:INFO:setup() successfully completed in 3.31s...............
2025-08-27 23:08:09,744:INFO:Initializing compare_models()
2025-08-27 23:08:09,744:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0AE5EAF10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0AE5EAF10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-27 23:08:09,744:INFO:Checking exceptions
2025-08-27 23:08:09,783:INFO:Preparing display monitor
2025-08-27 23:08:09,817:INFO:Initializing Logistic Regression
2025-08-27 23:08:09,817:INFO:Total runtime is 0.0 minutes
2025-08-27 23:08:09,829:INFO:SubProcess create_model() called ==================================
2025-08-27 23:08:09,829:INFO:Initializing create_model()
2025-08-27 23:08:09,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0AE5EAF10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C1EA45D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:08:09,830:INFO:Checking exceptions
2025-08-27 23:08:09,830:INFO:Importing libraries
2025-08-27 23:08:09,830:INFO:Copying training dataset
2025-08-27 23:08:09,901:INFO:Defining folds
2025-08-27 23:08:09,901:INFO:Declaring metric variables
2025-08-27 23:08:09,906:INFO:Importing untrained model
2025-08-27 23:08:09,911:INFO:Logistic Regression Imported successfully
2025-08-27 23:08:09,922:INFO:Starting cross validation
2025-08-27 23:08:09,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:08:19,057:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:19,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:19,073:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:19,073:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:19,085:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:19,088:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:19,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:19,191:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:08:21,758:INFO:Calculating mean and std
2025-08-27 23:08:21,764:INFO:Creating metrics dataframe
2025-08-27 23:08:21,774:INFO:Uploading results into container
2025-08-27 23:08:21,778:INFO:Uploading model into container now
2025-08-27 23:08:21,780:INFO:_master_model_container: 1
2025-08-27 23:08:21,781:INFO:_display_container: 2
2025-08-27 23:08:21,787:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8837, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 23:08:21,787:INFO:create_model() successfully completed......................................
2025-08-27 23:08:22,037:INFO:SubProcess create_model() end ==================================
2025-08-27 23:08:22,037:INFO:Creating metrics dataframe
2025-08-27 23:08:22,047:INFO:Initializing K Neighbors Classifier
2025-08-27 23:08:22,048:INFO:Total runtime is 0.20385140577952068 minutes
2025-08-27 23:08:22,052:INFO:SubProcess create_model() called ==================================
2025-08-27 23:08:22,053:INFO:Initializing create_model()
2025-08-27 23:08:22,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0AE5EAF10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C1EA45D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:08:22,053:INFO:Checking exceptions
2025-08-27 23:08:22,053:INFO:Importing libraries
2025-08-27 23:08:22,053:INFO:Copying training dataset
2025-08-27 23:08:22,187:INFO:Defining folds
2025-08-27 23:08:22,187:INFO:Declaring metric variables
2025-08-27 23:08:22,207:INFO:Importing untrained model
2025-08-27 23:08:22,228:INFO:K Neighbors Classifier Imported successfully
2025-08-27 23:08:22,263:INFO:Starting cross validation
2025-08-27 23:08:22,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:08:26,440:INFO:Calculating mean and std
2025-08-27 23:08:26,441:INFO:Creating metrics dataframe
2025-08-27 23:08:26,445:INFO:Uploading results into container
2025-08-27 23:08:26,445:INFO:Uploading model into container now
2025-08-27 23:08:26,447:INFO:_master_model_container: 2
2025-08-27 23:08:26,447:INFO:_display_container: 2
2025-08-27 23:08:26,447:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 23:08:26,448:INFO:create_model() successfully completed......................................
2025-08-27 23:08:26,628:INFO:SubProcess create_model() end ==================================
2025-08-27 23:08:26,628:INFO:Creating metrics dataframe
2025-08-27 23:08:26,642:INFO:Initializing Naive Bayes
2025-08-27 23:08:26,642:INFO:Total runtime is 0.28042256434758506 minutes
2025-08-27 23:08:26,650:INFO:SubProcess create_model() called ==================================
2025-08-27 23:08:26,651:INFO:Initializing create_model()
2025-08-27 23:08:26,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0AE5EAF10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C1EA45D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:08:26,651:INFO:Checking exceptions
2025-08-27 23:08:26,651:INFO:Importing libraries
2025-08-27 23:08:26,651:INFO:Copying training dataset
2025-08-27 23:08:26,729:INFO:Defining folds
2025-08-27 23:08:26,729:INFO:Declaring metric variables
2025-08-27 23:08:26,735:INFO:Importing untrained model
2025-08-27 23:08:26,742:INFO:Naive Bayes Imported successfully
2025-08-27 23:08:26,753:INFO:Starting cross validation
2025-08-27 23:08:26,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:08:27,504:INFO:Calculating mean and std
2025-08-27 23:08:27,508:INFO:Creating metrics dataframe
2025-08-27 23:08:27,514:INFO:Uploading results into container
2025-08-27 23:08:27,515:INFO:Uploading model into container now
2025-08-27 23:08:27,516:INFO:_master_model_container: 3
2025-08-27 23:08:27,516:INFO:_display_container: 2
2025-08-27 23:08:27,517:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 23:08:27,517:INFO:create_model() successfully completed......................................
2025-08-27 23:08:27,739:INFO:SubProcess create_model() end ==================================
2025-08-27 23:08:27,739:INFO:Creating metrics dataframe
2025-08-27 23:08:27,750:INFO:Initializing Decision Tree Classifier
2025-08-27 23:08:27,750:INFO:Total runtime is 0.2988810102144877 minutes
2025-08-27 23:08:27,755:INFO:SubProcess create_model() called ==================================
2025-08-27 23:08:27,755:INFO:Initializing create_model()
2025-08-27 23:08:27,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0AE5EAF10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C1EA45D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:08:27,756:INFO:Checking exceptions
2025-08-27 23:08:27,756:INFO:Importing libraries
2025-08-27 23:08:27,756:INFO:Copying training dataset
2025-08-27 23:08:27,813:INFO:Defining folds
2025-08-27 23:08:27,813:INFO:Declaring metric variables
2025-08-27 23:08:27,820:INFO:Importing untrained model
2025-08-27 23:08:27,826:INFO:Decision Tree Classifier Imported successfully
2025-08-27 23:08:27,837:INFO:Starting cross validation
2025-08-27 23:08:27,838:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:08:28,609:INFO:Calculating mean and std
2025-08-27 23:08:28,610:INFO:Creating metrics dataframe
2025-08-27 23:08:28,612:INFO:Uploading results into container
2025-08-27 23:08:28,613:INFO:Uploading model into container now
2025-08-27 23:08:28,613:INFO:_master_model_container: 4
2025-08-27 23:08:28,613:INFO:_display_container: 2
2025-08-27 23:08:28,613:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8837, splitter='best')
2025-08-27 23:08:28,613:INFO:create_model() successfully completed......................................
2025-08-27 23:08:28,743:INFO:SubProcess create_model() end ==================================
2025-08-27 23:08:28,743:INFO:Creating metrics dataframe
2025-08-27 23:08:28,752:INFO:Initializing SVM - Linear Kernel
2025-08-27 23:08:28,753:INFO:Total runtime is 0.3155898690223694 minutes
2025-08-27 23:08:28,758:INFO:SubProcess create_model() called ==================================
2025-08-27 23:08:28,758:INFO:Initializing create_model()
2025-08-27 23:08:28,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0AE5EAF10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0C1EA45D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:08:28,759:INFO:Checking exceptions
2025-08-27 23:08:28,759:INFO:Importing libraries
2025-08-27 23:08:28,759:INFO:Copying training dataset
2025-08-27 23:08:28,808:INFO:Defining folds
2025-08-27 23:08:28,808:INFO:Declaring metric variables
2025-08-27 23:08:28,813:INFO:Importing untrained model
2025-08-27 23:08:28,818:INFO:SVM - Linear Kernel Imported successfully
2025-08-27 23:08:28,827:INFO:Starting cross validation
2025-08-27 23:08:28,828:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:02,921:INFO:PyCaret ClassificationExperiment
2025-08-27 23:09:02,921:INFO:Logging name: clf-default-name
2025-08-27 23:09:02,921:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 23:09:02,921:INFO:version 3.3.2
2025-08-27 23:09:02,921:INFO:Initializing setup()
2025-08-27 23:09:02,921:INFO:self.USI: 6775
2025-08-27 23:09:02,921:INFO:self._variable_keys: {'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'gpu_param', 'y_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'memory', 'fold_generator', 'html_param', 'y_train', 'USI', 'data', 'X_test', 'fold_groups_param', 'logging_param', 'X', '_ml_usecase', 'X_train', 'exp_id', 'pipeline', 'seed', '_available_plots', 'fix_imbalance', 'target_param', 'n_jobs_param', 'idx'}
2025-08-27 23:09:02,922:INFO:Checking environment
2025-08-27 23:09:02,922:INFO:python_version: 3.11.9
2025-08-27 23:09:02,922:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 23:09:02,922:INFO:machine: AMD64
2025-08-27 23:09:02,922:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 23:09:02,925:INFO:Memory: svmem(total=17024348160, available=3203956736, percent=81.2, used=13820391424, free=3203956736)
2025-08-27 23:09:02,925:INFO:Physical Core: 4
2025-08-27 23:09:02,925:INFO:Logical Core: 8
2025-08-27 23:09:02,925:INFO:Checking libraries
2025-08-27 23:09:02,925:INFO:System:
2025-08-27 23:09:02,925:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 23:09:02,925:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 23:09:02,925:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 23:09:02,925:INFO:PyCaret required dependencies:
2025-08-27 23:09:02,925:INFO:                 pip: Not installed
2025-08-27 23:09:02,925:INFO:          setuptools: 80.9.0
2025-08-27 23:09:02,925:INFO:             pycaret: 3.3.2
2025-08-27 23:09:02,925:INFO:             IPython: 9.4.0
2025-08-27 23:09:02,925:INFO:          ipywidgets: 8.1.7
2025-08-27 23:09:02,925:INFO:                tqdm: 4.67.1
2025-08-27 23:09:02,925:INFO:               numpy: 1.26.4
2025-08-27 23:09:02,925:INFO:              pandas: 2.1.4
2025-08-27 23:09:02,925:INFO:              jinja2: 3.1.6
2025-08-27 23:09:02,925:INFO:               scipy: 1.11.4
2025-08-27 23:09:02,926:INFO:              joblib: 1.3.2
2025-08-27 23:09:02,926:INFO:             sklearn: 1.4.2
2025-08-27 23:09:02,926:INFO:                pyod: 2.0.5
2025-08-27 23:09:02,926:INFO:            imblearn: 0.14.0
2025-08-27 23:09:02,926:INFO:   category_encoders: 2.7.0
2025-08-27 23:09:02,926:INFO:            lightgbm: 4.6.0
2025-08-27 23:09:02,926:INFO:               numba: 0.61.2
2025-08-27 23:09:02,926:INFO:            requests: 2.32.5
2025-08-27 23:09:02,926:INFO:          matplotlib: 3.7.5
2025-08-27 23:09:02,926:INFO:          scikitplot: 0.3.7
2025-08-27 23:09:02,926:INFO:         yellowbrick: 1.5
2025-08-27 23:09:02,926:INFO:              plotly: 5.24.1
2025-08-27 23:09:02,926:INFO:    plotly-resampler: Not installed
2025-08-27 23:09:02,926:INFO:             kaleido: 1.0.0
2025-08-27 23:09:02,926:INFO:           schemdraw: 0.15
2025-08-27 23:09:02,926:INFO:         statsmodels: 0.14.5
2025-08-27 23:09:02,926:INFO:              sktime: 0.26.0
2025-08-27 23:09:02,926:INFO:               tbats: 1.1.3
2025-08-27 23:09:02,926:INFO:            pmdarima: 2.0.4
2025-08-27 23:09:02,926:INFO:              psutil: 7.0.0
2025-08-27 23:09:02,926:INFO:          markupsafe: 3.0.2
2025-08-27 23:09:02,926:INFO:             pickle5: Not installed
2025-08-27 23:09:02,926:INFO:         cloudpickle: 3.1.1
2025-08-27 23:09:02,926:INFO:         deprecation: 2.1.0
2025-08-27 23:09:02,926:INFO:              xxhash: 3.5.0
2025-08-27 23:09:02,926:INFO:           wurlitzer: Not installed
2025-08-27 23:09:02,926:INFO:PyCaret optional dependencies:
2025-08-27 23:09:02,926:INFO:                shap: Not installed
2025-08-27 23:09:02,926:INFO:           interpret: Not installed
2025-08-27 23:09:02,926:INFO:                umap: Not installed
2025-08-27 23:09:02,926:INFO:     ydata_profiling: Not installed
2025-08-27 23:09:02,926:INFO:  explainerdashboard: Not installed
2025-08-27 23:09:02,926:INFO:             autoviz: Not installed
2025-08-27 23:09:02,926:INFO:           fairlearn: Not installed
2025-08-27 23:09:02,926:INFO:          deepchecks: Not installed
2025-08-27 23:09:02,926:INFO:             xgboost: Not installed
2025-08-27 23:09:02,926:INFO:            catboost: Not installed
2025-08-27 23:09:02,926:INFO:              kmodes: Not installed
2025-08-27 23:09:02,926:INFO:             mlxtend: Not installed
2025-08-27 23:09:02,926:INFO:       statsforecast: Not installed
2025-08-27 23:09:02,926:INFO:        tune_sklearn: Not installed
2025-08-27 23:09:02,926:INFO:                 ray: Not installed
2025-08-27 23:09:02,926:INFO:            hyperopt: Not installed
2025-08-27 23:09:02,926:INFO:              optuna: Not installed
2025-08-27 23:09:02,926:INFO:               skopt: Not installed
2025-08-27 23:09:02,926:INFO:              mlflow: Not installed
2025-08-27 23:09:02,926:INFO:              gradio: Not installed
2025-08-27 23:09:02,926:INFO:             fastapi: Not installed
2025-08-27 23:09:02,926:INFO:             uvicorn: Not installed
2025-08-27 23:09:02,926:INFO:              m2cgen: Not installed
2025-08-27 23:09:02,926:INFO:           evidently: Not installed
2025-08-27 23:09:02,926:INFO:               fugue: Not installed
2025-08-27 23:09:02,926:INFO:           streamlit: Not installed
2025-08-27 23:09:02,926:INFO:             prophet: Not installed
2025-08-27 23:09:02,926:INFO:None
2025-08-27 23:09:02,926:INFO:Set up data.
2025-08-27 23:09:02,949:INFO:Set up folding strategy.
2025-08-27 23:09:02,949:INFO:Set up train/test split.
2025-08-27 23:09:03,022:INFO:Set up index.
2025-08-27 23:09:03,031:INFO:Assigning column types.
2025-08-27 23:09:03,051:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 23:09:03,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 23:09:03,118:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:09:03,208:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,303:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 23:09:03,305:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:09:03,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,337:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 23:09:03,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:09:03,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,519:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:09:03,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,581:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 23:09:03,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:03,992:INFO:Preparing preprocessing pipeline...
2025-08-27 23:09:04,006:INFO:Set up simple imputation.
2025-08-27 23:09:04,219:INFO:Finished creating preprocessing pipeline.
2025-08-27 23:09:04,224:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-27 23:09:04,224:INFO:Creating final display dataframe.
2025-08-27 23:09:04,452:INFO:Setup _display_container:                     Description             Value
0                    Session id              1898
1                        Target           failure
2                   Target type            Binary
3           Original data shape       (116060, 6)
4        Transformed data shape       (116060, 6)
5   Transformed train set shape        (81242, 6)
6    Transformed test set shape        (34818, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              6775
2025-08-27 23:09:04,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:04,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:04,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:04,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:09:04,955:INFO:setup() successfully completed in 2.04s...............
2025-08-27 23:09:04,969:INFO:Initializing compare_models()
2025-08-27 23:09:04,969:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-27 23:09:04,970:INFO:Checking exceptions
2025-08-27 23:09:05,044:INFO:Preparing display monitor
2025-08-27 23:09:05,114:INFO:Initializing Logistic Regression
2025-08-27 23:09:05,114:INFO:Total runtime is 0.0 minutes
2025-08-27 23:09:05,122:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:05,123:INFO:Initializing create_model()
2025-08-27 23:09:05,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:05,123:INFO:Checking exceptions
2025-08-27 23:09:05,123:INFO:Importing libraries
2025-08-27 23:09:05,123:INFO:Copying training dataset
2025-08-27 23:09:05,188:INFO:Defining folds
2025-08-27 23:09:05,189:INFO:Declaring metric variables
2025-08-27 23:09:05,211:INFO:Importing untrained model
2025-08-27 23:09:05,218:INFO:Logistic Regression Imported successfully
2025-08-27 23:09:05,228:INFO:Starting cross validation
2025-08-27 23:09:05,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:10,994:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:09:11,007:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:09:11,010:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:09:11,029:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:09:11,055:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:09:11,058:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:09:11,134:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:09:11,331:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:09:12,140:INFO:Calculating mean and std
2025-08-27 23:09:12,142:INFO:Creating metrics dataframe
2025-08-27 23:09:12,144:INFO:Uploading results into container
2025-08-27 23:09:12,145:INFO:Uploading model into container now
2025-08-27 23:09:12,145:INFO:_master_model_container: 1
2025-08-27 23:09:12,146:INFO:_display_container: 2
2025-08-27 23:09:12,146:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1898, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 23:09:12,146:INFO:create_model() successfully completed......................................
2025-08-27 23:09:12,358:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:12,358:INFO:Creating metrics dataframe
2025-08-27 23:09:12,367:INFO:Initializing K Neighbors Classifier
2025-08-27 23:09:12,367:INFO:Total runtime is 0.12088191509246826 minutes
2025-08-27 23:09:12,373:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:12,374:INFO:Initializing create_model()
2025-08-27 23:09:12,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:12,375:INFO:Checking exceptions
2025-08-27 23:09:12,376:INFO:Importing libraries
2025-08-27 23:09:12,376:INFO:Copying training dataset
2025-08-27 23:09:12,474:INFO:Defining folds
2025-08-27 23:09:12,474:INFO:Declaring metric variables
2025-08-27 23:09:12,491:INFO:Importing untrained model
2025-08-27 23:09:12,505:INFO:K Neighbors Classifier Imported successfully
2025-08-27 23:09:12,539:INFO:Starting cross validation
2025-08-27 23:09:12,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:15,140:INFO:Calculating mean and std
2025-08-27 23:09:15,142:INFO:Creating metrics dataframe
2025-08-27 23:09:15,143:INFO:Uploading results into container
2025-08-27 23:09:15,145:INFO:Uploading model into container now
2025-08-27 23:09:15,145:INFO:_master_model_container: 2
2025-08-27 23:09:15,146:INFO:_display_container: 2
2025-08-27 23:09:15,146:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 23:09:15,146:INFO:create_model() successfully completed......................................
2025-08-27 23:09:15,425:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:15,425:INFO:Creating metrics dataframe
2025-08-27 23:09:15,455:INFO:Initializing Naive Bayes
2025-08-27 23:09:15,455:INFO:Total runtime is 0.17234817345937092 minutes
2025-08-27 23:09:15,471:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:15,473:INFO:Initializing create_model()
2025-08-27 23:09:15,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:15,474:INFO:Checking exceptions
2025-08-27 23:09:15,474:INFO:Importing libraries
2025-08-27 23:09:15,475:INFO:Copying training dataset
2025-08-27 23:09:15,622:INFO:Defining folds
2025-08-27 23:09:15,623:INFO:Declaring metric variables
2025-08-27 23:09:15,641:INFO:Importing untrained model
2025-08-27 23:09:15,657:INFO:Naive Bayes Imported successfully
2025-08-27 23:09:15,692:INFO:Starting cross validation
2025-08-27 23:09:15,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:16,125:INFO:Calculating mean and std
2025-08-27 23:09:16,126:INFO:Creating metrics dataframe
2025-08-27 23:09:16,128:INFO:Uploading results into container
2025-08-27 23:09:16,129:INFO:Uploading model into container now
2025-08-27 23:09:16,130:INFO:_master_model_container: 3
2025-08-27 23:09:16,131:INFO:_display_container: 2
2025-08-27 23:09:16,131:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 23:09:16,131:INFO:create_model() successfully completed......................................
2025-08-27 23:09:16,322:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:16,323:INFO:Creating metrics dataframe
2025-08-27 23:09:16,355:INFO:Initializing Decision Tree Classifier
2025-08-27 23:09:16,355:INFO:Total runtime is 0.18735856612523397 minutes
2025-08-27 23:09:16,366:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:16,368:INFO:Initializing create_model()
2025-08-27 23:09:16,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:16,369:INFO:Checking exceptions
2025-08-27 23:09:16,369:INFO:Importing libraries
2025-08-27 23:09:16,369:INFO:Copying training dataset
2025-08-27 23:09:16,479:INFO:Defining folds
2025-08-27 23:09:16,480:INFO:Declaring metric variables
2025-08-27 23:09:16,490:INFO:Importing untrained model
2025-08-27 23:09:16,502:INFO:Decision Tree Classifier Imported successfully
2025-08-27 23:09:16,523:INFO:Starting cross validation
2025-08-27 23:09:16,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:17,084:INFO:Calculating mean and std
2025-08-27 23:09:17,086:INFO:Creating metrics dataframe
2025-08-27 23:09:17,088:INFO:Uploading results into container
2025-08-27 23:09:17,089:INFO:Uploading model into container now
2025-08-27 23:09:17,089:INFO:_master_model_container: 4
2025-08-27 23:09:17,089:INFO:_display_container: 2
2025-08-27 23:09:17,090:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1898, splitter='best')
2025-08-27 23:09:17,090:INFO:create_model() successfully completed......................................
2025-08-27 23:09:17,348:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:17,348:INFO:Creating metrics dataframe
2025-08-27 23:09:17,361:INFO:Initializing SVM - Linear Kernel
2025-08-27 23:09:17,362:INFO:Total runtime is 0.20414186716079713 minutes
2025-08-27 23:09:17,372:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:17,373:INFO:Initializing create_model()
2025-08-27 23:09:17,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:17,374:INFO:Checking exceptions
2025-08-27 23:09:17,375:INFO:Importing libraries
2025-08-27 23:09:17,375:INFO:Copying training dataset
2025-08-27 23:09:17,447:INFO:Defining folds
2025-08-27 23:09:17,447:INFO:Declaring metric variables
2025-08-27 23:09:17,451:INFO:Importing untrained model
2025-08-27 23:09:17,457:INFO:SVM - Linear Kernel Imported successfully
2025-08-27 23:09:17,466:INFO:Starting cross validation
2025-08-27 23:09:17,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:18,485:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:09:18,621:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:09:18,863:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:09:18,883:INFO:Calculating mean and std
2025-08-27 23:09:18,885:INFO:Creating metrics dataframe
2025-08-27 23:09:18,887:INFO:Uploading results into container
2025-08-27 23:09:18,887:INFO:Uploading model into container now
2025-08-27 23:09:18,888:INFO:_master_model_container: 5
2025-08-27 23:09:18,888:INFO:_display_container: 2
2025-08-27 23:09:18,889:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1898, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-27 23:09:18,889:INFO:create_model() successfully completed......................................
2025-08-27 23:09:19,228:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:19,228:INFO:Creating metrics dataframe
2025-08-27 23:09:19,249:INFO:Initializing Ridge Classifier
2025-08-27 23:09:19,250:INFO:Total runtime is 0.23559924364089968 minutes
2025-08-27 23:09:19,258:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:19,259:INFO:Initializing create_model()
2025-08-27 23:09:19,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:19,260:INFO:Checking exceptions
2025-08-27 23:09:19,261:INFO:Importing libraries
2025-08-27 23:09:19,261:INFO:Copying training dataset
2025-08-27 23:09:19,339:INFO:Defining folds
2025-08-27 23:09:19,339:INFO:Declaring metric variables
2025-08-27 23:09:19,345:INFO:Importing untrained model
2025-08-27 23:09:19,352:INFO:Ridge Classifier Imported successfully
2025-08-27 23:09:19,365:INFO:Starting cross validation
2025-08-27 23:09:19,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:19,795:INFO:Calculating mean and std
2025-08-27 23:09:19,797:INFO:Creating metrics dataframe
2025-08-27 23:09:19,798:INFO:Uploading results into container
2025-08-27 23:09:19,799:INFO:Uploading model into container now
2025-08-27 23:09:19,800:INFO:_master_model_container: 6
2025-08-27 23:09:19,800:INFO:_display_container: 2
2025-08-27 23:09:19,800:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1898, solver='auto',
                tol=0.0001)
2025-08-27 23:09:19,801:INFO:create_model() successfully completed......................................
2025-08-27 23:09:19,974:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:19,975:INFO:Creating metrics dataframe
2025-08-27 23:09:20,016:INFO:Initializing Random Forest Classifier
2025-08-27 23:09:20,018:INFO:Total runtime is 0.24840027093887332 minutes
2025-08-27 23:09:20,036:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:20,037:INFO:Initializing create_model()
2025-08-27 23:09:20,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:20,038:INFO:Checking exceptions
2025-08-27 23:09:20,039:INFO:Importing libraries
2025-08-27 23:09:20,039:INFO:Copying training dataset
2025-08-27 23:09:20,180:INFO:Defining folds
2025-08-27 23:09:20,180:INFO:Declaring metric variables
2025-08-27 23:09:20,192:INFO:Importing untrained model
2025-08-27 23:09:20,202:INFO:Random Forest Classifier Imported successfully
2025-08-27 23:09:20,223:INFO:Starting cross validation
2025-08-27 23:09:20,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:30,514:INFO:Calculating mean and std
2025-08-27 23:09:30,515:INFO:Creating metrics dataframe
2025-08-27 23:09:30,519:INFO:Uploading results into container
2025-08-27 23:09:30,519:INFO:Uploading model into container now
2025-08-27 23:09:30,519:INFO:_master_model_container: 7
2025-08-27 23:09:30,520:INFO:_display_container: 2
2025-08-27 23:09:30,520:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1898, verbose=0,
                       warm_start=False)
2025-08-27 23:09:30,520:INFO:create_model() successfully completed......................................
2025-08-27 23:09:30,719:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:30,719:INFO:Creating metrics dataframe
2025-08-27 23:09:30,735:INFO:Initializing Quadratic Discriminant Analysis
2025-08-27 23:09:30,735:INFO:Total runtime is 0.4270240068435669 minutes
2025-08-27 23:09:30,738:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:30,738:INFO:Initializing create_model()
2025-08-27 23:09:30,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:30,740:INFO:Checking exceptions
2025-08-27 23:09:30,740:INFO:Importing libraries
2025-08-27 23:09:30,740:INFO:Copying training dataset
2025-08-27 23:09:30,786:INFO:Defining folds
2025-08-27 23:09:30,786:INFO:Declaring metric variables
2025-08-27 23:09:30,791:INFO:Importing untrained model
2025-08-27 23:09:30,797:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 23:09:30,806:INFO:Starting cross validation
2025-08-27 23:09:30,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:30,960:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:30,975:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,975:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,975:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,976:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,976:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:30,977:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:30,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:30,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:30,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,979:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:30,995:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,996:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:30,997:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:30,997:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:30,997:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,005:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,013:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,013:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,015:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,019:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:31,023:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,023:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,024:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,030:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,030:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,031:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,036:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,036:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,036:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,053:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:31,063:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,064:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,064:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,065:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:31,069:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,069:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,069:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,069:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,069:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,069:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,078:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,078:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,079:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:09:31,092:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:09:31,096:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:31,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,114:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,128:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:09:31,190:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:31,197:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,198:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,198:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:09:31,201:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:09:31,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,213:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,214:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,218:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,219:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:09:31,219:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:09:31,221:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:09:31,253:INFO:Calculating mean and std
2025-08-27 23:09:31,254:INFO:Creating metrics dataframe
2025-08-27 23:09:31,256:INFO:Uploading results into container
2025-08-27 23:09:31,257:INFO:Uploading model into container now
2025-08-27 23:09:31,257:INFO:_master_model_container: 8
2025-08-27 23:09:31,257:INFO:_display_container: 2
2025-08-27 23:09:31,257:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-08-27 23:09:31,257:INFO:create_model() successfully completed......................................
2025-08-27 23:09:31,436:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:31,437:INFO:Creating metrics dataframe
2025-08-27 23:09:31,476:INFO:Initializing Ada Boost Classifier
2025-08-27 23:09:31,477:INFO:Total runtime is 0.4393916885058085 minutes
2025-08-27 23:09:31,495:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:31,497:INFO:Initializing create_model()
2025-08-27 23:09:31,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:31,498:INFO:Checking exceptions
2025-08-27 23:09:31,499:INFO:Importing libraries
2025-08-27 23:09:31,499:INFO:Copying training dataset
2025-08-27 23:09:31,643:INFO:Defining folds
2025-08-27 23:09:31,644:INFO:Declaring metric variables
2025-08-27 23:09:31,660:INFO:Importing untrained model
2025-08-27 23:09:31,679:INFO:Ada Boost Classifier Imported successfully
2025-08-27 23:09:31,713:INFO:Starting cross validation
2025-08-27 23:09:31,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:09:31,920:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:31,929:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:31,941:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:31,965:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:31,983:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:32,006:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:32,027:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:32,048:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:39,255:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:39,368:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:09:44,272:INFO:Calculating mean and std
2025-08-27 23:09:44,274:INFO:Creating metrics dataframe
2025-08-27 23:09:44,276:INFO:Uploading results into container
2025-08-27 23:09:44,277:INFO:Uploading model into container now
2025-08-27 23:09:44,279:INFO:_master_model_container: 9
2025-08-27 23:09:44,279:INFO:_display_container: 2
2025-08-27 23:09:44,279:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1898)
2025-08-27 23:09:44,279:INFO:create_model() successfully completed......................................
2025-08-27 23:09:44,623:INFO:SubProcess create_model() end ==================================
2025-08-27 23:09:44,624:INFO:Creating metrics dataframe
2025-08-27 23:09:44,668:INFO:Initializing Gradient Boosting Classifier
2025-08-27 23:09:44,668:INFO:Total runtime is 0.6592339277267456 minutes
2025-08-27 23:09:44,683:INFO:SubProcess create_model() called ==================================
2025-08-27 23:09:44,684:INFO:Initializing create_model()
2025-08-27 23:09:44,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:09:44,686:INFO:Checking exceptions
2025-08-27 23:09:44,687:INFO:Importing libraries
2025-08-27 23:09:44,687:INFO:Copying training dataset
2025-08-27 23:09:44,783:INFO:Defining folds
2025-08-27 23:09:44,783:INFO:Declaring metric variables
2025-08-27 23:09:44,788:INFO:Importing untrained model
2025-08-27 23:09:44,797:INFO:Gradient Boosting Classifier Imported successfully
2025-08-27 23:09:44,808:INFO:Starting cross validation
2025-08-27 23:09:44,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:10:39,769:INFO:Calculating mean and std
2025-08-27 23:10:39,770:INFO:Creating metrics dataframe
2025-08-27 23:10:39,774:INFO:Uploading results into container
2025-08-27 23:10:39,775:INFO:Uploading model into container now
2025-08-27 23:10:39,775:INFO:_master_model_container: 10
2025-08-27 23:10:39,776:INFO:_display_container: 2
2025-08-27 23:10:39,776:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1898, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-27 23:10:39,776:INFO:create_model() successfully completed......................................
2025-08-27 23:10:40,014:INFO:SubProcess create_model() end ==================================
2025-08-27 23:10:40,014:INFO:Creating metrics dataframe
2025-08-27 23:10:40,037:INFO:Initializing Linear Discriminant Analysis
2025-08-27 23:10:40,037:INFO:Total runtime is 1.58205539782842 minutes
2025-08-27 23:10:40,046:INFO:SubProcess create_model() called ==================================
2025-08-27 23:10:40,047:INFO:Initializing create_model()
2025-08-27 23:10:40,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:10:40,047:INFO:Checking exceptions
2025-08-27 23:10:40,047:INFO:Importing libraries
2025-08-27 23:10:40,048:INFO:Copying training dataset
2025-08-27 23:10:40,147:INFO:Defining folds
2025-08-27 23:10:40,148:INFO:Declaring metric variables
2025-08-27 23:10:40,167:INFO:Importing untrained model
2025-08-27 23:10:40,185:INFO:Linear Discriminant Analysis Imported successfully
2025-08-27 23:10:40,217:INFO:Starting cross validation
2025-08-27 23:10:40,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:10:40,731:INFO:Calculating mean and std
2025-08-27 23:10:40,733:INFO:Creating metrics dataframe
2025-08-27 23:10:40,735:INFO:Uploading results into container
2025-08-27 23:10:40,735:INFO:Uploading model into container now
2025-08-27 23:10:40,736:INFO:_master_model_container: 11
2025-08-27 23:10:40,736:INFO:_display_container: 2
2025-08-27 23:10:40,737:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-08-27 23:10:40,737:INFO:create_model() successfully completed......................................
2025-08-27 23:10:40,907:INFO:SubProcess create_model() end ==================================
2025-08-27 23:10:40,909:INFO:Creating metrics dataframe
2025-08-27 23:10:40,919:INFO:Initializing Extra Trees Classifier
2025-08-27 23:10:40,919:INFO:Total runtime is 1.5967532396316528 minutes
2025-08-27 23:10:40,923:INFO:SubProcess create_model() called ==================================
2025-08-27 23:10:40,923:INFO:Initializing create_model()
2025-08-27 23:10:40,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:10:40,924:INFO:Checking exceptions
2025-08-27 23:10:40,924:INFO:Importing libraries
2025-08-27 23:10:40,925:INFO:Copying training dataset
2025-08-27 23:10:40,969:INFO:Defining folds
2025-08-27 23:10:40,969:INFO:Declaring metric variables
2025-08-27 23:10:40,975:INFO:Importing untrained model
2025-08-27 23:10:40,980:INFO:Extra Trees Classifier Imported successfully
2025-08-27 23:10:40,987:INFO:Starting cross validation
2025-08-27 23:10:40,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:10:44,634:INFO:Calculating mean and std
2025-08-27 23:10:44,635:INFO:Creating metrics dataframe
2025-08-27 23:10:44,636:INFO:Uploading results into container
2025-08-27 23:10:44,637:INFO:Uploading model into container now
2025-08-27 23:10:44,637:INFO:_master_model_container: 12
2025-08-27 23:10:44,637:INFO:_display_container: 2
2025-08-27 23:10:44,639:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1898, verbose=0,
                     warm_start=False)
2025-08-27 23:10:44,639:INFO:create_model() successfully completed......................................
2025-08-27 23:10:44,835:INFO:SubProcess create_model() end ==================================
2025-08-27 23:10:44,836:INFO:Creating metrics dataframe
2025-08-27 23:10:44,869:INFO:Initializing Light Gradient Boosting Machine
2025-08-27 23:10:44,869:INFO:Total runtime is 1.6625939687093099 minutes
2025-08-27 23:10:44,876:INFO:SubProcess create_model() called ==================================
2025-08-27 23:10:44,877:INFO:Initializing create_model()
2025-08-27 23:10:44,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:10:44,878:INFO:Checking exceptions
2025-08-27 23:10:44,878:INFO:Importing libraries
2025-08-27 23:10:44,878:INFO:Copying training dataset
2025-08-27 23:10:44,940:INFO:Defining folds
2025-08-27 23:10:44,940:INFO:Declaring metric variables
2025-08-27 23:10:44,946:INFO:Importing untrained model
2025-08-27 23:10:44,953:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-27 23:10:44,965:INFO:Starting cross validation
2025-08-27 23:10:44,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:10:47,622:INFO:Calculating mean and std
2025-08-27 23:10:47,624:INFO:Creating metrics dataframe
2025-08-27 23:10:47,628:INFO:Uploading results into container
2025-08-27 23:10:47,630:INFO:Uploading model into container now
2025-08-27 23:10:47,630:INFO:_master_model_container: 13
2025-08-27 23:10:47,630:INFO:_display_container: 2
2025-08-27 23:10:47,630:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1898, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-27 23:10:47,630:INFO:create_model() successfully completed......................................
2025-08-27 23:10:47,815:INFO:SubProcess create_model() end ==================================
2025-08-27 23:10:47,815:INFO:Creating metrics dataframe
2025-08-27 23:10:47,826:INFO:Initializing Dummy Classifier
2025-08-27 23:10:47,826:INFO:Total runtime is 1.711865234375 minutes
2025-08-27 23:10:47,832:INFO:SubProcess create_model() called ==================================
2025-08-27 23:10:47,833:INFO:Initializing create_model()
2025-08-27 23:10:47,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A0BE952110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:10:47,833:INFO:Checking exceptions
2025-08-27 23:10:47,833:INFO:Importing libraries
2025-08-27 23:10:47,833:INFO:Copying training dataset
2025-08-27 23:10:47,916:INFO:Defining folds
2025-08-27 23:10:47,917:INFO:Declaring metric variables
2025-08-27 23:10:47,923:INFO:Importing untrained model
2025-08-27 23:10:47,932:INFO:Dummy Classifier Imported successfully
2025-08-27 23:10:47,943:INFO:Starting cross validation
2025-08-27 23:10:47,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:10:48,121:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,139:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,156:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,185:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,208:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,231:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,241:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,265:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,273:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,284:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:10:48,303:INFO:Calculating mean and std
2025-08-27 23:10:48,305:INFO:Creating metrics dataframe
2025-08-27 23:10:48,307:INFO:Uploading results into container
2025-08-27 23:10:48,308:INFO:Uploading model into container now
2025-08-27 23:10:48,308:INFO:_master_model_container: 14
2025-08-27 23:10:48,308:INFO:_display_container: 2
2025-08-27 23:10:48,309:INFO:DummyClassifier(constant=None, random_state=1898, strategy='prior')
2025-08-27 23:10:48,309:INFO:create_model() successfully completed......................................
2025-08-27 23:10:48,470:INFO:SubProcess create_model() end ==================================
2025-08-27 23:10:48,470:INFO:Creating metrics dataframe
2025-08-27 23:10:48,486:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-08-27 23:10:48,517:INFO:Initializing create_model()
2025-08-27 23:10:48,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:10:48,518:INFO:Checking exceptions
2025-08-27 23:10:48,526:INFO:Importing libraries
2025-08-27 23:10:48,526:INFO:Copying training dataset
2025-08-27 23:10:48,658:INFO:Defining folds
2025-08-27 23:10:48,659:INFO:Declaring metric variables
2025-08-27 23:10:48,659:INFO:Importing untrained model
2025-08-27 23:10:48,659:INFO:Declaring custom model
2025-08-27 23:10:48,659:INFO:Naive Bayes Imported successfully
2025-08-27 23:10:48,659:INFO:Cross validation set to False
2025-08-27 23:10:48,659:INFO:Fitting Model
2025-08-27 23:10:48,720:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 23:10:48,730:INFO:create_model() successfully completed......................................
2025-08-27 23:10:49,032:INFO:_master_model_container: 14
2025-08-27 23:10:49,032:INFO:_display_container: 2
2025-08-27 23:10:49,033:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 23:10:49,033:INFO:compare_models() successfully completed......................................
2025-08-27 23:10:49,033:INFO:Initializing plot_model()
2025-08-27 23:10:49,034:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-27 23:10:49,034:INFO:Checking exceptions
2025-08-27 23:10:49,053:INFO:Preloading libraries
2025-08-27 23:10:49,054:INFO:Copying training dataset
2025-08-27 23:10:49,055:INFO:Plot type: confusion_matrix
2025-08-27 23:10:49,219:INFO:Fitting Model
2025-08-27 23:10:49,237:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-08-27 23:10:49,237:INFO:Scoring test/hold-out set
2025-08-27 23:10:49,646:INFO:Visual Rendered Successfully
2025-08-27 23:10:49,898:INFO:plot_model() successfully completed......................................
2025-08-27 23:16:01,696:INFO:Initializing predict_model()
2025-08-27 23:16:01,696:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A0C5CE2C90>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A0C52B2F20>)
2025-08-27 23:16:01,696:INFO:Checking exceptions
2025-08-27 23:16:01,696:INFO:Preloading libraries
2025-08-27 23:16:01,698:INFO:Set up data.
2025-08-27 23:16:01,702:INFO:Set up index.
2025-08-27 23:20:42,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 23:20:42,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 23:20:42,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 23:20:42,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-08-27 23:20:43,656:INFO:PyCaret ClassificationExperiment
2025-08-27 23:20:43,657:INFO:Logging name: clf-default-name
2025-08-27 23:20:43,657:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-08-27 23:20:43,657:INFO:version 3.3.2
2025-08-27 23:20:43,658:INFO:Initializing setup()
2025-08-27 23:20:43,658:INFO:self.USI: 12a1
2025-08-27 23:20:43,658:INFO:self._variable_keys: {'fold_groups_param', 'logging_param', 'gpu_param', 'y', 'fix_imbalance', 'fold_generator', 'X', 'X_train', 'y_train', 'log_plots_param', 'USI', 'html_param', 'memory', 'is_multiclass', 'n_jobs_param', 'gpu_n_jobs_param', 'pipeline', '_available_plots', 'X_test', 'seed', 'target_param', 'exp_name_log', 'data', 'fold_shuffle_param', 'idx', 'exp_id', '_ml_usecase', 'y_test'}
2025-08-27 23:20:43,658:INFO:Checking environment
2025-08-27 23:20:43,658:INFO:python_version: 3.11.9
2025-08-27 23:20:43,658:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-08-27 23:20:43,658:INFO:machine: AMD64
2025-08-27 23:20:43,658:INFO:platform: Windows-10-10.0.19045-SP0
2025-08-27 23:20:43,660:INFO:Memory: svmem(total=17024348160, available=3526897664, percent=79.3, used=13497450496, free=3526897664)
2025-08-27 23:20:43,660:INFO:Physical Core: 4
2025-08-27 23:20:43,660:INFO:Logical Core: 8
2025-08-27 23:20:43,660:INFO:Checking libraries
2025-08-27 23:20:43,660:INFO:System:
2025-08-27 23:20:43,660:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-08-27 23:20:43,660:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-08-27 23:20:43,660:INFO:   machine: Windows-10-10.0.19045-SP0
2025-08-27 23:20:43,660:INFO:PyCaret required dependencies:
2025-08-27 23:20:43,660:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:43,697:INFO:                 pip: Not installed
2025-08-27 23:20:43,697:INFO:          setuptools: 80.9.0
2025-08-27 23:20:43,697:INFO:             pycaret: 3.3.2
2025-08-27 23:20:43,697:INFO:             IPython: 9.4.0
2025-08-27 23:20:43,697:INFO:          ipywidgets: 8.1.7
2025-08-27 23:20:43,697:INFO:                tqdm: 4.67.1
2025-08-27 23:20:43,697:INFO:               numpy: 1.26.4
2025-08-27 23:20:43,697:INFO:              pandas: 2.1.4
2025-08-27 23:20:43,697:INFO:              jinja2: 3.1.6
2025-08-27 23:20:43,697:INFO:               scipy: 1.11.4
2025-08-27 23:20:43,697:INFO:              joblib: 1.3.2
2025-08-27 23:20:43,698:INFO:             sklearn: 1.4.2
2025-08-27 23:20:43,698:INFO:                pyod: 2.0.5
2025-08-27 23:20:43,698:INFO:            imblearn: 0.14.0
2025-08-27 23:20:43,698:INFO:   category_encoders: 2.7.0
2025-08-27 23:20:43,698:INFO:            lightgbm: 4.6.0
2025-08-27 23:20:43,698:INFO:               numba: 0.61.2
2025-08-27 23:20:43,698:INFO:            requests: 2.32.5
2025-08-27 23:20:43,698:INFO:          matplotlib: 3.7.5
2025-08-27 23:20:43,698:INFO:          scikitplot: 0.3.7
2025-08-27 23:20:43,698:INFO:         yellowbrick: 1.5
2025-08-27 23:20:43,698:INFO:              plotly: 5.24.1
2025-08-27 23:20:43,698:INFO:    plotly-resampler: Not installed
2025-08-27 23:20:43,698:INFO:             kaleido: 1.0.0
2025-08-27 23:20:43,698:INFO:           schemdraw: 0.15
2025-08-27 23:20:43,698:INFO:         statsmodels: 0.14.5
2025-08-27 23:20:43,698:INFO:              sktime: 0.26.0
2025-08-27 23:20:43,698:INFO:               tbats: 1.1.3
2025-08-27 23:20:43,698:INFO:            pmdarima: 2.0.4
2025-08-27 23:20:43,698:INFO:              psutil: 7.0.0
2025-08-27 23:20:43,698:INFO:          markupsafe: 3.0.2
2025-08-27 23:20:43,698:INFO:             pickle5: Not installed
2025-08-27 23:20:43,698:INFO:         cloudpickle: 3.1.1
2025-08-27 23:20:43,699:INFO:         deprecation: 2.1.0
2025-08-27 23:20:43,699:INFO:              xxhash: 3.5.0
2025-08-27 23:20:43,699:INFO:           wurlitzer: Not installed
2025-08-27 23:20:43,699:INFO:PyCaret optional dependencies:
2025-08-27 23:20:43,718:INFO:                shap: Not installed
2025-08-27 23:20:43,718:INFO:           interpret: Not installed
2025-08-27 23:20:43,718:INFO:                umap: Not installed
2025-08-27 23:20:43,718:INFO:     ydata_profiling: Not installed
2025-08-27 23:20:43,718:INFO:  explainerdashboard: Not installed
2025-08-27 23:20:43,718:INFO:             autoviz: Not installed
2025-08-27 23:20:43,718:INFO:           fairlearn: Not installed
2025-08-27 23:20:43,718:INFO:          deepchecks: Not installed
2025-08-27 23:20:43,718:INFO:             xgboost: Not installed
2025-08-27 23:20:43,718:INFO:            catboost: Not installed
2025-08-27 23:20:43,718:INFO:              kmodes: Not installed
2025-08-27 23:20:43,718:INFO:             mlxtend: Not installed
2025-08-27 23:20:43,718:INFO:       statsforecast: Not installed
2025-08-27 23:20:43,718:INFO:        tune_sklearn: Not installed
2025-08-27 23:20:43,718:INFO:                 ray: Not installed
2025-08-27 23:20:43,718:INFO:            hyperopt: Not installed
2025-08-27 23:20:43,718:INFO:              optuna: Not installed
2025-08-27 23:20:43,718:INFO:               skopt: Not installed
2025-08-27 23:20:43,718:INFO:              mlflow: Not installed
2025-08-27 23:20:43,718:INFO:              gradio: Not installed
2025-08-27 23:20:43,718:INFO:             fastapi: Not installed
2025-08-27 23:20:43,718:INFO:             uvicorn: Not installed
2025-08-27 23:20:43,718:INFO:              m2cgen: Not installed
2025-08-27 23:20:43,718:INFO:           evidently: Not installed
2025-08-27 23:20:43,718:INFO:               fugue: Not installed
2025-08-27 23:20:43,721:INFO:           streamlit: Not installed
2025-08-27 23:20:43,721:INFO:             prophet: Not installed
2025-08-27 23:20:43,721:INFO:None
2025-08-27 23:20:43,721:INFO:Set up data.
2025-08-27 23:20:43,748:INFO:Set up folding strategy.
2025-08-27 23:20:43,749:INFO:Set up train/test split.
2025-08-27 23:20:43,871:INFO:Set up index.
2025-08-27 23:20:43,879:INFO:Assigning column types.
2025-08-27 23:20:43,937:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-08-27 23:20:44,073:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 23:20:44,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:20:44,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-08-27 23:20:44,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:20:44,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,515:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-08-27 23:20:44,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:20:44,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-08-27 23:20:44,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,714:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-08-27 23:20:44,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:44,932:INFO:Preparing preprocessing pipeline...
2025-08-27 23:20:44,945:INFO:Set up simple imputation.
2025-08-27 23:20:45,024:INFO:Finished creating preprocessing pipeline.
2025-08-27 23:20:45,040:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-08-27 23:20:45,041:INFO:Creating final display dataframe.
2025-08-27 23:20:45,563:INFO:Setup _display_container:                     Description             Value
0                    Session id              3252
1                        Target           failure
2                   Target type            Binary
3           Original data shape       (104797, 6)
4        Transformed data shape       (104797, 6)
5   Transformed train set shape        (73357, 6)
6    Transformed test set shape        (31440, 6)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              12a1
2025-08-27 23:20:45,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:45,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:46,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:46,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-08-27 23:20:46,150:INFO:setup() successfully completed in 2.5s...............
2025-08-27 23:20:46,151:INFO:Initializing compare_models()
2025-08-27 23:20:46,151:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-08-27 23:20:46,151:INFO:Checking exceptions
2025-08-27 23:20:46,189:INFO:Preparing display monitor
2025-08-27 23:20:46,252:INFO:Initializing Logistic Regression
2025-08-27 23:20:46,252:INFO:Total runtime is 0.0 minutes
2025-08-27 23:20:46,265:INFO:SubProcess create_model() called ==================================
2025-08-27 23:20:46,266:INFO:Initializing create_model()
2025-08-27 23:20:46,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:20:46,267:INFO:Checking exceptions
2025-08-27 23:20:46,267:INFO:Importing libraries
2025-08-27 23:20:46,267:INFO:Copying training dataset
2025-08-27 23:20:46,382:INFO:Defining folds
2025-08-27 23:20:46,382:INFO:Declaring metric variables
2025-08-27 23:20:46,388:INFO:Importing untrained model
2025-08-27 23:20:46,403:INFO:Logistic Regression Imported successfully
2025-08-27 23:20:46,426:INFO:Starting cross validation
2025-08-27 23:20:46,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:20:54,326:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:54,352:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:54,387:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:54,405:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:54,450:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:54,510:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:54,759:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:54,806:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-08-27 23:20:55,747:INFO:Calculating mean and std
2025-08-27 23:20:55,754:INFO:Creating metrics dataframe
2025-08-27 23:20:55,759:INFO:Uploading results into container
2025-08-27 23:20:55,759:INFO:Uploading model into container now
2025-08-27 23:20:55,759:INFO:_master_model_container: 1
2025-08-27 23:20:55,759:INFO:_display_container: 2
2025-08-27 23:20:55,759:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3252, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-08-27 23:20:55,759:INFO:create_model() successfully completed......................................
2025-08-27 23:20:55,938:INFO:SubProcess create_model() end ==================================
2025-08-27 23:20:55,938:INFO:Creating metrics dataframe
2025-08-27 23:20:55,942:INFO:Initializing K Neighbors Classifier
2025-08-27 23:20:55,942:INFO:Total runtime is 0.16149723927179974 minutes
2025-08-27 23:20:55,957:INFO:SubProcess create_model() called ==================================
2025-08-27 23:20:55,958:INFO:Initializing create_model()
2025-08-27 23:20:55,958:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:20:55,958:INFO:Checking exceptions
2025-08-27 23:20:55,958:INFO:Importing libraries
2025-08-27 23:20:55,958:INFO:Copying training dataset
2025-08-27 23:20:56,055:INFO:Defining folds
2025-08-27 23:20:56,056:INFO:Declaring metric variables
2025-08-27 23:20:56,061:INFO:Importing untrained model
2025-08-27 23:20:56,077:INFO:K Neighbors Classifier Imported successfully
2025-08-27 23:20:56,099:INFO:Starting cross validation
2025-08-27 23:20:56,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:21:00,140:INFO:Calculating mean and std
2025-08-27 23:21:00,143:INFO:Creating metrics dataframe
2025-08-27 23:21:00,149:INFO:Uploading results into container
2025-08-27 23:21:00,150:INFO:Uploading model into container now
2025-08-27 23:21:00,151:INFO:_master_model_container: 2
2025-08-27 23:21:00,151:INFO:_display_container: 2
2025-08-27 23:21:00,151:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-08-27 23:21:00,152:INFO:create_model() successfully completed......................................
2025-08-27 23:21:00,281:INFO:SubProcess create_model() end ==================================
2025-08-27 23:21:00,281:INFO:Creating metrics dataframe
2025-08-27 23:21:00,294:INFO:Initializing Naive Bayes
2025-08-27 23:21:00,294:INFO:Total runtime is 0.23402635256449383 minutes
2025-08-27 23:21:00,299:INFO:SubProcess create_model() called ==================================
2025-08-27 23:21:00,301:INFO:Initializing create_model()
2025-08-27 23:21:00,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:21:00,301:INFO:Checking exceptions
2025-08-27 23:21:00,301:INFO:Importing libraries
2025-08-27 23:21:00,301:INFO:Copying training dataset
2025-08-27 23:21:00,358:INFO:Defining folds
2025-08-27 23:21:00,358:INFO:Declaring metric variables
2025-08-27 23:21:00,375:INFO:Importing untrained model
2025-08-27 23:21:00,393:INFO:Naive Bayes Imported successfully
2025-08-27 23:21:00,427:INFO:Starting cross validation
2025-08-27 23:21:00,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:21:00,984:INFO:Calculating mean and std
2025-08-27 23:21:00,986:INFO:Creating metrics dataframe
2025-08-27 23:21:00,991:INFO:Uploading results into container
2025-08-27 23:21:00,992:INFO:Uploading model into container now
2025-08-27 23:21:00,992:INFO:_master_model_container: 3
2025-08-27 23:21:00,993:INFO:_display_container: 2
2025-08-27 23:21:00,993:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 23:21:00,994:INFO:create_model() successfully completed......................................
2025-08-27 23:21:01,127:INFO:SubProcess create_model() end ==================================
2025-08-27 23:21:01,127:INFO:Creating metrics dataframe
2025-08-27 23:21:01,154:INFO:Initializing Decision Tree Classifier
2025-08-27 23:21:01,154:INFO:Total runtime is 0.24836063782374065 minutes
2025-08-27 23:21:01,174:INFO:SubProcess create_model() called ==================================
2025-08-27 23:21:01,175:INFO:Initializing create_model()
2025-08-27 23:21:01,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:21:01,177:INFO:Checking exceptions
2025-08-27 23:21:01,178:INFO:Importing libraries
2025-08-27 23:21:01,178:INFO:Copying training dataset
2025-08-27 23:21:01,298:INFO:Defining folds
2025-08-27 23:21:01,298:INFO:Declaring metric variables
2025-08-27 23:21:01,310:INFO:Importing untrained model
2025-08-27 23:21:01,321:INFO:Decision Tree Classifier Imported successfully
2025-08-27 23:21:01,336:INFO:Starting cross validation
2025-08-27 23:21:01,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:21:02,109:INFO:Calculating mean and std
2025-08-27 23:21:02,111:INFO:Creating metrics dataframe
2025-08-27 23:21:02,117:INFO:Uploading results into container
2025-08-27 23:21:02,118:INFO:Uploading model into container now
2025-08-27 23:21:02,119:INFO:_master_model_container: 4
2025-08-27 23:21:02,119:INFO:_display_container: 2
2025-08-27 23:21:02,120:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3252, splitter='best')
2025-08-27 23:21:02,120:INFO:create_model() successfully completed......................................
2025-08-27 23:21:02,263:INFO:SubProcess create_model() end ==================================
2025-08-27 23:21:02,264:INFO:Creating metrics dataframe
2025-08-27 23:21:02,280:INFO:Initializing SVM - Linear Kernel
2025-08-27 23:21:02,280:INFO:Total runtime is 0.2671291033426921 minutes
2025-08-27 23:21:02,281:INFO:SubProcess create_model() called ==================================
2025-08-27 23:21:02,289:INFO:Initializing create_model()
2025-08-27 23:21:02,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:21:02,289:INFO:Checking exceptions
2025-08-27 23:21:02,289:INFO:Importing libraries
2025-08-27 23:21:02,289:INFO:Copying training dataset
2025-08-27 23:21:02,351:INFO:Defining folds
2025-08-27 23:21:02,351:INFO:Declaring metric variables
2025-08-27 23:21:02,362:INFO:Importing untrained model
2025-08-27 23:21:02,375:INFO:SVM - Linear Kernel Imported successfully
2025-08-27 23:21:02,411:INFO:Starting cross validation
2025-08-27 23:21:02,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:21:03,550:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:21:03,833:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:21:03,882:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:21:04,165:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:21:04,332:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:21:04,381:INFO:Calculating mean and std
2025-08-27 23:21:04,381:INFO:Creating metrics dataframe
2025-08-27 23:21:04,395:INFO:Uploading results into container
2025-08-27 23:21:04,401:INFO:Uploading model into container now
2025-08-27 23:21:04,404:INFO:_master_model_container: 5
2025-08-27 23:21:04,404:INFO:_display_container: 2
2025-08-27 23:21:04,406:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3252, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-08-27 23:21:04,406:INFO:create_model() successfully completed......................................
2025-08-27 23:21:04,680:INFO:SubProcess create_model() end ==================================
2025-08-27 23:21:04,680:INFO:Creating metrics dataframe
2025-08-27 23:21:04,680:INFO:Initializing Ridge Classifier
2025-08-27 23:21:04,690:INFO:Total runtime is 0.3072912255922953 minutes
2025-08-27 23:21:04,695:INFO:SubProcess create_model() called ==================================
2025-08-27 23:21:04,695:INFO:Initializing create_model()
2025-08-27 23:21:04,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:21:04,695:INFO:Checking exceptions
2025-08-27 23:21:04,695:INFO:Importing libraries
2025-08-27 23:21:04,695:INFO:Copying training dataset
2025-08-27 23:21:04,748:INFO:Defining folds
2025-08-27 23:21:04,748:INFO:Declaring metric variables
2025-08-27 23:21:04,754:INFO:Importing untrained model
2025-08-27 23:21:04,770:INFO:Ridge Classifier Imported successfully
2025-08-27 23:21:04,785:INFO:Starting cross validation
2025-08-27 23:21:04,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:21:05,284:INFO:Calculating mean and std
2025-08-27 23:21:05,285:INFO:Creating metrics dataframe
2025-08-27 23:21:05,285:INFO:Uploading results into container
2025-08-27 23:21:05,285:INFO:Uploading model into container now
2025-08-27 23:21:05,285:INFO:_master_model_container: 6
2025-08-27 23:21:05,285:INFO:_display_container: 2
2025-08-27 23:21:05,285:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3252, solver='auto',
                tol=0.0001)
2025-08-27 23:21:05,285:INFO:create_model() successfully completed......................................
2025-08-27 23:21:05,403:INFO:SubProcess create_model() end ==================================
2025-08-27 23:21:05,403:INFO:Creating metrics dataframe
2025-08-27 23:21:05,414:INFO:Initializing Random Forest Classifier
2025-08-27 23:21:05,414:INFO:Total runtime is 0.3193537910779317 minutes
2025-08-27 23:21:05,419:INFO:SubProcess create_model() called ==================================
2025-08-27 23:21:05,419:INFO:Initializing create_model()
2025-08-27 23:21:05,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:21:05,419:INFO:Checking exceptions
2025-08-27 23:21:05,419:INFO:Importing libraries
2025-08-27 23:21:05,419:INFO:Copying training dataset
2025-08-27 23:21:05,471:INFO:Defining folds
2025-08-27 23:21:05,471:INFO:Declaring metric variables
2025-08-27 23:21:05,477:INFO:Importing untrained model
2025-08-27 23:21:05,483:INFO:Random Forest Classifier Imported successfully
2025-08-27 23:21:05,494:INFO:Starting cross validation
2025-08-27 23:21:05,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:21:19,574:INFO:Calculating mean and std
2025-08-27 23:21:19,576:INFO:Creating metrics dataframe
2025-08-27 23:21:19,579:INFO:Uploading results into container
2025-08-27 23:21:19,579:INFO:Uploading model into container now
2025-08-27 23:21:19,584:INFO:_master_model_container: 7
2025-08-27 23:21:19,584:INFO:_display_container: 2
2025-08-27 23:21:19,585:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3252, verbose=0,
                       warm_start=False)
2025-08-27 23:21:19,585:INFO:create_model() successfully completed......................................
2025-08-27 23:21:19,723:INFO:SubProcess create_model() end ==================================
2025-08-27 23:21:19,723:INFO:Creating metrics dataframe
2025-08-27 23:21:19,761:INFO:Initializing Quadratic Discriminant Analysis
2025-08-27 23:21:19,762:INFO:Total runtime is 0.5584854563077291 minutes
2025-08-27 23:21:19,775:INFO:SubProcess create_model() called ==================================
2025-08-27 23:21:19,776:INFO:Initializing create_model()
2025-08-27 23:21:19,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:21:19,776:INFO:Checking exceptions
2025-08-27 23:21:19,776:INFO:Importing libraries
2025-08-27 23:21:19,778:INFO:Copying training dataset
2025-08-27 23:21:19,878:INFO:Defining folds
2025-08-27 23:21:19,878:INFO:Declaring metric variables
2025-08-27 23:21:19,902:INFO:Importing untrained model
2025-08-27 23:21:19,919:INFO:Quadratic Discriminant Analysis Imported successfully
2025-08-27 23:21:19,956:INFO:Starting cross validation
2025-08-27 23:21:19,962:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:21:20,248:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,265:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,266:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,267:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,274:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,274:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,278:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,274:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,293:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,298:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,300:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,300:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,312:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,313:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,313:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,313:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,322:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,323:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,324:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,329:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,329:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,330:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,301:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,337:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,338:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,338:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,338:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,341:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,342:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,343:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,344:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,351:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,356:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,361:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,361:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,370:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,370:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,370:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,385:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,398:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,415:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,416:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,417:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,427:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,428:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,429:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,430:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,431:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,438:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,443:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,443:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,443:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,443:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,444:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,451:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,452:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,453:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,453:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,462:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,463:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,464:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,471:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,472:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,479:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,479:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,480:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,484:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,501:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-08-27 23:21:20,515:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,515:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,515:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-08-27 23:21:20,521:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-08-27 23:21:20,524:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-08-27 23:21:20,573:INFO:Calculating mean and std
2025-08-27 23:21:20,574:INFO:Creating metrics dataframe
2025-08-27 23:21:20,579:INFO:Uploading results into container
2025-08-27 23:21:20,581:INFO:Uploading model into container now
2025-08-27 23:21:20,581:INFO:_master_model_container: 8
2025-08-27 23:21:20,582:INFO:_display_container: 2
2025-08-27 23:21:20,582:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-08-27 23:21:20,582:INFO:create_model() successfully completed......................................
2025-08-27 23:21:20,749:INFO:SubProcess create_model() end ==================================
2025-08-27 23:21:20,749:INFO:Creating metrics dataframe
2025-08-27 23:21:20,764:INFO:Initializing Ada Boost Classifier
2025-08-27 23:21:20,764:INFO:Total runtime is 0.5752009749412537 minutes
2025-08-27 23:21:20,772:INFO:SubProcess create_model() called ==================================
2025-08-27 23:21:20,772:INFO:Initializing create_model()
2025-08-27 23:21:20,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:21:20,772:INFO:Checking exceptions
2025-08-27 23:21:20,772:INFO:Importing libraries
2025-08-27 23:21:20,772:INFO:Copying training dataset
2025-08-27 23:21:20,855:INFO:Defining folds
2025-08-27 23:21:20,857:INFO:Declaring metric variables
2025-08-27 23:21:20,874:INFO:Importing untrained model
2025-08-27 23:21:20,890:INFO:Ada Boost Classifier Imported successfully
2025-08-27 23:21:20,912:INFO:Starting cross validation
2025-08-27 23:21:20,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:21:21,115:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:21,136:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:21,159:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:21,185:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:21,211:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:21,238:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:21,271:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:21,283:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:31,195:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:31,282:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-08-27 23:21:40,421:INFO:Calculating mean and std
2025-08-27 23:21:40,423:INFO:Creating metrics dataframe
2025-08-27 23:21:40,428:INFO:Uploading results into container
2025-08-27 23:21:40,430:INFO:Uploading model into container now
2025-08-27 23:21:40,430:INFO:_master_model_container: 9
2025-08-27 23:21:40,430:INFO:_display_container: 2
2025-08-27 23:21:40,430:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3252)
2025-08-27 23:21:40,433:INFO:create_model() successfully completed......................................
2025-08-27 23:21:40,627:INFO:SubProcess create_model() end ==================================
2025-08-27 23:21:40,634:INFO:Creating metrics dataframe
2025-08-27 23:21:40,673:INFO:Initializing Gradient Boosting Classifier
2025-08-27 23:21:40,673:INFO:Total runtime is 0.9070183952649434 minutes
2025-08-27 23:21:40,693:INFO:SubProcess create_model() called ==================================
2025-08-27 23:21:40,694:INFO:Initializing create_model()
2025-08-27 23:21:40,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:21:40,694:INFO:Checking exceptions
2025-08-27 23:21:40,694:INFO:Importing libraries
2025-08-27 23:21:40,694:INFO:Copying training dataset
2025-08-27 23:21:40,803:INFO:Defining folds
2025-08-27 23:21:40,806:INFO:Declaring metric variables
2025-08-27 23:21:40,828:INFO:Importing untrained model
2025-08-27 23:21:40,848:INFO:Gradient Boosting Classifier Imported successfully
2025-08-27 23:21:40,884:INFO:Starting cross validation
2025-08-27 23:21:40,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:23:08,142:INFO:Calculating mean and std
2025-08-27 23:23:08,142:INFO:Creating metrics dataframe
2025-08-27 23:23:08,149:INFO:Uploading results into container
2025-08-27 23:23:08,149:INFO:Uploading model into container now
2025-08-27 23:23:08,149:INFO:_master_model_container: 10
2025-08-27 23:23:08,149:INFO:_display_container: 2
2025-08-27 23:23:08,154:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3252, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-08-27 23:23:08,156:INFO:create_model() successfully completed......................................
2025-08-27 23:23:08,408:INFO:SubProcess create_model() end ==================================
2025-08-27 23:23:08,408:INFO:Creating metrics dataframe
2025-08-27 23:23:08,468:INFO:Initializing Linear Discriminant Analysis
2025-08-27 23:23:08,468:INFO:Total runtime is 2.370251977443695 minutes
2025-08-27 23:23:08,490:INFO:SubProcess create_model() called ==================================
2025-08-27 23:23:08,490:INFO:Initializing create_model()
2025-08-27 23:23:08,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:23:08,490:INFO:Checking exceptions
2025-08-27 23:23:08,490:INFO:Importing libraries
2025-08-27 23:23:08,490:INFO:Copying training dataset
2025-08-27 23:23:08,635:INFO:Defining folds
2025-08-27 23:23:08,635:INFO:Declaring metric variables
2025-08-27 23:23:08,652:INFO:Importing untrained model
2025-08-27 23:23:08,658:INFO:Linear Discriminant Analysis Imported successfully
2025-08-27 23:23:08,687:INFO:Starting cross validation
2025-08-27 23:23:08,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:23:09,272:INFO:Calculating mean and std
2025-08-27 23:23:09,272:INFO:Creating metrics dataframe
2025-08-27 23:23:09,272:INFO:Uploading results into container
2025-08-27 23:23:09,272:INFO:Uploading model into container now
2025-08-27 23:23:09,272:INFO:_master_model_container: 11
2025-08-27 23:23:09,281:INFO:_display_container: 2
2025-08-27 23:23:09,282:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-08-27 23:23:09,282:INFO:create_model() successfully completed......................................
2025-08-27 23:23:09,421:INFO:SubProcess create_model() end ==================================
2025-08-27 23:23:09,421:INFO:Creating metrics dataframe
2025-08-27 23:23:09,439:INFO:Initializing Extra Trees Classifier
2025-08-27 23:23:09,439:INFO:Total runtime is 2.3864368041356405 minutes
2025-08-27 23:23:09,439:INFO:SubProcess create_model() called ==================================
2025-08-27 23:23:09,450:INFO:Initializing create_model()
2025-08-27 23:23:09,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:23:09,450:INFO:Checking exceptions
2025-08-27 23:23:09,451:INFO:Importing libraries
2025-08-27 23:23:09,451:INFO:Copying training dataset
2025-08-27 23:23:09,571:INFO:Defining folds
2025-08-27 23:23:09,571:INFO:Declaring metric variables
2025-08-27 23:23:09,601:INFO:Importing untrained model
2025-08-27 23:23:09,626:INFO:Extra Trees Classifier Imported successfully
2025-08-27 23:23:09,664:INFO:Starting cross validation
2025-08-27 23:23:09,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:23:14,195:INFO:Calculating mean and std
2025-08-27 23:23:14,195:INFO:Creating metrics dataframe
2025-08-27 23:23:14,195:INFO:Uploading results into container
2025-08-27 23:23:14,195:INFO:Uploading model into container now
2025-08-27 23:23:14,204:INFO:_master_model_container: 12
2025-08-27 23:23:14,206:INFO:_display_container: 2
2025-08-27 23:23:14,206:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3252, verbose=0,
                     warm_start=False)
2025-08-27 23:23:14,207:INFO:create_model() successfully completed......................................
2025-08-27 23:23:14,365:INFO:SubProcess create_model() end ==================================
2025-08-27 23:23:14,365:INFO:Creating metrics dataframe
2025-08-27 23:23:14,397:INFO:Initializing Light Gradient Boosting Machine
2025-08-27 23:23:14,397:INFO:Total runtime is 2.4690686583518984 minutes
2025-08-27 23:23:14,408:INFO:SubProcess create_model() called ==================================
2025-08-27 23:23:14,411:INFO:Initializing create_model()
2025-08-27 23:23:14,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:23:14,411:INFO:Checking exceptions
2025-08-27 23:23:14,412:INFO:Importing libraries
2025-08-27 23:23:14,412:INFO:Copying training dataset
2025-08-27 23:23:14,505:INFO:Defining folds
2025-08-27 23:23:14,506:INFO:Declaring metric variables
2025-08-27 23:23:14,524:INFO:Importing untrained model
2025-08-27 23:23:14,552:INFO:Light Gradient Boosting Machine Imported successfully
2025-08-27 23:23:14,593:INFO:Starting cross validation
2025-08-27 23:23:14,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:23:19,407:INFO:Calculating mean and std
2025-08-27 23:23:19,410:INFO:Creating metrics dataframe
2025-08-27 23:23:19,420:INFO:Uploading results into container
2025-08-27 23:23:19,421:INFO:Uploading model into container now
2025-08-27 23:23:19,422:INFO:_master_model_container: 13
2025-08-27 23:23:19,423:INFO:_display_container: 2
2025-08-27 23:23:19,426:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3252, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-08-27 23:23:19,427:INFO:create_model() successfully completed......................................
2025-08-27 23:23:19,578:INFO:SubProcess create_model() end ==================================
2025-08-27 23:23:19,578:INFO:Creating metrics dataframe
2025-08-27 23:23:19,620:INFO:Initializing Dummy Classifier
2025-08-27 23:23:19,620:INFO:Total runtime is 2.556121150652568 minutes
2025-08-27 23:23:19,645:INFO:SubProcess create_model() called ==================================
2025-08-27 23:23:19,647:INFO:Initializing create_model()
2025-08-27 23:23:19,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C16E26B350>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:23:19,648:INFO:Checking exceptions
2025-08-27 23:23:19,648:INFO:Importing libraries
2025-08-27 23:23:19,648:INFO:Copying training dataset
2025-08-27 23:23:19,767:INFO:Defining folds
2025-08-27 23:23:19,767:INFO:Declaring metric variables
2025-08-27 23:23:19,783:INFO:Importing untrained model
2025-08-27 23:23:19,796:INFO:Dummy Classifier Imported successfully
2025-08-27 23:23:19,813:INFO:Starting cross validation
2025-08-27 23:23:19,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-08-27 23:23:20,003:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,018:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,038:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,078:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,102:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,128:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,156:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,178:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,200:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,217:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-08-27 23:23:20,251:INFO:Calculating mean and std
2025-08-27 23:23:20,251:INFO:Creating metrics dataframe
2025-08-27 23:23:20,261:INFO:Uploading results into container
2025-08-27 23:23:20,262:INFO:Uploading model into container now
2025-08-27 23:23:20,262:INFO:_master_model_container: 14
2025-08-27 23:23:20,262:INFO:_display_container: 2
2025-08-27 23:23:20,262:INFO:DummyClassifier(constant=None, random_state=3252, strategy='prior')
2025-08-27 23:23:20,262:INFO:create_model() successfully completed......................................
2025-08-27 23:23:20,416:INFO:SubProcess create_model() end ==================================
2025-08-27 23:23:20,416:INFO:Creating metrics dataframe
2025-08-27 23:23:20,473:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-08-27 23:23:20,507:INFO:Initializing create_model()
2025-08-27 23:23:20,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-08-27 23:23:20,507:INFO:Checking exceptions
2025-08-27 23:23:20,515:INFO:Importing libraries
2025-08-27 23:23:20,515:INFO:Copying training dataset
2025-08-27 23:23:20,612:INFO:Defining folds
2025-08-27 23:23:20,613:INFO:Declaring metric variables
2025-08-27 23:23:20,613:INFO:Importing untrained model
2025-08-27 23:23:20,614:INFO:Declaring custom model
2025-08-27 23:23:20,615:INFO:Naive Bayes Imported successfully
2025-08-27 23:23:20,617:INFO:Cross validation set to False
2025-08-27 23:23:20,617:INFO:Fitting Model
2025-08-27 23:23:20,728:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 23:23:20,728:INFO:create_model() successfully completed......................................
2025-08-27 23:23:21,089:INFO:_master_model_container: 14
2025-08-27 23:23:21,089:INFO:_display_container: 2
2025-08-27 23:23:21,090:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-08-27 23:23:21,090:INFO:compare_models() successfully completed......................................
2025-08-27 23:23:21,090:INFO:Initializing plot_model()
2025-08-27 23:23:21,091:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-08-27 23:23:21,091:INFO:Checking exceptions
2025-08-27 23:23:21,119:INFO:Preloading libraries
2025-08-27 23:23:21,119:INFO:Copying training dataset
2025-08-27 23:23:21,121:INFO:Plot type: confusion_matrix
2025-08-27 23:23:21,453:INFO:Fitting Model
2025-08-27 23:23:21,454:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-08-27 23:23:21,457:INFO:Scoring test/hold-out set
2025-08-27 23:23:22,050:INFO:Visual Rendered Successfully
2025-08-27 23:23:22,271:INFO:plot_model() successfully completed......................................
2025-08-27 23:32:24,461:INFO:Initializing predict_model()
2025-08-27 23:32:24,461:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15A9BF920>)
2025-08-27 23:32:24,461:INFO:Checking exceptions
2025-08-27 23:32:24,461:INFO:Preloading libraries
2025-08-27 23:32:24,463:INFO:Set up data.
2025-08-27 23:32:24,466:INFO:Set up index.
2025-08-27 23:32:47,625:INFO:Initializing predict_model()
2025-08-27 23:32:47,625:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C15A9BFD80>)
2025-08-27 23:32:47,625:INFO:Checking exceptions
2025-08-27 23:32:47,625:INFO:Preloading libraries
2025-08-27 23:32:47,627:INFO:Set up data.
2025-08-27 23:32:47,630:INFO:Set up index.
2025-08-27 23:33:39,490:INFO:Initializing predict_model()
2025-08-27 23:33:39,490:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C157BE3F10>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C16ED47420>)
2025-08-27 23:33:39,491:INFO:Checking exceptions
2025-08-27 23:33:39,491:INFO:Preloading libraries
2025-08-27 23:33:39,492:INFO:Set up data.
2025-08-27 23:33:39,496:INFO:Set up index.
2025-09-01 22:17:01,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-01 22:17:01,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-01 22:17:01,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-01 22:17:01,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-09-01 22:17:05,874:INFO:PyCaret ClassificationExperiment
2025-09-01 22:17:05,875:INFO:Logging name: clf-default-name
2025-09-01 22:17:05,875:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-09-01 22:17:05,876:INFO:version 3.3.2
2025-09-01 22:17:05,876:INFO:Initializing setup()
2025-09-01 22:17:05,876:INFO:self.USI: 2597
2025-09-01 22:17:05,876:INFO:self._variable_keys: {'logging_param', 'gpu_n_jobs_param', 'is_multiclass', 'memory', 'pipeline', 'y_train', 'exp_id', '_ml_usecase', 'exp_name_log', 'data', 'seed', 'gpu_param', 'n_jobs_param', '_available_plots', 'X_train', 'y', 'X', 'idx', 'fold_generator', 'fold_groups_param', 'X_test', 'fold_shuffle_param', 'y_test', 'log_plots_param', 'html_param', 'target_param', 'fix_imbalance', 'USI'}
2025-09-01 22:17:05,876:INFO:Checking environment
2025-09-01 22:17:05,876:INFO:python_version: 3.11.9
2025-09-01 22:17:05,877:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-09-01 22:17:05,877:INFO:machine: AMD64
2025-09-01 22:17:05,877:INFO:platform: Windows-10-10.0.19045-SP0
2025-09-01 22:17:05,882:INFO:Memory: svmem(total=17024348160, available=1051594752, percent=93.8, used=15972753408, free=1051594752)
2025-09-01 22:17:05,882:INFO:Physical Core: 4
2025-09-01 22:17:05,883:INFO:Logical Core: 8
2025-09-01 22:17:05,883:INFO:Checking libraries
2025-09-01 22:17:05,883:INFO:System:
2025-09-01 22:17:05,883:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-09-01 22:17:05,883:INFO:executable: c:\Apps\repos\neuraltwin\.venv\Scripts\python.exe
2025-09-01 22:17:05,883:INFO:   machine: Windows-10-10.0.19045-SP0
2025-09-01 22:17:05,883:INFO:PyCaret required dependencies:
2025-09-01 22:17:05,897:WARNING:c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-09-01 22:17:06,118:INFO:                 pip: Not installed
2025-09-01 22:17:06,118:INFO:          setuptools: 80.9.0
2025-09-01 22:17:06,118:INFO:             pycaret: 3.3.2
2025-09-01 22:17:06,118:INFO:             IPython: 9.4.0
2025-09-01 22:17:06,118:INFO:          ipywidgets: 8.1.7
2025-09-01 22:17:06,118:INFO:                tqdm: 4.67.1
2025-09-01 22:17:06,118:INFO:               numpy: 1.26.4
2025-09-01 22:17:06,118:INFO:              pandas: 2.1.4
2025-09-01 22:17:06,118:INFO:              jinja2: 3.1.6
2025-09-01 22:17:06,118:INFO:               scipy: 1.11.4
2025-09-01 22:17:06,118:INFO:              joblib: 1.3.2
2025-09-01 22:17:06,118:INFO:             sklearn: 1.4.2
2025-09-01 22:17:06,118:INFO:                pyod: 2.0.5
2025-09-01 22:17:06,123:INFO:            imblearn: 0.14.0
2025-09-01 22:17:06,123:INFO:   category_encoders: 2.7.0
2025-09-01 22:17:06,123:INFO:            lightgbm: 4.6.0
2025-09-01 22:17:06,123:INFO:               numba: 0.61.2
2025-09-01 22:17:06,123:INFO:            requests: 2.32.5
2025-09-01 22:17:06,123:INFO:          matplotlib: 3.7.5
2025-09-01 22:17:06,123:INFO:          scikitplot: 0.3.7
2025-09-01 22:17:06,124:INFO:         yellowbrick: 1.5
2025-09-01 22:17:06,124:INFO:              plotly: 5.24.1
2025-09-01 22:17:06,124:INFO:    plotly-resampler: Not installed
2025-09-01 22:17:06,124:INFO:             kaleido: 1.0.0
2025-09-01 22:17:06,124:INFO:           schemdraw: 0.15
2025-09-01 22:17:06,125:INFO:         statsmodels: 0.14.5
2025-09-01 22:17:06,125:INFO:              sktime: 0.26.0
2025-09-01 22:17:06,125:INFO:               tbats: 1.1.3
2025-09-01 22:17:06,126:INFO:            pmdarima: 2.0.4
2025-09-01 22:17:06,126:INFO:              psutil: 7.0.0
2025-09-01 22:17:06,126:INFO:          markupsafe: 3.0.2
2025-09-01 22:17:06,126:INFO:             pickle5: Not installed
2025-09-01 22:17:06,126:INFO:         cloudpickle: 3.1.1
2025-09-01 22:17:06,127:INFO:         deprecation: 2.1.0
2025-09-01 22:17:06,127:INFO:              xxhash: 3.5.0
2025-09-01 22:17:06,127:INFO:           wurlitzer: Not installed
2025-09-01 22:17:06,127:INFO:PyCaret optional dependencies:
2025-09-01 22:17:06,170:INFO:                shap: Not installed
2025-09-01 22:17:06,170:INFO:           interpret: Not installed
2025-09-01 22:17:06,170:INFO:                umap: Not installed
2025-09-01 22:17:06,170:INFO:     ydata_profiling: Not installed
2025-09-01 22:17:06,170:INFO:  explainerdashboard: Not installed
2025-09-01 22:17:06,170:INFO:             autoviz: Not installed
2025-09-01 22:17:06,170:INFO:           fairlearn: Not installed
2025-09-01 22:17:06,171:INFO:          deepchecks: Not installed
2025-09-01 22:17:06,171:INFO:             xgboost: Not installed
2025-09-01 22:17:06,171:INFO:            catboost: Not installed
2025-09-01 22:17:06,171:INFO:              kmodes: Not installed
2025-09-01 22:17:06,171:INFO:             mlxtend: Not installed
2025-09-01 22:17:06,171:INFO:       statsforecast: Not installed
2025-09-01 22:17:06,171:INFO:        tune_sklearn: Not installed
2025-09-01 22:17:06,171:INFO:                 ray: Not installed
2025-09-01 22:17:06,171:INFO:            hyperopt: Not installed
2025-09-01 22:17:06,172:INFO:              optuna: Not installed
2025-09-01 22:17:06,172:INFO:               skopt: Not installed
2025-09-01 22:17:06,172:INFO:              mlflow: Not installed
2025-09-01 22:17:06,172:INFO:              gradio: Not installed
2025-09-01 22:17:06,172:INFO:             fastapi: Not installed
2025-09-01 22:17:06,172:INFO:             uvicorn: Not installed
2025-09-01 22:17:06,172:INFO:              m2cgen: Not installed
2025-09-01 22:17:06,172:INFO:           evidently: Not installed
2025-09-01 22:17:06,173:INFO:               fugue: Not installed
2025-09-01 22:17:06,173:INFO:           streamlit: Not installed
2025-09-01 22:17:06,173:INFO:             prophet: Not installed
2025-09-01 22:17:06,173:INFO:None
2025-09-01 22:17:06,173:INFO:Set up data.
2025-09-01 22:17:06,235:INFO:Set up folding strategy.
2025-09-01 22:17:06,236:INFO:Set up train/test split.
2025-09-01 22:17:06,367:INFO:Set up index.
2025-09-01 22:17:06,372:INFO:Assigning column types.
2025-09-01 22:17:06,407:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-09-01 22:17:06,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-01 22:17:06,500:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-01 22:17:06,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:06,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:06,630:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-09-01 22:17:06,645:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-01 22:17:06,736:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:06,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:06,739:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-09-01 22:17:06,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-01 22:17:06,933:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:06,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:07,010:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-09-01 22:17:07,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:07,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:07,052:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-09-01 22:17:07,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:07,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:07,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:07,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:07,272:INFO:Preparing preprocessing pipeline...
2025-09-01 22:17:07,281:INFO:Set up simple imputation.
2025-09-01 22:17:07,299:INFO:Set up encoding of categorical features.
2025-09-01 22:17:07,590:INFO:Finished creating preprocessing pipeline.
2025-09-01 22:17:07,621:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Fabian Klos\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['speed', 'brake', 'temp',
                                             'vibration', 'battery'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_im...
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['id'],
                                    transformer=TargetEncoder(cols=['id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-09-01 22:17:07,623:INFO:Creating final display dataframe.
2025-09-01 22:17:08,371:INFO:Setup _display_container:                     Description             Value
0                    Session id              3259
1                        Target           failure
2                   Target type            Binary
3           Original data shape       (109973, 7)
4        Transformed data shape       (109973, 7)
5   Transformed train set shape        (76981, 7)
6    Transformed test set shape        (32992, 7)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              2597
2025-09-01 22:17:08,501:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:08,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:08,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:08,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-09-01 22:17:08,598:INFO:setup() successfully completed in 2.73s...............
2025-09-01 22:17:08,606:INFO:Initializing compare_models()
2025-09-01 22:17:08,606:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-09-01 22:17:08,606:INFO:Checking exceptions
2025-09-01 22:17:08,655:INFO:Preparing display monitor
2025-09-01 22:17:08,830:INFO:Initializing Logistic Regression
2025-09-01 22:17:08,831:INFO:Total runtime is 1.6657511393229165e-05 minutes
2025-09-01 22:17:08,860:INFO:SubProcess create_model() called ==================================
2025-09-01 22:17:08,865:INFO:Initializing create_model()
2025-09-01 22:17:08,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F101E57290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-01 22:17:08,868:INFO:Checking exceptions
2025-09-01 22:17:08,869:INFO:Importing libraries
2025-09-01 22:17:08,870:INFO:Copying training dataset
2025-09-01 22:17:09,006:INFO:Defining folds
2025-09-01 22:17:09,007:INFO:Declaring metric variables
2025-09-01 22:17:09,024:INFO:Importing untrained model
2025-09-01 22:17:09,050:INFO:Logistic Regression Imported successfully
2025-09-01 22:17:09,089:INFO:Starting cross validation
2025-09-01 22:17:09,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-01 22:17:19,309:WARNING:Exception in thread ExecutorManagerThread:
2025-09-01 22:17:19,310:WARNING:Traceback (most recent call last):
2025-09-01 22:17:19,310:WARNING:  File "C:\Users\Fabian Klos\AppData\Local\Programs\Python\Python311\Lib\threading.py", line 1045, in _bootstrap_inner
2025-09-01 22:17:19,313:WARNING:    self.run()
2025-09-01 22:17:19,314:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\process_executor.py", line 599, in run
2025-09-01 22:17:19,314:WARNING:    self.terminate_broken(bpe)
2025-09-01 22:17:19,315:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\process_executor.py", line 803, in terminate_broken
2025-09-01 22:17:19,316:WARNING:    self.kill_workers(reason="broken executor")
2025-09-01 22:17:19,316:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\process_executor.py", line 836, in kill_workers
2025-09-01 22:17:19,318:WARNING:    kill_process_tree(p)
2025-09-01 22:17:19,318:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\backend\utils.py", line 19, in kill_process_tree
2025-09-01 22:17:19,358:WARNING:    _kill_process_tree_with_psutil(process)
2025-09-01 22:17:19,359:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\backend\utils.py", line 35, in _kill_process_tree_with_psutil
2025-09-01 22:17:19,359:WARNING:    descendants = psutil.Process(process.pid).children(recursive=True)
2025-09-01 22:17:19,360:WARNING:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-09-01 22:17:19,360:WARNING:  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\psutil\__init__.py", line 966, in children
2025-09-01 22:17:19,392:WARNING:    ppid_map = _ppid_map()
2025-09-01 22:17:19,393:WARNING:               ^^^^^^^^^^^
2025-09-01 22:17:19,393:WARNING:OSError: [WinError 1455] Die Auslagerungsdatei ist zu klein, um diesen Vorgang durchzufhren
2025-09-01 22:17:19,395:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-01 22:17:19,552:WARNING:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Fabian Klos\AppData\Local\Programs\Python\Python311\Lib\multiprocessing\queues.py", line 122, in get
    return _ForkingPickler.loads(res)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 9, in <module>
    from pycaret.internal.pipeline import pipeline_predict_inverse_only
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 25, in <module>
    from pycaret.utils.generic import get_all_object_vars_and_properties, variable_return
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\utils\generic.py", line 11, in <module>
    import pandas as pd
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\__init__.py", line 59, in <module>
    from pandas.core.api import (
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\api.py", line 47, in <module>
    from pandas.core.groupby import (
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\groupby\__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\groupby\generic.py", line 67, in <module>
    from pandas.core.frame import DataFrame
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\frame.py", line 181, in <module>
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1032, in get_code
  File "<frozen importlib._bootstrap_external>", line 1131, in get_data
MemoryError
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.

2025-09-01 22:17:19,554:INFO:Initializing create_model()
2025-09-01 22:17:19,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F101E57290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-01 22:17:19,554:INFO:Checking exceptions
2025-09-01 22:17:19,555:INFO:Importing libraries
2025-09-01 22:17:19,555:INFO:Copying training dataset
2025-09-01 22:17:19,632:INFO:Defining folds
2025-09-01 22:17:19,632:INFO:Declaring metric variables
2025-09-01 22:17:19,653:INFO:Importing untrained model
2025-09-01 22:17:19,674:INFO:Logistic Regression Imported successfully
2025-09-01 22:17:19,707:INFO:Starting cross validation
2025-09-01 22:17:19,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-09-01 22:17:19,816:ERROR:create_model() for lr raised an exception or returned all 0.0:
2025-09-01 22:17:19,977:ERROR:joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\process_executor.py", line 426, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Fabian Klos\AppData\Local\Programs\Python\Python311\Lib\multiprocessing\queues.py", line 122, in get
    return _ForkingPickler.loads(res)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\patches\sklearn.py", line 9, in <module>
    from pycaret.internal.pipeline import pipeline_predict_inverse_only
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 25, in <module>
    from pycaret.utils.generic import get_all_object_vars_and_properties, variable_return
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\utils\generic.py", line 11, in <module>
    import pandas as pd
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\__init__.py", line 59, in <module>
    from pandas.core.api import (
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\api.py", line 47, in <module>
    from pandas.core.groupby import (
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\groupby\__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\groupby\generic.py", line 67, in <module>
    from pandas.core.frame import DataFrame
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\frame.py", line 181, in <module>
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1032, in get_code
  File "<frozen importlib._bootstrap_external>", line 1131, in get_data
MemoryError
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1952, in __call__
    return output if self.return_generator else list(output)
                                                ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1595, in _get_outputs
    yield from self._retrieve()
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1699, in _retrieve
    self._raise_error_fast()
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1734, in _raise_error_fast
    error_job.get_result(self.timeout)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 736, in get_result
    return self._return_or_raise()
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 754, in _return_or_raise
    raise self._result
joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
             ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
              ^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1462, in dispatch_one_batch
    self._dispatch(tasks)
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\parallel.py", line 1384, in _dispatch
    job = self._backend.apply_async(batch, callback=batch_tracker)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\_parallel_backends.py", line 600, in apply_async
    future = self._workers.submit(func)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\reusable_executor.py", line 225, in submit
    return super().submit(fn, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\process_executor.py", line 1248, in submit
    self._ensure_executor_running()
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\process_executor.py", line 1220, in _ensure_executor_running
    self._adjust_process_count()
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\process_executor.py", line 1209, in _adjust_process_count
    p.start()
  File "C:\Users\Fabian Klos\AppData\Local\Programs\Python\Python311\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\backend\process.py", line 45, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\joblib\externals\loky\backend\popen_loky_win32.py", line 86, in __init__
    hp, ht, pid, _ = _winapi.CreateProcess(
                     ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\debugpy\_vendored\pydevd\_pydev_bundle\pydev_monkey.py", line 911, in new_CreateProcess
    return getattr(_subprocess, original_name)(app_name, cmd_line, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [WinError 8] Zur Verarbeitung dieses Befehls sind nicht gengend Speicherressourcen verfgbar

2025-09-01 22:17:19,977:INFO:Initializing K Neighbors Classifier
2025-09-01 22:17:19,977:INFO:Total runtime is 0.1857809106508891 minutes
2025-09-01 22:17:19,994:INFO:SubProcess create_model() called ==================================
2025-09-01 22:17:19,995:INFO:Initializing create_model()
2025-09-01 22:17:19,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F101E57290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-01 22:17:19,995:INFO:Checking exceptions
2025-09-01 22:17:19,996:INFO:Importing libraries
2025-09-01 22:17:19,996:INFO:Copying training dataset
2025-09-01 22:17:20,007:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-01 22:17:20,044:WARNING:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1421, in _create_model
    data_X, data_y = self._create_model_get_train_X_y(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 103, in _create_model_get_train_X_y
    if self.X_train is None:
       ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 25, in X_train
    return self.train.drop(self.target_param, axis=1)
           ^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 5806, in train
    return self.dataset.loc[self.idx[0], :]
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1147, in __getitem__
    return self._getitem_tuple(key)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1339, in _getitem_tuple
    return self._getitem_tuple_same_dim(tup)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 994, in _getitem_tuple_same_dim
    retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1382, in _getitem_axis
    return self._getitem_iterable(key, axis=axis)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1322, in _getitem_iterable
    keyarr, indexer = self._get_listlike_indexer(key, axis)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1520, in _get_listlike_indexer
    keyarr, indexer = ax._get_indexer_strict(key, axis_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 6110, in _get_indexer_strict
    indexer = self.get_indexer_for(keyarr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 6097, in get_indexer_for
    return self.get_indexer(target)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 3943, in get_indexer
    return self._get_indexer(target, method, limit, tolerance)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 3970, in _get_indexer
    indexer = self._engine.get_indexer(tgt_values)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 336, in pandas._libs.index.IndexEngine.get_indexer
  File "pandas\_libs\hashtable_class_helper.pxi", line 2730, in pandas._libs.hashtable.Int64HashTable.lookup
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 601. KiB for an array with shape (76981,) and data type int64

2025-09-01 22:17:20,045:INFO:Initializing create_model()
2025-09-01 22:17:20,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F101E57290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-01 22:17:20,045:INFO:Checking exceptions
2025-09-01 22:17:20,046:INFO:Importing libraries
2025-09-01 22:17:20,046:INFO:Copying training dataset
2025-09-01 22:17:20,050:ERROR:create_model() for knn raised an exception or returned all 0.0:
2025-09-01 22:17:20,138:ERROR:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1421, in _create_model
    data_X, data_y = self._create_model_get_train_X_y(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 103, in _create_model_get_train_X_y
    if self.X_train is None:
       ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 25, in X_train
    return self.train.drop(self.target_param, axis=1)
           ^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 5806, in train
    return self.dataset.loc[self.idx[0], :]
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1147, in __getitem__
    return self._getitem_tuple(key)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1339, in _getitem_tuple
    return self._getitem_tuple_same_dim(tup)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 994, in _getitem_tuple_same_dim
    retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1382, in _getitem_axis
    return self._getitem_iterable(key, axis=axis)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1322, in _getitem_iterable
    keyarr, indexer = self._get_listlike_indexer(key, axis)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1520, in _get_listlike_indexer
    keyarr, indexer = ax._get_indexer_strict(key, axis_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 6110, in _get_indexer_strict
    indexer = self.get_indexer_for(keyarr)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 6097, in get_indexer_for
    return self.get_indexer(target)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 3943, in get_indexer
    return self._get_indexer(target, method, limit, tolerance)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 3970, in _get_indexer
    indexer = self._engine.get_indexer(tgt_values)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 336, in pandas._libs.index.IndexEngine.get_indexer
  File "pandas\_libs\hashtable_class_helper.pxi", line 2730, in pandas._libs.hashtable.Int64HashTable.lookup
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 601. KiB for an array with shape (76981,) and data type int64

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1421, in _create_model
    data_X, data_y = self._create_model_get_train_X_y(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 103, in _create_model_get_train_X_y
    if self.X_train is None:
       ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 25, in X_train
    return self.train.drop(self.target_param, axis=1)
           ^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 5806, in train
    return self.dataset.loc[self.idx[0], :]
           ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py", line 557, in dataset
    return self.data[[c for c in self.data.columns if c not in self._fxs["Ignore"]]]
           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
               ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
                 ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\array_algos\take.py", line 156, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype, order="F")
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 430. KiB for an array with shape (109973, 1) and data type float32

2025-09-01 22:17:20,139:INFO:Initializing Naive Bayes
2025-09-01 22:17:20,139:INFO:Total runtime is 0.18847530682881675 minutes
2025-09-01 22:17:20,156:INFO:SubProcess create_model() called ==================================
2025-09-01 22:17:20,157:INFO:Initializing create_model()
2025-09-01 22:17:20,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F101E57290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-01 22:17:20,158:INFO:Checking exceptions
2025-09-01 22:17:20,158:INFO:Importing libraries
2025-09-01 22:17:20,158:INFO:Copying training dataset
2025-09-01 22:17:20,170:WARNING:create_model() for nb raised an exception or returned all 0.0, trying without fit_kwargs:
2025-09-01 22:17:20,177:WARNING:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1421, in _create_model
    data_X, data_y = self._create_model_get_train_X_y(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 103, in _create_model_get_train_X_y
    if self.X_train is None:
       ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 25, in X_train
    return self.train.drop(self.target_param, axis=1)
           ^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 5806, in train
    return self.dataset.loc[self.idx[0], :]
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1147, in __getitem__
    return self._getitem_tuple(key)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1339, in _getitem_tuple
    return self._getitem_tuple_same_dim(tup)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 994, in _getitem_tuple_same_dim
    retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1382, in _getitem_axis
    return self._getitem_iterable(key, axis=axis)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1322, in _getitem_iterable
    keyarr, indexer = self._get_listlike_indexer(key, axis)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1520, in _get_listlike_indexer
    keyarr, indexer = ax._get_indexer_strict(key, axis_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 6111, in _get_indexer_strict
    keyarr = self.reindex(keyarr)[0]
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 4427, in reindex
    indexer = self.get_indexer(
              ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 3943, in get_indexer
    return self._get_indexer(target, method, limit, tolerance)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 3970, in _get_indexer
    indexer = self._engine.get_indexer(tgt_values)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 336, in pandas._libs.index.IndexEngine.get_indexer
  File "pandas\_libs\hashtable_class_helper.pxi", line 2730, in pandas._libs.hashtable.Int64HashTable.lookup
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 601. KiB for an array with shape (76981,) and data type int64

2025-09-01 22:17:20,178:INFO:Initializing create_model()
2025-09-01 22:17:20,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F101E57290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-01 22:17:20,179:INFO:Checking exceptions
2025-09-01 22:17:20,179:INFO:Importing libraries
2025-09-01 22:17:20,179:INFO:Copying training dataset
2025-09-01 22:17:20,186:ERROR:create_model() for nb raised an exception or returned all 0.0:
2025-09-01 22:17:20,216:ERROR:Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1421, in _create_model
    data_X, data_y = self._create_model_get_train_X_y(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 103, in _create_model_get_train_X_y
    if self.X_train is None:
       ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 25, in X_train
    return self.train.drop(self.target_param, axis=1)
           ^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 5806, in train
    return self.dataset.loc[self.idx[0], :]
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1147, in __getitem__
    return self._getitem_tuple(key)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1339, in _getitem_tuple
    return self._getitem_tuple_same_dim(tup)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 994, in _getitem_tuple_same_dim
    retval = getattr(retval, self.name)._getitem_axis(key, axis=i)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1382, in _getitem_axis
    return self._getitem_iterable(key, axis=axis)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1322, in _getitem_iterable
    keyarr, indexer = self._get_listlike_indexer(key, axis)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexing.py", line 1520, in _get_listlike_indexer
    keyarr, indexer = ax._get_indexer_strict(key, axis_name)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 6111, in _get_indexer_strict
    keyarr = self.reindex(keyarr)[0]
             ^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 4427, in reindex
    indexer = self.get_indexer(
              ^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 3943, in get_indexer
    return self._get_indexer(target, method, limit, tolerance)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\indexes\base.py", line 3970, in _get_indexer
    indexer = self._engine.get_indexer(tgt_values)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 336, in pandas._libs.index.IndexEngine.get_indexer
  File "pandas\_libs\hashtable_class_helper.pxi", line 2730, in pandas._libs.hashtable.Int64HashTable.lookup
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 601. KiB for an array with shape (76981,) and data type int64

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1421, in _create_model
    data_X, data_y = self._create_model_get_train_X_y(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 103, in _create_model_get_train_X_y
    if self.X_train is None:
       ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\non_ts_supervised_experiment.py", line 25, in X_train
    return self.train.drop(self.target_param, axis=1)
           ^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 5806, in train
    return self.dataset.loc[self.idx[0], :]
           ^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\pycaret_experiment.py", line 557, in dataset
    return self.data[[c for c in self.data.columns if c not in self._fxs["Ignore"]]]
           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\frame.py", line 3908, in __getitem__
    data = self._take_with_is_copy(indexer, axis=1)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\generic.py", line 4088, in _take_with_is_copy
    result = self.take(indices=indices, axis=axis)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\generic.py", line 4068, in take
    new_data = self._mgr.take(
               ^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\internals\managers.py", line 877, in take
    return self.reindex_indexer(
           ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\internals\managers.py", line 663, in reindex_indexer
    new_blocks = self._slice_take_blocks_ax0(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\internals\managers.py", line 826, in _slice_take_blocks_ax0
    nb = blk.take_nd(taker, axis=0, new_mgr_locs=mgr_locs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\internals\blocks.py", line 1061, in take_nd
    new_values = algos.take_nd(
                 ^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\array_algos\take.py", line 118, in take_nd
    return _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Apps\repos\neuraltwin\.venv\Lib\site-packages\pandas\core\array_algos\take.py", line 156, in _take_nd_ndarray
    out = np.empty(out_shape, dtype=dtype, order="F")
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 430. KiB for an array with shape (109973, 1) and data type float32

2025-09-01 22:17:20,217:INFO:Initializing Decision Tree Classifier
2025-09-01 22:17:20,218:INFO:Total runtime is 0.18979194561640422 minutes
2025-09-01 22:17:20,230:INFO:SubProcess create_model() called ==================================
2025-09-01 22:17:20,231:INFO:Initializing create_model()
2025-09-01 22:17:20,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F17F921410>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F101E57290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-09-01 22:17:20,231:INFO:Checking exceptions
2025-09-01 22:17:20,231:INFO:Importing libraries
2025-09-01 22:17:20,232:INFO:Copying training dataset
2025-09-01 22:17:20,288:INFO:Defining folds
2025-09-01 22:17:20,288:INFO:Declaring metric variables
2025-09-01 22:17:20,299:INFO:Importing untrained model
2025-09-01 22:17:20,312:INFO:Decision Tree Classifier Imported successfully
2025-09-01 22:17:20,336:INFO:Starting cross validation
2025-09-01 22:17:20,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
